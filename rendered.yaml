---
# Source: fullstack-app/templates/kubecost-grafana-dashboard-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kubecost-dashboard
  namespace: monitoring
  labels:
    grafana_dashboard: "1"
data:
  kubecost-dashboard.json: |
        {"__inputs":[{"name":"DS_ENDOURANCE","label":"endourance","description":"","type":"datasource","pluginId":"postgres","pluginName":"PostgreSQL"}],"__requires":[{"type":"panel","id":"gauge","name":"Gauge","version":""},{"type":"grafana","id":"grafana","name":"Grafana","version":"8.1.5-35396"},{"type":"panel","id":"graph","name":"Graph (old)","version":""},{"type":"panel","id":"michaeldmoore-scatter-panel","name":"Scatter","version":"1.0.0"},{"type":"datasource","id":"postgres","name":"PostgreSQL","version":"1.0.0"},{"type":"panel","id":"text","name":"Text","version":""},{"type":"panel","id":"timeseries","name":"Time series","version":""}],"annotations":{"list":[{"$$hashKey":"object:59","builtIn":1,"datasource":"-- Grafana --","enable":true,"hide":true,"iconColor":"rgba(0, 211, 255, 1)","name":"Annotations & Alerts","target":{"limit":100,"matchAny":false,"tags":[],"type":"dashboard"},"type":"dashboard"}]},"editable":true,"gnetId":15068,"graphTooltip":0,"id":null,"links":[],"panels":[{"datasource":null,"gridPos":{"h":3,"w":23,"x":0,"y":0},"id":30,"links":[],"options":{"content":"\n# NG ENDURANCE\n### POWERED BY BLUE BOX\n\n\n\n\n\n","mode":"markdown"},"pluginVersion":"8.1.5-35396","timeFrom":null,"timeShift":null,"transparent":true,"type":"text"},{"datasource":"${DS_ENDOURANCE}","description":"","fieldConfig":{"defaults":{"color":{"mode":"thresholds"},"mappings":[],"max":2100,"min":0,"thresholds":{"mode":"absolute","steps":[{"color":"super-light-blue","value":null},{"color":"light-blue","value":525},{"color":"semi-dark-blue","value":1050},{"color":"dark-blue","value":1575}]},"unit":"kwatt"},"overrides":[]},"gridPos":{"h":6,"w":5,"x":0,"y":3},"id":20,"links":[],"options":{"orientation":"auto","reduceOptions":{"calcs":["last"],"fields":"","values":false},"showThresholdLabels":true,"showThresholdMarkers":true,"text":{}},"pluginVersion":"8.1.5-35396","targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG1\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=380 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"timeFrom":null,"timeShift":null,"title":"ekW MAIN ENGINE 1","transparent":true,"type":"gauge"},{"datasource":"${DS_ENDOURANCE}","description":"","fieldConfig":{"defaults":{"color":{"mode":"thresholds"},"displayName":"","mappings":[],"max":3150,"min":0,"thresholds":{"mode":"absolute","steps":[{"color":"super-light-blue","value":null},{"color":"light-blue","value":787},{"color":"semi-dark-blue","value":1575},{"color":"dark-blue","value":2362}]},"unit":"kwatt"},"overrides":[]},"gridPos":{"h":6,"w":5,"x":5,"y":3},"id":23,"links":[],"options":{"orientation":"auto","reduceOptions":{"calcs":["last"],"fields":"","values":false},"showThresholdLabels":true,"showThresholdMarkers":true,"text":{}},"pluginVersion":"8.1.5-35396","targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG2\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=381 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"timeFrom":null,"timeShift":null,"title":"ekW MAIN ENGINE 2","transparent":true,"type":"gauge"},{"datasource":"${DS_ENDOURANCE}","description":"","fieldConfig":{"defaults":{"color":{"mode":"thresholds"},"displayName":"","mappings":[],"max":3150,"min":0,"thresholds":{"mode":"absolute","steps":[{"color":"super-light-blue","value":null},{"color":"light-blue","value":787},{"color":"semi-dark-blue","value":1575},{"color":"dark-blue","value":2362}]},"unit":"kwatt"},"overrides":[]},"gridPos":{"h":6,"w":5,"x":10,"y":3},"id":36,"links":[],"options":{"orientation":"auto","reduceOptions":{"calcs":["last"],"fields":"","values":false},"showThresholdLabels":true,"showThresholdMarkers":true,"text":{}},"pluginVersion":"8.1.5-35396","targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG3\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=382 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"timeFrom":null,"timeShift":null,"title":"ekW MAIN ENGINE 3","transparent":true,"type":"gauge"},{"datasource":"${DS_ENDOURANCE}","description":"","fieldConfig":{"defaults":{"color":{"mode":"thresholds"},"mappings":[],"max":2100,"min":0,"thresholds":{"mode":"absolute","steps":[{"color":"super-light-blue","value":null},{"color":"light-blue","value":525},{"color":"semi-dark-blue","value":1050},{"color":"dark-blue","value":1575}]},"unit":"kwatt"},"overrides":[]},"gridPos":{"h":6,"w":5,"x":15,"y":3},"id":25,"links":[],"options":{"orientation":"auto","reduceOptions":{"calcs":["last"],"fields":"","values":false},"showThresholdLabels":true,"showThresholdMarkers":true,"text":{}},"pluginVersion":"8.1.5-35396","targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG4\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=383 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"timeFrom":null,"timeShift":null,"title":"ekW MAIN ENGINE 4","transparent":true,"type":"gauge"},{"datasource":"${DS_ENDOURANCE}","description":"","gridPos":{"h":16,"w":23,"x":0,"y":9},"id":53,"options":{"border":{"show":false,"color":"yellow","size":1},"fieldSets":[{"col":2,"color":"#1F60C4","dotSize":2,"hidden":false,"lineSize":1,"lineType":"exponential"}],"grid":{"color":"gray"},"legend":{"show":false,"size":3},"rotateYAxisTitle":true,"xAxis":{"col":1,"inverted":false},"xAxisExtents":{"min":0,"max":1},"xAxisTitle":{"text":"Engine load (%)","color":"#777","textSize":1},"yAxisExtents":{"min":180,"max":500},"yAxisTitle":{"text":"SFoC (g(bkWh)","color":"#777","textSize":1}},"pluginVersion":"7.5.5","repeat":null,"targets":[{"format":"time_series","group":[],"metricColumn":"none","queryType":"randomWalk","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"KW Main Propulsion Port\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=397 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"hide":false,"metricColumn":"none","queryType":"randomWalk","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"KW Main Propulsion Starboard\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=401 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"B","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"hide":false,"metricColumn":"none","queryType":"randomWalk","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Speed\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=425 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"C","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"hide":false,"metricColumn":"none","queryType":"randomWalk","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Depth AFT\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=368 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"D","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"hide":false,"metricColumn":"none","queryType":"randomWalk","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Depth FWD\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=369 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"E","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"timeFrom":null,"timeShift":null,"title":"Speed - power curve","transformations":[{"id":"calculateField","options":{"alias":"Propulsion power","mode":"reduceRow","reduce":{"include":["KW Main Propulsion Starboard","KW Main Propulsion Port"],"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Trim","binary":{"left":"Depth FWD","operator":"-","reducer":"sum","right":"Depth AFT"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"filterFieldsByName","options":{"include":{"names":["Time","Speed","Propulsion power","Trim"]}}}],"type":"michaeldmoore-scatter-panel"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"${DS_ENDOURANCE}","fieldConfig":{"defaults":{"unit":"kwatt"},"overrides":[]},"fill":10,"fillGradient":10,"gridPos":{"h":9,"w":23,"x":0,"y":25},"hiddenSeries":false,"hideTimeOverride":false,"id":16,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"8.1.5-35396","pointradius":2,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":true,"steppedLine":true,"targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG1\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=380 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG2\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=381 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"B","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG3\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=382 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"C","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG4\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=383 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"D","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Power Production Gen Sets (ekW)","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:1216","format":"kwatt","label":null,"logBase":1,"max":null,"min":"0","show":true},{"$$hashKey":"object:1217","format":"short","label":null,"logBase":1,"max":null,"min":null,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"${DS_ENDOURANCE}","description":"","fieldConfig":{"defaults":{"unit":"kwatt"},"overrides":[]},"fill":1,"fillGradient":10,"gridPos":{"h":9,"w":23,"x":0,"y":34},"hiddenSeries":false,"hideTimeOverride":false,"id":55,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":2,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"8.1.5-35396","pointradius":2,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG1\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=380 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG2\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=381 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"B","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG3\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=382 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"C","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG4\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=383 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"D","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"hide":false,"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Power Prop 2\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=401 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"E","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"hide":false,"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Power Prop 1\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=397 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"F","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"hide":false,"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Thruster 1\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=406 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"G","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"hide":false,"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Thruster 2\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=408 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"H","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Hotel load (ekW)","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"transformations":[{"id":"calculateField","options":{"alias":"Generated power","mode":"reduceRow","reduce":{"include":["Active Power DG1","Active Power DG2","Active Power DG3","Active Power DG4"],"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Power on water","mode":"reduceRow","reduce":{"include":["Power Prop 2","Power Prop 1","Thruster 1","Thruster 2"],"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Hotel load","binary":{"left":"Generated power","operator":"-","reducer":"sum","right":"Power on water"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Hotel load (I)","mode":"reduceRow","reduce":{"include":["Hotel load"],"reducer":"mean"},"replaceFields":true}}],"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:1216","format":"kwatt","label":null,"logBase":1,"max":null,"min":"0","show":true},{"$$hashKey":"object:1217","format":"short","label":null,"logBase":1,"max":null,"min":null,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{"Engine load":"dark-blue"},"bars":false,"dashLength":10,"dashes":false,"datasource":"${DS_ENDOURANCE}","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":0,"fillGradient":0,"gridPos":{"h":9,"w":11,"x":0,"y":43},"hiddenSeries":false,"hideTimeOverride":false,"id":38,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"connected","options":{"alertThreshold":false},"paceLength":10,"percentage":false,"pluginVersion":"8.1.5-35396","pointradius":2,"points":false,"renderer":"flot","seriesOverrides":[{"$$hashKey":"object:112","alias":"Instant SFoC","yaxis":1},{"$$hashKey":"object:117","alias":"Engine load","yaxis":2}],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG1\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=380 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"FoC DG1\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=372 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"B","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"SFoC & Load - Engine 1 ","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"transformations":[{"id":"calculateField","options":{"alias":"","binary":{"left":"Active Power DG1","operator":"*","reducer":"sum","right":"0.96"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Engine load","binary":{"left":"Active Power DG1 * 0.96","operator":"/","reducer":"sum","right":"2250"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"binary":{"left":"FoC DG1","operator":"*","reducer":"sum","right":"830"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Instant SFoC","binary":{"left":"FoC DG1 * 830","operator":"/","reducer":"sum","right":"Active Power DG1 * 0.96"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"filterFieldsByName","options":{"include":{"names":["Time","Engine load","Instant SFoC"]}}}],"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:132","decimals":0,"format":"string","label":"SFoC (g/kWh)","logBase":1,"max":"350","min":"180","show":true},{"$$hashKey":"object:133","decimals":1,"format":"percentunit","label":"Engine load (%)","logBase":1,"max":"1","min":"0","show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{"Engine load":"dark-blue"},"bars":false,"dashLength":10,"dashes":false,"datasource":"${DS_ENDOURANCE}","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":0,"fillGradient":0,"gridPos":{"h":9,"w":12,"x":11,"y":43},"hiddenSeries":false,"hideTimeOverride":false,"id":39,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"connected","options":{"alertThreshold":false},"paceLength":10,"percentage":false,"pluginVersion":"8.1.5-35396","pointradius":2,"points":false,"renderer":"flot","seriesOverrides":[{"$$hashKey":"object:112","alias":"Instant SFoC","yaxis":1},{"$$hashKey":"object:117","alias":"Engine load","yaxis":2}],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG4\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=383 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"FoC DG4\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=375 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"B","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"SFoC & Load - Engine 4","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"transformations":[{"id":"calculateField","options":{"alias":"","binary":{"left":"Active Power DG4","operator":"*","reducer":"sum","right":"0.96"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Engine load","binary":{"left":"Active Power DG4 * 0.96","operator":"/","reducer":"sum","right":"2250"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"binary":{"left":"FoC DG4","operator":"*","reducer":"sum","right":"830"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Instant SFoC","binary":{"left":"FoC DG4 * 830","operator":"/","reducer":"sum","right":"Active Power DG4 * 0.96"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"filterFieldsByName","options":{"include":{"names":["Time","Engine load","Instant SFoC"]}}}],"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:132","decimals":0,"format":"string","label":"SFoC (g/kWh)","logBase":1,"max":"350","min":"180","show":true},{"$$hashKey":"object:133","decimals":1,"format":"percentunit","label":"Engine load (%)","logBase":1,"max":"1","min":"0","show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{"Engine load":"dark-blue"},"bars":false,"dashLength":10,"dashes":false,"datasource":"${DS_ENDOURANCE}","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":0,"fillGradient":0,"gridPos":{"h":9,"w":11,"x":0,"y":52},"hiddenSeries":false,"hideTimeOverride":false,"id":42,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"connected","options":{"alertThreshold":false},"paceLength":10,"percentage":false,"pluginVersion":"8.1.5-35396","pointradius":2,"points":false,"renderer":"flot","seriesOverrides":[{"$$hashKey":"object:112","alias":"Instant SFoC","yaxis":1},{"$$hashKey":"object:117","alias":"Engine load","yaxis":2}],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG2\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=381 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"FoC DG2\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=373 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"B","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"SFoC & Load - Engine 2","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"transformations":[{"id":"calculateField","options":{"alias":"","binary":{"left":"Active Power DG2","operator":"*","reducer":"sum","right":"0.96"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Engine load","binary":{"left":"Active Power DG2 * 0.96","operator":"/","reducer":"sum","right":"3150"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"binary":{"left":"FoC DG2","operator":"*","reducer":"sum","right":"830"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Instant SFoC","binary":{"left":"FoC DG2 * 830","operator":"/","reducer":"sum","right":"Active Power DG2 * 0.96"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"filterFieldsByName","options":{"include":{"names":["Time","Engine load","Instant SFoC"]}}}],"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:132","decimals":0,"format":"string","label":"SFoC (g/kWh)","logBase":1,"max":"350","min":"180","show":true},{"$$hashKey":"object:133","decimals":1,"format":"percentunit","label":"Engine load (%)","logBase":1,"max":"1","min":"0","show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{"Engine load":"dark-blue"},"bars":false,"dashLength":10,"dashes":false,"datasource":"${DS_ENDOURANCE}","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":0,"fillGradient":0,"gridPos":{"h":9,"w":12,"x":11,"y":52},"hiddenSeries":false,"hideTimeOverride":false,"id":43,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"connected","options":{"alertThreshold":false},"paceLength":10,"percentage":false,"pluginVersion":"8.1.5-35396","pointradius":2,"points":false,"renderer":"flot","seriesOverrides":[{"$$hashKey":"object:112","alias":"Instant SFoC","yaxis":1},{"$$hashKey":"object:117","alias":"Engine load","yaxis":2}],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG3\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=382 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"FoC DG3\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=374 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"B","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"SFoC & Load - Engine 3","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"transformations":[{"id":"calculateField","options":{"alias":"","binary":{"left":"Active Power DG3","operator":"*","reducer":"sum","right":"0.96"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Engine load","binary":{"left":"Active Power DG3 * 0.96","operator":"/","reducer":"sum","right":"3150"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"binary":{"left":"FoC DG3","operator":"*","reducer":"sum","right":"830"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Instant SFoC","binary":{"left":"FoC DG3 * 830","operator":"/","reducer":"sum","right":"Active Power DG3 * 0.96"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"filterFieldsByName","options":{"include":{"names":["Time","Engine load","Instant SFoC"]}}}],"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:132","decimals":0,"format":"string","label":"SFoC (g/kWh)","logBase":1,"max":"350","min":"180","show":true},{"$$hashKey":"object:133","decimals":1,"format":"percentunit","label":"Engine load (%)","logBase":1,"max":"1","min":"0","show":true}],"yaxis":{"align":false,"alignLevel":null}},{"datasource":"${DS_ENDOURANCE}","gridPos":{"h":8,"w":12,"x":0,"y":61},"hideTimeOverride":false,"id":49,"links":[],"options":{"border":{"show":false,"color":"yellow","size":1},"fieldSets":[{"col":2,"color":"#505bd3","dotSize":2,"hidden":false,"lineSize":1,"lineType":"none"}],"grid":{"color":"gray"},"legend":{"show":false,"size":3},"rotateYAxisTitle":true,"xAxis":{"col":1,"inverted":false},"xAxisExtents":{"min":0,"max":1},"xAxisTitle":{"text":"Engine load (%)","color":"#777","textSize":1},"yAxisExtents":{"min":180,"max":500},"yAxisTitle":{"text":"SFoC (g(bkWh)","color":"#777","textSize":1}},"pluginVersion":"7.5.5","targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG1\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=380 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"FoC DG1\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=372 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"B","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"timeFrom":null,"timeShift":null,"title":"SFoC curve - Engine 1 ","transformations":[{"id":"calculateField","options":{"alias":"Engine load","binary":{"left":"Active Power DG1","operator":"/","reducer":"sum","right":"2250"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"binary":{"left":"FoC DG1","operator":"*","reducer":"sum","right":"855"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Instant SFoC","binary":{"left":"FoC DG1 * 855","operator":"/","reducer":"sum","right":"Active Power DG1"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"filterFieldsByName","options":{"include":{"names":["Time","Engine load","Instant SFoC"]}}}],"type":"michaeldmoore-scatter-panel"},{"datasource":"${DS_ENDOURANCE}","gridPos":{"h":8,"w":11,"x":12,"y":61},"hideTimeOverride":false,"id":50,"links":[],"options":{"border":{"show":false,"color":"yellow","size":1},"fieldSets":[{"col":2,"color":"#acea72","dotSize":2,"hidden":false,"lineSize":1,"lineType":"none"}],"grid":{"color":"gray"},"legend":{"show":false,"size":3},"rotateYAxisTitle":true,"xAxis":{"col":1,"inverted":false},"xAxisExtents":{"min":0,"max":1},"xAxisTitle":{"text":"Engine load (%)","color":"#777","textSize":1},"yAxisExtents":{"min":180,"max":500},"yAxisTitle":{"text":"SFoC (g(bkWh)","color":"#777","textSize":1}},"pluginVersion":"7.5.5","targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG4\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=383 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"FoC DG4\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=375 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"B","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"timeFrom":null,"timeShift":null,"title":"SFoC curve - Engine 4","transformations":[{"id":"calculateField","options":{"alias":"Engine load","binary":{"left":"Active Power DG4","operator":"/","reducer":"sum","right":"2250"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"binary":{"left":"FoC DG4","operator":"*","reducer":"sum","right":"855"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Instant SFoC","binary":{"left":"FoC DG4 * 855","operator":"/","reducer":"sum","right":"Active Power DG4"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"filterFieldsByName","options":{"include":{"names":["Time","Engine load","Instant SFoC"]}}}],"type":"michaeldmoore-scatter-panel"},{"datasource":"${DS_ENDOURANCE}","gridPos":{"h":9,"w":12,"x":0,"y":69},"hideTimeOverride":false,"id":51,"links":[],"options":{"border":{"show":false,"color":"yellow","size":1},"fieldSets":[{"col":2,"color":"#9b5cd6","dotSize":2,"hidden":false,"lineSize":1,"lineType":"none"}],"grid":{"color":"gray"},"legend":{"show":false,"size":3},"rotateYAxisTitle":true,"xAxis":{"col":1,"inverted":false},"xAxisExtents":{"min":0,"max":1},"xAxisTitle":{"text":"Engine load (%)","color":"#777","textSize":1},"yAxisExtents":{"min":180,"max":500},"yAxisTitle":{"text":"SFoC (g(bkWh)","color":"#777","textSize":1}},"pluginVersion":"7.5.5","targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG2\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=381 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"FoC DG2\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=373 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"B","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"timeFrom":null,"timeShift":null,"title":"SFoC curve - Engine 2","transformations":[{"id":"calculateField","options":{"alias":"Engine load","binary":{"left":"Active Power DG2","operator":"/","reducer":"sum","right":"3150"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"binary":{"left":"FoC DG2","operator":"*","reducer":"sum","right":"855"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Instant SFoC","binary":{"left":"FoC DG2 * 855","operator":"/","reducer":"sum","right":"Active Power DG2"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"filterFieldsByName","options":{"include":{"names":["Time","Engine load","Instant SFoC"]}}}],"type":"michaeldmoore-scatter-panel"},{"datasource":"${DS_ENDOURANCE}","gridPos":{"h":9,"w":11,"x":12,"y":69},"hideTimeOverride":false,"id":52,"links":[],"options":{"border":{"show":false,"color":"yellow","size":1},"fieldSets":[{"col":2,"color":"#f7bd8a","dotSize":2,"hidden":false,"lineSize":1,"lineType":"none"}],"grid":{"color":"gray"},"legend":{"show":false,"size":3},"rotateYAxisTitle":true,"xAxis":{"col":1,"inverted":false},"xAxisExtents":{"min":0,"max":1},"xAxisTitle":{"text":"Engine load (%)","color":"#777","textSize":1},"yAxisExtents":{"min":180,"max":500},"yAxisTitle":{"text":"SFoC (g(bkWh)","color":"#777","textSize":1}},"pluginVersion":"7.5.5","targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Active Power DG3\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=382 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"FoC DG3\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=374 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"B","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"timeFrom":null,"timeShift":null,"title":"SFoC curve - Engine 3","transformations":[{"id":"calculateField","options":{"alias":"Engine load","binary":{"left":"Active Power DG3","operator":"/","reducer":"sum","right":"3150"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"binary":{"left":"FoC DG3","operator":"*","reducer":"sum","right":"855"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"calculateField","options":{"alias":"Instant SFoC","binary":{"left":"FoC DG3 * 855","operator":"/","reducer":"sum","right":"Active Power DG3"},"mode":"binary","reduce":{"reducer":"sum"}}},{"id":"filterFieldsByName","options":{"include":{"names":["Time","Engine load","Instant SFoC"]}}}],"type":"michaeldmoore-scatter-panel"},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"${DS_ENDOURANCE}","fieldConfig":{"defaults":{"unit":"none"},"overrides":[]},"fill":1,"fillGradient":10,"gridPos":{"h":9,"w":23,"x":0,"y":78},"hiddenSeries":false,"hideTimeOverride":false,"id":34,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":0,"links":[],"nullPointMode":"null","options":{"alertThreshold":true},"percentage":false,"pluginVersion":"8.1.5-35396","pointradius":2,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Net Fuel Flow DG1\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=372 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Net Fuel Flow DG2\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=373 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"B","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Net Fuel Flow DG3\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=374 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"C","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Net Fuel Flow DG4\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=375 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"D","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Instant Fuel Consumption (l/h)","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"transparent":true,"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:1449","format":"none","label":null,"logBase":1,"max":null,"min":"0","show":true},{"$$hashKey":"object:1450","format":"short","label":null,"logBase":1,"max":null,"min":null,"show":true}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"${DS_ENDOURANCE}","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":10,"fillGradient":10,"gridPos":{"h":9,"w":23,"x":0,"y":87},"hiddenSeries":false,"hideTimeOverride":false,"id":33,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":0,"links":[],"nullPointMode":"null as zero","options":{"alertThreshold":false},"paceLength":10,"percentage":false,"pluginVersion":"8.1.5-35396","pointradius":2,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":true,"steppedLine":false,"targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"KW Main Propulsion Port\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=397 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"KW Main Propulsion Starboard\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=401 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"B","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Main Propulsion Power (kW)","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:1038","format":"kwatt","label":"","logBase":1,"max":"8000","min":"0","show":true},{"$$hashKey":"object:1039","format":"short","label":null,"logBase":1,"max":null,"min":null,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"${DS_ENDOURANCE}","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":1,"gridPos":{"h":19,"w":23,"x":0,"y":96},"hiddenSeries":false,"hideTimeOverride":false,"id":37,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null as zero","options":{"alertThreshold":true},"paceLength":10,"percentage":false,"pluginVersion":"8.1.5-35396","pointradius":2,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Speed over water\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=425 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Speed over surface (knots)","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:190","format":"velocityknot","label":"","logBase":1,"max":"17","min":"0","show":true},{"$$hashKey":"object:191","format":"short","label":null,"logBase":1,"max":null,"min":null,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"${DS_ENDOURANCE}","fieldConfig":{"defaults":{"links":[]},"overrides":[]},"fill":1,"fillGradient":1,"gridPos":{"h":15,"w":23,"x":0,"y":115},"hiddenSeries":false,"hideTimeOverride":false,"id":48,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null as zero","options":{"alertThreshold":true},"paceLength":10,"percentage":false,"pluginVersion":"8.1.5-35396","pointradius":2,"points":false,"renderer":"flot","seriesOverrides":[],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Heel\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=396 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Heel angle (deg)","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"transformations":[],"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:95","format":"degree","label":"","logBase":1,"max":null,"min":null,"show":true},{"$$hashKey":"object:96","format":"short","label":null,"logBase":1,"max":null,"min":null,"show":false}],"yaxis":{"align":false,"alignLevel":null}},{"aliasColors":{},"bars":false,"dashLength":10,"dashes":false,"datasource":"${DS_ENDOURANCE}","fieldConfig":{"defaults":{"links":[],"unit":"lengthm"},"overrides":[{"matcher":{"id":"byName","options":"Trim"},"properties":[{"id":"unit","value":"lengthm"}]}]},"fill":1,"fillGradient":1,"gridPos":{"h":15,"w":23,"x":0,"y":130},"hiddenSeries":false,"hideTimeOverride":false,"id":54,"legend":{"avg":false,"current":false,"max":false,"min":false,"show":true,"total":false,"values":false},"lines":true,"linewidth":1,"links":[],"nullPointMode":"null as zero","options":{"alertThreshold":true},"paceLength":10,"percentage":false,"pluginVersion":"8.1.5-35396","pointradius":2,"points":false,"renderer":"flot","seriesOverrides":[{"$$hashKey":"object:183","alias":"Draft Fwd","yaxis":1},{"$$hashKey":"object:190","alias":"Draft Aft","yaxis":1},{"$$hashKey":"object:197","alias":"Trim","yaxis":2}],"spaceLength":10,"stack":false,"steppedLine":false,"targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Draft Fwd\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=367 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"hide":false,"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"Draft Aft\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=370 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"B","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"thresholds":[],"timeFrom":null,"timeRegions":[],"timeShift":null,"title":"Draft & trim","tooltip":{"shared":true,"sort":0,"value_type":"individual"},"transformations":[{"id":"calculateField","options":{"alias":"Trim","binary":{"left":"Draft Fwd","operator":"-","reducer":"sum","right":"Draft Aft"},"mode":"binary","reduce":{"reducer":"sum"}}}],"type":"graph","xaxis":{"buckets":null,"mode":"time","name":null,"show":true,"values":[]},"yaxes":[{"$$hashKey":"object:95","format":"lengthm","label":"","logBase":1,"max":null,"min":null,"show":true},{"$$hashKey":"object:96","decimals":2,"format":"lengthm","label":"","logBase":1,"max":"0.5","min":"-0.5","show":true}],"yaxis":{"align":false,"alignLevel":null}},{"datasource":"${DS_ENDOURANCE}","fieldConfig":{"defaults":{"color":{"mode":"palette-classic"},"custom":{"axisLabel":"","axisPlacement":"auto","barAlignment":0,"drawStyle":"line","fillOpacity":10,"gradientMode":"opacity","hideFrom":{"graph":false,"legend":false,"tooltip":false,"viz":false},"lineInterpolation":"stepAfter","lineWidth":1,"pointSize":5,"scaleDistribution":{"type":"linear"},"showPoints":"never","spanNulls":false,"stacking":{"group":"A","mode":"none"},"thresholdsStyle":{"mode":"off"}},"mappings":[],"max":231,"min":0,"thresholds":{"mode":"absolute","steps":[{"color":"green","value":null},{"color":"red","value":80}]},"unit":"rpm"},"overrides":[]},"gridPos":{"h":9,"w":23,"x":0,"y":145},"hideTimeOverride":false,"id":32,"links":[],"options":{"graph":{},"legend":{"calcs":[],"displayMode":"list","placement":"bottom"},"tooltip":{"mode":"single"}},"pluginVersion":"7.5.5","targets":[{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"RPM Main Propulsion 1\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=398 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"A","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]},{"format":"time_series","group":[],"metricColumn":"none","rawQuery":true,"rawSql":"SELECT\n  $__time(timestamp/1000),\n  engineeringvalue as \"RPM Main Propulsion 2\"\nFROM\n  analogsignalfilteredlast\nWHERE\n id=402 and\n timestamp >= $__unixEpochFrom()::bigint*1000 and\n timestamp <= $__unixEpochTo()::bigint*1000\norder by timestamp;\n","refId":"B","select":[[{"params":["value"],"type":"column"}]],"timeColumn":"time","where":[{"name":"$__timeFilter","params":[],"type":"macro"}]}],"timeFrom":null,"timeShift":null,"title":"Main Propulsion RPM","type":"timeseries"}],"refresh":false,"schemaVersion":30,"style":"dark","tags":[],"templating":{"list":[]},"time":{"from":"now-2d","to":"now"},"timepicker":{"refresh_intervals":["5s","10s","30s","1m","5m","15m","30m","1h","2h","1d"],"time_options":["5m","15m","1h","6h","12h","24h","2d","7d","30d"]},"timezone":"","title":"NG Endurance","uid":"9HIAOOQZk","version":142}
---
# Source: fullstack-app/templates/service-client.yaml
apiVersion: v1
kind: Service
metadata:
  name: server-client
  labels:
    app: server-client
spec:
  type: ClusterIP
  selector:
    app: server-client
  ports:
    - port: 80
      targetPort: 80
---
# Source: fullstack-app/templates/service-server.yaml
apiVersion: v1
kind: Service
metadata:
  name: server-server
  labels:
    app: server-server
spec:
  type: ClusterIP
  selector:
    app: server-server
  ports:
    - port: 80
      targetPort: 6001
---
# Source: fullstack-app/templates/deployment-client.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: server-client
  labels:
    app: server-client
spec:
  replicas: 2
  selector:
    matchLabels:
      app: server-client
  template:
    metadata:
      labels:
        app: server-client
    spec:
      containers:
        - name: client
          image: "gantagouthamyadav/fullstack-client:latest"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 80
          resources:
            requests:
              cpu: "250m"
              memory: "256Mi"
            limits:
              cpu: "500m"
---
# Source: fullstack-app/templates/deployment-server.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: server-server
  labels:
    app: server-server
spec:
  replicas: 2
  selector:
    matchLabels:
      app: server-server
  template:
    metadata:
      labels:
        app: server-server
    spec:
      containers:
        - name: server
          image: "gantagouthamyadav/fullstack-server:public-posts"
          imagePullPolicy: Always
          ports:
            - containerPort: 6001
        
          env:
            - name: MONGO_URI
              value: "mongodb://fullstack-app-mongo-mongodb.fullstack.svc.cluster.local:27017/mern-social"
            - name: MONGODB_URI
              value: "mongodb://fullstack-app-mongo-mongodb.fullstack.svc.cluster.local:27017/mern-social"
            - name: DB_URI
              value: "mongodb://fullstack-app-mongo-mongodb.fullstack.svc.cluster.local:27017/mern-social"
          resources:
            requests:
              cpu: "100m"
              memory: "128Mi"
            limits:
              cpu: "250m"
              memory: "256Mi"
---
# Source: fullstack-app/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: server-ingress
  namespace: fullstack
  labels:
    app: server
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/use-regex: "true"
spec:
  ingressClassName: nginx
  rules:
    - host: fullstack.mernappproject.com
      http:
        paths:
          - path: /api(/|$)(.*)
            pathType: ImplementationSpecific
            backend:
              service:
                name: server-server
                port:
                  number: 80
          - path: /()(.*)
            pathType: ImplementationSpecific
            backend:
              service:
                name: server-client
                port:
                  number: 80
---
# Source: fullstack-app/templates/kubectl-cost-servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kubectl-cost
  namespace: monitoring
  labels:
    release: kube-prometheus-stack
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: kubectl-cost
  endpoints:
    - port: http
      path: /metrics
      interval: 30s
  namespaceSelector:
    matchNames:
      - monitoring

---
# Source: velero/templates/serviceaccount-server.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: velero-server
  namespace: velero
  labels:
    app.kubernetes.io/name: velero
    app.kubernetes.io/instance: velero
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: velero-5.0.2
---
# Source: velero/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: velero
  namespace: velero
  labels:
    app.kubernetes.io/name: velero
    app.kubernetes.io/instance: velero
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: velero-5.0.2
type: Opaque
data:
  cloud: "W2RlZmF1bHRdCmF3c19hY2Nlc3Nfa2V5X2lkID0ge3sgLkVudi5BV1NfQUNDRVNTX0tFWV9JRCB9fQphd3Nfc2VjcmV0X2FjY2Vzc19rZXkgPSB7eyAuRW52LkFXU19TRUNSRVRfQUNDRVNTX0tFWSB9fQo="
---
# Source: velero/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: velero-server
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: velero
    app.kubernetes.io/instance: velero
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: velero-5.0.2
subjects:
  - kind: ServiceAccount
    namespace: velero
    name: velero-server
roleRef:
  kind: ClusterRole
  name: cluster-admin
  apiGroup: rbac.authorization.k8s.io
---
# Source: velero/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: velero-server
  namespace: velero
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: velero
    app.kubernetes.io/instance: velero
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: velero-5.0.2
rules:
- apiGroups:
    - "*"
  resources:
    - "*"
  verbs:
    - "*"
---
# Source: velero/templates/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: velero-server
  namespace: velero
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: velero
    app.kubernetes.io/instance: velero
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: velero-5.0.2
subjects:
  - kind: ServiceAccount
    namespace: velero
    name: velero-server
roleRef:
  kind: Role
  name: velero-server
  apiGroup: rbac.authorization.k8s.io
---
# Source: velero/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: velero
  namespace: velero
  labels:
    app.kubernetes.io/name: velero
    app.kubernetes.io/instance: velero
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: velero-5.0.2
spec:
  type: ClusterIP
  ports:
    - name: http-monitoring
      port: 8085
      targetPort: http-monitoring
  selector:
    name: velero
    app.kubernetes.io/name: velero
    app.kubernetes.io/instance: velero
---
# Source: velero/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: velero
  namespace: velero
  labels:
    app.kubernetes.io/name: velero
    app.kubernetes.io/instance: velero
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: velero-5.0.2
    component: velero
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app.kubernetes.io/instance: velero
      app.kubernetes.io/name: velero
  template:
    metadata:
      labels:
        name: velero
        app.kubernetes.io/name: velero
        app.kubernetes.io/instance: velero
        app.kubernetes.io/managed-by: Helm
        helm.sh/chart: velero-5.0.2
      annotations:
        prometheus.io/path: /metrics
        prometheus.io/port: "8085"
        prometheus.io/scrape: "true"
    spec:
      restartPolicy: Always
      serviceAccountName: velero-server
      terminationGracePeriodSeconds: 3600
      containers:
        - name: velero
          image: "velero/velero:v1.11.1"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http-monitoring
              containerPort: 8085
          command:
            - /velero
          args:
            - server
            ### Flags
            - --uploader-type=restic
            ### Global Flags
          resources:
            limits:
              cpu: 1000m
              memory: 512Mi
            requests:
              cpu: 500m
              memory: 128Mi
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /metrics
              port: http-monitoring
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 5
            httpGet:
              path: /metrics
              port: http-monitoring
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 5
          volumeMounts:
            - name: plugins
              mountPath: /plugins
            - name: cloud-credentials
              mountPath: /credentials
            - name: scratch
              mountPath: /scratch
          env:
            - name: VELERO_SCRATCH_DIR
              value: /scratch
            - name: VELERO_NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: LD_LIBRARY_PATH
              value: /plugins
            - name: AWS_SHARED_CREDENTIALS_FILE
              value: /credentials/cloud
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: /credentials/cloud
            - name: AZURE_CREDENTIALS_FILE
              value: /credentials/cloud
            - name: ALIBABA_CLOUD_CREDENTIALS_FILE
              value: /credentials/cloud
      dnsPolicy: ClusterFirst
      volumes:
        - name: cloud-credentials
          secret:
            secretName: velero
        - name: plugins
          emptyDir: {}
        - name: scratch
          emptyDir: {}
---
# Source: velero/templates/backupstoragelocation.yaml
apiVersion: velero.io/v1
kind: BackupStorageLocation
metadata:
  name: default
  namespace: velero
  labels:
    app.kubernetes.io/name: velero
    app.kubernetes.io/instance: velero
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: velero-5.0.2
spec:
  credential:
  provider: 
  accessMode: ReadWrite
  objectStorage:
    bucket:
---
# Source: velero/templates/volumesnapshotlocation.yaml
apiVersion: velero.io/v1
kind: VolumeSnapshotLocation
metadata:
  name: default
  namespace: velero
  labels:
    app.kubernetes.io/name: velero
    app.kubernetes.io/instance: velero
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: velero-5.0.2
spec:
  credential:
  provider:
---
# Source: velero/templates/upgrade-crds/serviceaccount-upgrade.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: velero-server-upgrade-crds
  namespace: velero
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,pre-rollback
    "helm.sh/hook-weight": "-4"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app.kubernetes.io/name: velero
    app.kubernetes.io/instance: velero
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: velero-5.0.2
---
# Source: velero/templates/upgrade-crds/clusterrole-upgrade.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: velero-upgrade-crds
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,pre-rollback
    "helm.sh/hook-weight": "-5"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app.kubernetes.io/component: upgrade-crds
    app.kubernetes.io/name: velero
    app.kubernetes.io/instance: velero
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: velero-5.0.2
rules:
- apiGroups: 
    - "apiextensions.k8s.io"
  resources: 
    - "customresourcedefinitions"
  verbs: 
    - create
    - patch
    - update
    - get
    - list
---
# Source: velero/templates/upgrade-crds/clusterrolebinding-upgrade.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: velero-upgrade-crds
  labels:
    app.kubernetes.io/component: upgrade-crds
    app.kubernetes.io/name: velero
    app.kubernetes.io/instance: velero
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: velero-5.0.2
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,pre-rollback
    "helm.sh/hook-weight": "-3"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
subjects:
  - kind: ServiceAccount
    namespace: velero
    name: velero-server-upgrade-crds
roleRef:
  kind: ClusterRole
  name: velero-upgrade-crds
  apiGroup: rbac.authorization.k8s.io
---
# Source: velero/templates/upgrade-crds/upgrade-crds.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: velero-upgrade-crds
  namespace: velero
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,pre-rollback
    "helm.sh/hook-weight": "5"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app.kubernetes.io/name: velero
    app.kubernetes.io/instance: velero
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: velero-5.0.2
spec:
  backoffLimit: 3
  template:
    metadata:
      name: velero-upgrade-crds
    spec:
      serviceAccountName: velero-server-upgrade-crds
      initContainers:
        - name: kubectl
          image: "docker.io/bitnami/kubectl:1.32"
          imagePullPolicy: IfNotPresent
          command:
            - /bin/sh
          args:
            - -c
            - cp `which sh` /tmp && cp `which kubectl` /tmp
          volumeMounts:
            - mountPath: /tmp
              name: crds
      containers:
        - name: velero
          image: "velero/velero:v1.11.1"
          imagePullPolicy: IfNotPresent
          command:
            - /tmp/sh
          args:
            - -c
            - /velero install --crds-only --dry-run -o yaml | /tmp/kubectl apply -f -
          resources:
            limits:
              cpu: 1000m
              memory: 512Mi
            requests:
              cpu: 500m
              memory: 128Mi
          volumeMounts:
            - mountPath: /tmp
              name: crds
      volumes:
        - name: crds
          emptyDir: {}
      restartPolicy: OnFailure

---
# Source: kube-prometheus-stack/charts/grafana/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  labels:
    helm.sh/chart: grafana-7.3.10
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "10.4.1"
    app.kubernetes.io/managed-by: Helm
  name: kube-prometheus-stack-grafana
  namespace: monitoring
---
# Source: kube-prometheus-stack/charts/kube-state-metrics/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:    
    helm.sh/chart: kube-state-metrics-5.19.0
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "2.12.0"
    release: kube-prometheus-stack
  name: kube-prometheus-stack-kube-state-metrics
  namespace: monitoring
---
# Source: kube-prometheus-stack/charts/prometheus-node-exporter/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kube-prometheus-stack-prometheus-node-exporter
  namespace: monitoring
  labels:
    helm.sh/chart: prometheus-node-exporter-4.34.0
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: prometheus-node-exporter
    app.kubernetes.io/name: prometheus-node-exporter
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "1.8.0"
    jobLabel: node-exporter
    release: kube-prometheus-stack
---
# Source: kube-prometheus-stack/templates/alertmanager/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kube-prometheus-stack-alertmanager
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-alertmanager
    app.kubernetes.io/name: kube-prometheus-stack-alertmanager
    app.kubernetes.io/component: alertmanager
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
automountServiceAccountToken: true
---
# Source: kube-prometheus-stack/templates/prometheus-operator/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kube-prometheus-stack-operator
  namespace: monitoring
  labels:
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
    app: kube-prometheus-stack-operator
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator
automountServiceAccountToken: true
---
# Source: kube-prometheus-stack/templates/prometheus/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kube-prometheus-stack-prometheus
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-prometheus
    app.kubernetes.io/name: kube-prometheus-stack-prometheus
    app.kubernetes.io/component: prometheus
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
automountServiceAccountToken: true
---
# Source: kube-prometheus-stack/charts/grafana/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: kube-prometheus-stack-grafana
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-7.3.10
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "10.4.1"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  
  admin-user: "YWRtaW4="
  admin-password: "cHJvbS1vcGVyYXRvcg=="
  ldap-toml: ""
---
# Source: kube-prometheus-stack/templates/alertmanager/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: alertmanager-kube-prometheus-stack-alertmanager
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-alertmanager
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
data:
  alertmanager.yaml: "Z2xvYmFsOgogIHJlc29sdmVfdGltZW91dDogNW0KaW5oaWJpdF9ydWxlczoKLSBlcXVhbDoKICAtIG5hbWVzcGFjZQogIC0gYWxlcnRuYW1lCiAgc291cmNlX21hdGNoZXJzOgogIC0gc2V2ZXJpdHkgPSBjcml0aWNhbAogIHRhcmdldF9tYXRjaGVyczoKICAtIHNldmVyaXR5ID1+IHdhcm5pbmd8aW5mbwotIGVxdWFsOgogIC0gbmFtZXNwYWNlCiAgLSBhbGVydG5hbWUKICBzb3VyY2VfbWF0Y2hlcnM6CiAgLSBzZXZlcml0eSA9IHdhcm5pbmcKICB0YXJnZXRfbWF0Y2hlcnM6CiAgLSBzZXZlcml0eSA9IGluZm8KLSBlcXVhbDoKICAtIG5hbWVzcGFjZQogIHNvdXJjZV9tYXRjaGVyczoKICAtIGFsZXJ0bmFtZSA9IEluZm9JbmhpYml0b3IKICB0YXJnZXRfbWF0Y2hlcnM6CiAgLSBzZXZlcml0eSA9IGluZm8KLSB0YXJnZXRfbWF0Y2hlcnM6CiAgLSBhbGVydG5hbWUgPSBJbmZvSW5oaWJpdG9yCnJlY2VpdmVyczoKLSBuYW1lOiBzbGFjay1ub3RpZmljYXRpb25zCiAgc2xhY2tfY29uZmlnczoKICAtIGFwaV91cmw6IGh0dHBzOi8vaG9va3Muc2xhY2suY29tL3NlcnZpY2VzL1QwOFM2MlBCUU42L0IwOFNTMlBTS01FL1U3b0Fnd2dlRUFzeDNTSXZKT2xPeTY4SwogICAgY2hhbm5lbDogJyNhbGVydHMnCiAgICBzZW5kX3Jlc29sdmVkOiB0cnVlCiAgICB1c2VybmFtZTogcHJvbWV0aGV1cwpyb3V0ZToKICBncm91cF9ieToKICAtIGFsZXJ0bmFtZQogIGdyb3VwX2ludGVydmFsOiA1bQogIGdyb3VwX3dhaXQ6IDMwcwogIHJlY2VpdmVyOiAibnVsbCIKICByZXBlYXRfaW50ZXJ2YWw6IDEyaAogIHJvdXRlczoKICAtIG1hdGNoZXJzOgogICAgLSBhbGVydG5hbWUgPSAiV2F0Y2hkb2ciCiAgICByZWNlaXZlcjogIm51bGwiCnRlbXBsYXRlczoKLSAvZXRjL2FsZXJ0bWFuYWdlci9jb25maWcvKi50bXBs"
---
# Source: kube-prometheus-stack/charts/grafana/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kube-prometheus-stack-grafana
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-7.3.10
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "10.4.1"
    app.kubernetes.io/managed-by: Helm
data:
  
  grafana.ini: |
    [analytics]
    check_for_updates = true
    [grafana_net]
    url = https://grafana.net
    [log]
    mode = console
    [paths]
    data = /var/lib/grafana/
    logs = /var/log/grafana
    plugins = /var/lib/grafana/plugins
    provisioning = /etc/grafana/provisioning
    [server]
    domain = ''
---
# Source: kube-prometheus-stack/templates/grafana/configmaps-datasources.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kube-prometheus-stack-grafana-datasource
  namespace: monitoring
  labels:
    grafana_datasource: "1"
    app: kube-prometheus-stack-grafana
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
data:
  datasource.yaml: |-
    apiVersion: 1
    datasources:
    - name: Prometheus
      type: prometheus
      uid: prometheus
      url: http://kube-prometheus-stack-prometheus.monitoring:9090/
      access: proxy
      isDefault: true
      jsonData:
        httpMethod: POST
        timeInterval: 30s
    - name: Alertmanager
      type: alertmanager
      uid: alertmanager
      url: http://kube-prometheus-stack-alertmanager.monitoring:9093/
      access: proxy
      jsonData:
        handleGrafanaManagedAlerts: false
        implementation: prometheus
---
# Source: kube-prometheus-stack/charts/grafana/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    helm.sh/chart: grafana-7.3.10
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "10.4.1"
    app.kubernetes.io/managed-by: Helm
  name: kube-prometheus-stack-grafana-clusterrole
rules:
  - apiGroups: [""] # "" indicates the core API group
    resources: ["configmaps", "secrets"]
    verbs: ["get", "watch", "list"]
---
# Source: kube-prometheus-stack/charts/kube-state-metrics/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:    
    helm.sh/chart: kube-state-metrics-5.19.0
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "2.12.0"
    release: kube-prometheus-stack
  name: kube-prometheus-stack-kube-state-metrics
rules:

- apiGroups: ["certificates.k8s.io"]
  resources:
  - certificatesigningrequests
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - configmaps
  verbs: ["list", "watch"]

- apiGroups: ["batch"]
  resources:
  - cronjobs
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "apps"]
  resources:
  - daemonsets
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "apps"]
  resources:
  - deployments
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - endpoints
  verbs: ["list", "watch"]

- apiGroups: ["autoscaling"]
  resources:
  - horizontalpodautoscalers
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "networking.k8s.io"]
  resources:
  - ingresses
  verbs: ["list", "watch"]

- apiGroups: ["batch"]
  resources:
  - jobs
  verbs: ["list", "watch"]

- apiGroups: ["coordination.k8s.io"]
  resources:
  - leases
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - limitranges
  verbs: ["list", "watch"]

- apiGroups: ["admissionregistration.k8s.io"]
  resources:
    - mutatingwebhookconfigurations
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - namespaces
  verbs: ["list", "watch"]

- apiGroups: ["networking.k8s.io"]
  resources:
  - networkpolicies
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - nodes
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - persistentvolumeclaims
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - persistentvolumes
  verbs: ["list", "watch"]

- apiGroups: ["policy"]
  resources:
    - poddisruptionbudgets
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - pods
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "apps"]
  resources:
  - replicasets
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - replicationcontrollers
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - resourcequotas
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - secrets
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - services
  verbs: ["list", "watch"]

- apiGroups: ["apps"]
  resources:
  - statefulsets
  verbs: ["list", "watch"]

- apiGroups: ["storage.k8s.io"]
  resources:
    - storageclasses
  verbs: ["list", "watch"]

- apiGroups: ["admissionregistration.k8s.io"]
  resources:
    - validatingwebhookconfigurations
  verbs: ["list", "watch"]

- apiGroups: ["storage.k8s.io"]
  resources:
    - volumeattachments
  verbs: ["list", "watch"]
---
# Source: kube-prometheus-stack/templates/prometheus-operator/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kube-prometheus-stack-operator
  labels:
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
    app: kube-prometheus-stack-operator
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator
rules:
- apiGroups:
  - monitoring.coreos.com
  resources:
  - alertmanagers
  - alertmanagers/finalizers
  - alertmanagers/status
  - alertmanagerconfigs
  - prometheuses
  - prometheuses/finalizers
  - prometheuses/status
  - prometheusagents
  - prometheusagents/finalizers
  - prometheusagents/status
  - thanosrulers
  - thanosrulers/finalizers
  - thanosrulers/status
  - scrapeconfigs
  - servicemonitors
  - podmonitors
  - probes
  - prometheusrules
  verbs:
  - '*'
- apiGroups:
  - apps
  resources:
  - statefulsets
  verbs:
  - '*'
- apiGroups:
  - ""
  resources:
  - configmaps
  - secrets
  verbs:
  - '*'
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - list
  - delete
- apiGroups:
  - ""
  resources:
  - services
  - services/finalizers
  - endpoints
  verbs:
  - get
  - create
  - update
  - delete
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - namespaces
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - patch
  - create
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - storage.k8s.io
  resources:
  - storageclasses
  verbs:
  - get
---
# Source: kube-prometheus-stack/templates/prometheus/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kube-prometheus-stack-prometheus
  labels:
    app: kube-prometheus-stack-prometheus
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
rules:
# This permission are not in the kube-prometheus repo
# they're grabbed from https://github.com/prometheus/prometheus/blob/master/documentation/examples/rbac-setup.yml
- apiGroups: [""]
  resources:
  - nodes
  - nodes/metrics
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups:
  - "networking.k8s.io"
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics", "/metrics/cadvisor"]
  verbs: ["get"]
---
# Source: kube-prometheus-stack/charts/grafana/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: kube-prometheus-stack-grafana-clusterrolebinding
  labels:
    helm.sh/chart: grafana-7.3.10
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "10.4.1"
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: kube-prometheus-stack-grafana
    namespace: monitoring
roleRef:
  kind: ClusterRole
  name: kube-prometheus-stack-grafana-clusterrole
  apiGroup: rbac.authorization.k8s.io
---
# Source: kube-prometheus-stack/charts/kube-state-metrics/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:    
    helm.sh/chart: kube-state-metrics-5.19.0
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "2.12.0"
    release: kube-prometheus-stack
  name: kube-prometheus-stack-kube-state-metrics
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kube-prometheus-stack-kube-state-metrics
subjects:
- kind: ServiceAccount
  name: kube-prometheus-stack-kube-state-metrics
  namespace: monitoring
---
# Source: kube-prometheus-stack/templates/prometheus-operator/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kube-prometheus-stack-operator
  labels:
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
    app: kube-prometheus-stack-operator
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kube-prometheus-stack-operator
subjects:
- kind: ServiceAccount
  name: kube-prometheus-stack-operator
  namespace: monitoring
---
# Source: kube-prometheus-stack/templates/prometheus/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kube-prometheus-stack-prometheus
  labels:
    app: kube-prometheus-stack-prometheus
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kube-prometheus-stack-prometheus
subjects:
  - kind: ServiceAccount
    name: kube-prometheus-stack-prometheus
    namespace: monitoring
---
# Source: kube-prometheus-stack/charts/grafana/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: kube-prometheus-stack-grafana
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-7.3.10
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "10.4.1"
    app.kubernetes.io/managed-by: Helm
rules: []
---
# Source: kube-prometheus-stack/charts/grafana/templates/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: kube-prometheus-stack-grafana
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-7.3.10
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "10.4.1"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: kube-prometheus-stack-grafana
subjects:
- kind: ServiceAccount
  name: kube-prometheus-stack-grafana
  namespace: monitoring
---
# Source: kube-prometheus-stack/charts/grafana/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kube-prometheus-stack-grafana
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-7.3.10
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "10.4.1"
    app.kubernetes.io/managed-by: Helm
spec:
  type: LoadBalancer
  ports:
    - name: http-web
      port: 80
      protocol: TCP
      targetPort: 3000
  selector:
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: kube-prometheus-stack
---
# Source: kube-prometheus-stack/charts/kube-state-metrics/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kube-prometheus-stack-kube-state-metrics
  namespace: monitoring
  labels:    
    helm.sh/chart: kube-state-metrics-5.19.0
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "2.12.0"
    release: kube-prometheus-stack
  annotations:
    prometheus.io/scrape: 'true'
spec:
  type: "ClusterIP"
  ports:
  - name: "http"
    protocol: TCP
    port: 8080
    targetPort: 8080
  
  selector:    
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: kube-prometheus-stack
---
# Source: kube-prometheus-stack/charts/prometheus-node-exporter/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kube-prometheus-stack-prometheus-node-exporter
  namespace: monitoring
  labels:
    helm.sh/chart: prometheus-node-exporter-4.34.0
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: prometheus-node-exporter
    app.kubernetes.io/name: prometheus-node-exporter
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "1.8.0"
    jobLabel: node-exporter
    release: kube-prometheus-stack
  annotations:
    prometheus.io/scrape: "true"
spec:
  type: ClusterIP
  ports:
    - port: 9100
      targetPort: 9100
      protocol: TCP
      name: http-metrics
  selector:
    app.kubernetes.io/name: prometheus-node-exporter
    app.kubernetes.io/instance: kube-prometheus-stack
---
# Source: kube-prometheus-stack/templates/alertmanager/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kube-prometheus-stack-alertmanager
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-alertmanager
    self-monitor: "true"
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  ports:
  - name: http-web
    port: 9093
    targetPort: 9093
    protocol: TCP
  - name: reloader-web
    appProtocol: http
    port: 8080
    targetPort: reloader-web
  selector:
    app.kubernetes.io/name: alertmanager
    alertmanager: kube-prometheus-stack-alertmanager
  sessionAffinity: None
  type: "ClusterIP"
---
# Source: kube-prometheus-stack/templates/exporters/core-dns/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kube-prometheus-stack-coredns
  labels:
    app: kube-prometheus-stack-coredns
    jobLabel: coredns
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
  namespace: kube-system
spec:
  clusterIP: None
  ports:
    - name: http-metrics
      port: 9153
      protocol: TCP
      targetPort: 9153
  selector:
    k8s-app: kube-dns
---
# Source: kube-prometheus-stack/templates/exporters/kube-controller-manager/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kube-prometheus-stack-kube-controller-manager
  labels:
    app: kube-prometheus-stack-kube-controller-manager
    jobLabel: kube-controller-manager
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
  namespace: kube-system
spec:
  clusterIP: None
  ports:
    - name: http-metrics
      port: 10257
      protocol: TCP
      targetPort: 10257
  selector:
    component: kube-controller-manager
  type: ClusterIP
---
# Source: kube-prometheus-stack/templates/exporters/kube-etcd/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kube-prometheus-stack-kube-etcd
  labels:
    app: kube-prometheus-stack-kube-etcd
    jobLabel: kube-etcd
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
  namespace: kube-system
spec:
  clusterIP: None
  ports:
    - name: http-metrics
      port: 2381
      protocol: TCP
      targetPort: 2381
  selector:
    component: etcd
  type: ClusterIP
---
# Source: kube-prometheus-stack/templates/exporters/kube-proxy/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kube-prometheus-stack-kube-proxy
  labels:
    app: kube-prometheus-stack-kube-proxy
    jobLabel: kube-proxy
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
  namespace: kube-system
spec:
  clusterIP: None
  ports:
    - name: http-metrics
      port: 10249
      protocol: TCP
      targetPort: 10249
  selector:
    k8s-app: kube-proxy
  type: ClusterIP
---
# Source: kube-prometheus-stack/templates/exporters/kube-scheduler/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kube-prometheus-stack-kube-scheduler
  labels:
    app: kube-prometheus-stack-kube-scheduler
    jobLabel: kube-scheduler
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
  namespace: kube-system
spec:
  clusterIP: None
  ports:
    - name: http-metrics
      port: 10259
      protocol: TCP
      targetPort: 10259
  selector:
    component: kube-scheduler
  type: ClusterIP
---
# Source: kube-prometheus-stack/templates/prometheus-operator/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kube-prometheus-stack-operator
  namespace: monitoring
  labels:
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
    app: kube-prometheus-stack-operator
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator
spec:
  ports:
  - name: https
    port: 443
    targetPort: https
  selector:
    app: kube-prometheus-stack-operator
    release: "kube-prometheus-stack"
  type: "ClusterIP"
---
# Source: kube-prometheus-stack/templates/prometheus/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kube-prometheus-stack-prometheus
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-prometheus
    self-monitor: "true"
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  ports:
  - name: http-web
    port: 9090
    targetPort: 9090
  - name: reloader-web
    appProtocol: http
    port: 8080
    targetPort: reloader-web
  publishNotReadyAddresses: false
  selector:
    app.kubernetes.io/name: prometheus
    operator.prometheus.io/name: kube-prometheus-stack-prometheus
  sessionAffinity: None
  type: "ClusterIP"
---
# Source: kube-prometheus-stack/charts/prometheus-node-exporter/templates/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-prometheus-stack-prometheus-node-exporter
  namespace: monitoring
  labels:
    helm.sh/chart: prometheus-node-exporter-4.34.0
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: prometheus-node-exporter
    app.kubernetes.io/name: prometheus-node-exporter
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "1.8.0"
    jobLabel: node-exporter
    release: kube-prometheus-stack
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/instance: kube-prometheus-stack
  revisionHistoryLimit: 10
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
      labels:
        helm.sh/chart: prometheus-node-exporter-4.34.0
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: metrics
        app.kubernetes.io/part-of: prometheus-node-exporter
        app.kubernetes.io/name: prometheus-node-exporter
        app.kubernetes.io/instance: kube-prometheus-stack
        app.kubernetes.io/version: "1.8.0"
        jobLabel: node-exporter
        release: kube-prometheus-stack
    spec:
      automountServiceAccountToken: false
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
      serviceAccountName: kube-prometheus-stack-prometheus-node-exporter
      containers:
        - name: node-exporter
          image: quay.io/prometheus/node-exporter:v1.8.0
          imagePullPolicy: IfNotPresent
          args:
            - --path.procfs=/host/proc
            - --path.sysfs=/host/sys
            - --path.rootfs=/host/root
            - --path.udev.data=/host/root/run/udev/data
            - --web.listen-address=[$(HOST_IP)]:9100
            - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
            - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
          securityContext:
            readOnlyRootFilesystem: true
          env:
            - name: HOST_IP
              value: 0.0.0.0
          ports:
            - name: http-metrics
              containerPort: 9100
              protocol: TCP
          livenessProbe:
            failureThreshold: 3
            httpGet:
              httpHeaders:
              path: /
              port: 9100
              scheme: HTTP
            initialDelaySeconds: 0
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            httpGet:
              httpHeaders:
              path: /
              port: 9100
              scheme: HTTP
            initialDelaySeconds: 0
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          volumeMounts:
            - name: proc
              mountPath: /host/proc
              readOnly:  true
            - name: sys
              mountPath: /host/sys
              readOnly: true
            - name: root
              mountPath: /host/root
              mountPropagation: HostToContainer
              readOnly: true
      hostNetwork: true
      hostPID: true
      nodeSelector:
        kubernetes.io/os: linux
      tolerations:
        - effect: NoSchedule
          operator: Exists
      volumes:
        - name: proc
          hostPath:
            path: /proc
        - name: sys
          hostPath:
            path: /sys
        - name: root
          hostPath:
            path: /
---
# Source: kube-prometheus-stack/charts/grafana/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kube-prometheus-stack-grafana
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-7.3.10
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "10.4.1"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/name: grafana
      app.kubernetes.io/instance: kube-prometheus-stack
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: grafana
        app.kubernetes.io/instance: kube-prometheus-stack
      annotations:
        checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
        checksum/sc-dashboard-provider-config: 954264f54a280bc12359dfc16136b098503f64ec7d7889261c2a5a3894135a5a
        checksum/secret: 032056e9c62bbe9d1daa41ee49cd3d9524c076f51ca4c65adadf4ef08ef28712
        kubectl.kubernetes.io/default-container: grafana
    spec:
      
      serviceAccountName: kube-prometheus-stack-grafana
      automountServiceAccountToken: true
      securityContext:
        fsGroup: 472
        runAsGroup: 472
        runAsNonRoot: true
        runAsUser: 472
      enableServiceLinks: true
      containers:
        - name: grafana-sc-datasources
          image: "quay.io/kiwigrid/k8s-sidecar:1.26.1"
          imagePullPolicy: IfNotPresent
          env:
            - name: METHOD
              value: WATCH
            - name: LABEL
              value: "grafana_datasource"
            - name: LABEL_VALUE
              value: "1"
            - name: FOLDER
              value: "/etc/grafana/provisioning/datasources"
            - name: RESOURCE
              value: "both"
            - name: REQ_USERNAME
              valueFrom:
                secretKeyRef:
                  name: kube-prometheus-stack-grafana
                  key: admin-user
            - name: REQ_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: kube-prometheus-stack-grafana
                  key: admin-password
            - name: REQ_URL
              value: http://localhost:3000/api/admin/provisioning/datasources/reload
            - name: REQ_METHOD
              value: POST
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          volumeMounts:
            - name: sc-datasources-volume
              mountPath: "/etc/grafana/provisioning/datasources"
        - name: grafana
          image: "docker.io/grafana/grafana:10.4.1"
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          volumeMounts:
            - name: config
              mountPath: "/etc/grafana/grafana.ini"
              subPath: grafana.ini
            - name: storage
              mountPath: "/var/lib/grafana"
            - name: sc-datasources-volume
              mountPath: "/etc/grafana/provisioning/datasources"
          ports:
            - name: grafana
              containerPort: 3000
              protocol: TCP
            - name: gossip-tcp
              containerPort: 9094
              protocol: TCP
            - name: gossip-udp
              containerPort: 9094
              protocol: UDP
          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: GF_SECURITY_ADMIN_USER
              valueFrom:
                secretKeyRef:
                  name: kube-prometheus-stack-grafana
                  key: admin-user
            - name: GF_SECURITY_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: kube-prometheus-stack-grafana
                  key: admin-password
            - name: GF_PATHS_DATA
              value: /var/lib/grafana/
            - name: GF_PATHS_LOGS
              value: /var/log/grafana
            - name: GF_PATHS_PLUGINS
              value: /var/lib/grafana/plugins
            - name: GF_PATHS_PROVISIONING
              value: /etc/grafana/provisioning
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
            initialDelaySeconds: 60
            timeoutSeconds: 30
          readinessProbe:
            httpGet:
              path: /api/health
              port: 3000
      volumes:
        - name: config
          configMap:
            name: kube-prometheus-stack-grafana
        - name: storage
          emptyDir: {}
        - name: sc-datasources-volume
          emptyDir:
            {}
---
# Source: kube-prometheus-stack/charts/kube-state-metrics/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kube-prometheus-stack-kube-state-metrics
  namespace: monitoring
  labels:    
    helm.sh/chart: kube-state-metrics-5.19.0
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "2.12.0"
    release: kube-prometheus-stack
spec:
  selector:
    matchLabels:      
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/instance: kube-prometheus-stack
  replicas: 1
  strategy:
    type: RollingUpdate
  revisionHistoryLimit: 10
  template:
    metadata:
      labels:        
        helm.sh/chart: kube-state-metrics-5.19.0
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: metrics
        app.kubernetes.io/part-of: kube-state-metrics
        app.kubernetes.io/name: kube-state-metrics
        app.kubernetes.io/instance: kube-prometheus-stack
        app.kubernetes.io/version: "2.12.0"
        release: kube-prometheus-stack
    spec:
      hostNetwork: false
      serviceAccountName: kube-prometheus-stack-kube-state-metrics
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: kube-state-metrics
        args:
        - --port=8080
        - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
        imagePullPolicy: IfNotPresent
        image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.12.0
        ports:
        - containerPort: 8080
          name: "http"
        livenessProbe:
          failureThreshold: 3
          httpGet:
            httpHeaders:
            path: /healthz
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        readinessProbe:
          failureThreshold: 3
          httpGet:
            httpHeaders:
            path: /
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
---
# Source: kube-prometheus-stack/templates/prometheus-operator/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kube-prometheus-stack-operator
  namespace: monitoring
  labels:
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
    app: kube-prometheus-stack-operator
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: kube-prometheus-stack-operator
      release: "kube-prometheus-stack"
  template:
    metadata:
      labels:
        
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: kube-prometheus-stack
        app.kubernetes.io/version: "58.5.0"
        app.kubernetes.io/part-of: kube-prometheus-stack
        chart: kube-prometheus-stack-58.5.0
        release: "kube-prometheus-stack"
        heritage: "Helm"
        app: kube-prometheus-stack-operator
        app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
        app.kubernetes.io/component: prometheus-operator
    spec:
      containers:
        - name: kube-prometheus-stack
          image: "quay.io/prometheus-operator/prometheus-operator:v0.73.2"
          imagePullPolicy: "IfNotPresent"
          args:
            - --kubelet-service=kube-system/kube-prometheus-stack-kubelet
            - --localhost=127.0.0.1
            - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.73.2
            - --config-reloader-cpu-request=0
            - --config-reloader-cpu-limit=0
            - --config-reloader-memory-request=0
            - --config-reloader-memory-limit=0
            - --thanos-default-base-image=quay.io/thanos/thanos:v0.35.0
            - --secret-field-selector=type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1
            - --web.enable-tls=true
            - --web.cert-file=/cert/cert
            - --web.key-file=/cert/key
            - --web.listen-address=:10250
            - --web.tls-min-version=VersionTLS13
          ports:
            - containerPort: 10250
              name: https
          env:
          - name: GOGC
            value: "30"
          resources:
            {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          volumeMounts:
            - name: tls-secret
              mountPath: /cert
              readOnly: true
      volumes:
        - name: tls-secret
          secret:
            defaultMode: 420
            secretName: kube-prometheus-stack-admission
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: kube-prometheus-stack-operator
      automountServiceAccountToken: true
---
# Source: kube-prometheus-stack/templates/alertmanager/alertmanager.yaml
apiVersion: monitoring.coreos.com/v1
kind: Alertmanager
metadata:
  name: kube-prometheus-stack-alertmanager
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-alertmanager
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  image: "quay.io/prometheus/alertmanager:v0.27.0"
  version: v0.27.0
  replicas: 1
  listenLocal: false
  serviceAccountName: kube-prometheus-stack-alertmanager
  automountServiceAccountToken: true
  externalUrl: http://kube-prometheus-stack-alertmanager.monitoring:9093
  paused: false
  logFormat: "logfmt"
  logLevel:  "info"
  retention: "120h"
  alertmanagerConfigSelector: {}
  alertmanagerConfigNamespaceSelector: {}
  routePrefix: "/"
  securityContext:
    fsGroup: 2000
    runAsGroup: 2000
    runAsNonRoot: true
    runAsUser: 1000
    seccompProfile:
      type: RuntimeDefault
  portName: http-web
---
# Source: kube-prometheus-stack/templates/prometheus-operator/admission-webhooks/mutatingWebhookConfiguration.yaml
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name:  kube-prometheus-stack-admission
  labels:
    app: kube-prometheus-stack-admission
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator-webhook
webhooks:
  - name: prometheusrulemutate.monitoring.coreos.com
    failurePolicy: Ignore
    rules:
      - apiGroups:
          - monitoring.coreos.com
        apiVersions:
          - "*"
        resources:
          - prometheusrules
        operations:
          - CREATE
          - UPDATE
    clientConfig:
      service:
        namespace: monitoring
        name: kube-prometheus-stack-operator
        path: /admission-prometheusrules/mutate
    timeoutSeconds: 10
    admissionReviewVersions: ["v1", "v1beta1"]
    sideEffects: None
---
# Source: kube-prometheus-stack/templates/prometheus/prometheus.yaml
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: kube-prometheus-stack-prometheus
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-prometheus
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  alerting:
    alertmanagers:
      - name: default
        namespace: monitoring
        port: web
  image: "quay.io/prometheus/prometheus:v2.52.0"
  version: v2.52.0
  additionalArgs:
    - --web.enable-lifecycle
    - --web.max-connections=512
    - --web.enable-admin-api
    - --storage.tsdb.max-block-duration=2h
    - --storage.tsdb.retention.time=7d
    - --scrape.sample-limit=100000
    - --scrape.body-size-limit=10MB
  externalUrl: http://kube-prometheus-stack-prometheus.monitoring:9090
  paused: false
  replicas: 1
  shards: 1
  logLevel:  info
  logFormat:  logfmt
  listenLocal: false
  enableAdminAPI: false
  resources:
    limits:
      cpu: 600m
      memory: 1Gi
    requests:
      cpu: 300m
      memory: 512Mi
  retention: "10d"
  tsdb:
    outOfOrderTimeWindow: 0s
  walCompression: true
  routePrefix: "/"
  serviceAccountName: kube-prometheus-stack-prometheus
  serviceMonitorSelector:
    matchLabels:
      release: "kube-prometheus-stack"

  serviceMonitorNamespaceSelector: {}
  podMonitorSelector:
    matchLabels:
      release: "kube-prometheus-stack"

  podMonitorNamespaceSelector: {}
  probeSelector:
    matchLabels:
      release: "kube-prometheus-stack"

  probeNamespaceSelector: {}
  securityContext:
    fsGroup: 2000
    runAsGroup: 2000
    runAsNonRoot: true
    runAsUser: 1000
    seccompProfile:
      type: RuntimeDefault
  ruleNamespaceSelector: {}
  ruleSelector:
    matchLabels:
      release: "kube-prometheus-stack"

  scrapeConfigSelector:
    matchLabels:
      release: "kube-prometheus-stack"

  scrapeConfigNamespaceSelector: {}
  portName: http-web
  hostNetwork: false
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/alertmanager.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-alertmanager.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: alertmanager.rules
    rules:
    - alert: AlertmanagerFailedReload
      annotations:
        description: Configuration has failed to load for {{ $labels.namespace }}/{{ $labels.pod}}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerfailedreload
        summary: Reloading an Alertmanager configuration has failed.
      expr: |-
        # Without max_over_time, failed scrapes could create false negatives, see
        # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
        max_over_time(alertmanager_config_last_reload_successful{job="kube-prometheus-stack-alertmanager",namespace="monitoring"}[5m]) == 0
      for: 10m
      labels:
        severity: critical
    - alert: AlertmanagerMembersInconsistent
      annotations:
        description: Alertmanager {{ $labels.namespace }}/{{ $labels.pod}} has only found {{ $value }} members of the {{$labels.job}} cluster.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagermembersinconsistent
        summary: A member of an Alertmanager cluster has not found all other cluster members.
      expr: |-
        # Without max_over_time, failed scrapes could create false negatives, see
        # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
          max_over_time(alertmanager_cluster_members{job="kube-prometheus-stack-alertmanager",namespace="monitoring"}[5m])
        < on (namespace,service,cluster) group_left
          count by (namespace,service,cluster) (max_over_time(alertmanager_cluster_members{job="kube-prometheus-stack-alertmanager",namespace="monitoring"}[5m]))
      for: 15m
      labels:
        severity: critical
    - alert: AlertmanagerFailedToSendAlerts
      annotations:
        description: Alertmanager {{ $labels.namespace }}/{{ $labels.pod}} failed to send {{ $value | humanizePercentage }} of notifications to {{ $labels.integration }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerfailedtosendalerts
        summary: An Alertmanager instance failed to send notifications.
      expr: |-
        (
          rate(alertmanager_notifications_failed_total{job="kube-prometheus-stack-alertmanager",namespace="monitoring"}[5m])
        /
          ignoring (reason) group_left rate(alertmanager_notifications_total{job="kube-prometheus-stack-alertmanager",namespace="monitoring"}[5m])
        )
        > 0.01
      for: 5m
      labels:
        severity: warning
    - alert: AlertmanagerClusterFailedToSendAlerts
      annotations:
        description: The minimum notification failure rate to {{ $labels.integration }} sent from any instance in the {{$labels.job}} cluster is {{ $value | humanizePercentage }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerclusterfailedtosendalerts
        summary: All Alertmanager instances in a cluster failed to send notifications to a critical integration.
      expr: |-
        min by (namespace,service, integration) (
          rate(alertmanager_notifications_failed_total{job="kube-prometheus-stack-alertmanager",namespace="monitoring", integration=~`.*`}[5m])
        /
          ignoring (reason) group_left rate(alertmanager_notifications_total{job="kube-prometheus-stack-alertmanager",namespace="monitoring", integration=~`.*`}[5m])
        )
        > 0.01
      for: 5m
      labels:
        severity: critical
    - alert: AlertmanagerClusterFailedToSendAlerts
      annotations:
        description: The minimum notification failure rate to {{ $labels.integration }} sent from any instance in the {{$labels.job}} cluster is {{ $value | humanizePercentage }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerclusterfailedtosendalerts
        summary: All Alertmanager instances in a cluster failed to send notifications to a non-critical integration.
      expr: |-
        min by (namespace,service, integration) (
          rate(alertmanager_notifications_failed_total{job="kube-prometheus-stack-alertmanager",namespace="monitoring", integration!~`.*`}[5m])
        /
          ignoring (reason) group_left rate(alertmanager_notifications_total{job="kube-prometheus-stack-alertmanager",namespace="monitoring", integration!~`.*`}[5m])
        )
        > 0.01
      for: 5m
      labels:
        severity: warning
    - alert: AlertmanagerConfigInconsistent
      annotations:
        description: Alertmanager instances within the {{$labels.job}} cluster have different configurations.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerconfiginconsistent
        summary: Alertmanager instances within the same cluster have different configurations.
      expr: |-
        count by (namespace,service,cluster) (
          count_values by (namespace,service,cluster) ("config_hash", alertmanager_config_hash{job="kube-prometheus-stack-alertmanager",namespace="monitoring"})
        )
        != 1
      for: 20m
      labels:
        severity: critical
    - alert: AlertmanagerClusterDown
      annotations:
        description: '{{ $value | humanizePercentage }} of Alertmanager instances within the {{$labels.job}} cluster have been up for less than half of the last 5m.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerclusterdown
        summary: Half or more of the Alertmanager instances within the same cluster are down.
      expr: |-
        (
          count by (namespace,service,cluster) (
            avg_over_time(up{job="kube-prometheus-stack-alertmanager",namespace="monitoring"}[5m]) < 0.5
          )
        /
          count by (namespace,service,cluster) (
            up{job="kube-prometheus-stack-alertmanager",namespace="monitoring"}
          )
        )
        >= 0.5
      for: 5m
      labels:
        severity: critical
    - alert: AlertmanagerClusterCrashlooping
      annotations:
        description: '{{ $value | humanizePercentage }} of Alertmanager instances within the {{$labels.job}} cluster have restarted at least 5 times in the last 10m.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerclustercrashlooping
        summary: Half or more of the Alertmanager instances within the same cluster are crashlooping.
      expr: |-
        (
          count by (namespace,service,cluster) (
            changes(process_start_time_seconds{job="kube-prometheus-stack-alertmanager",namespace="monitoring"}[10m]) > 4
          )
        /
          count by (namespace,service,cluster) (
            up{job="kube-prometheus-stack-alertmanager",namespace="monitoring"}
          )
        )
        >= 0.5
      for: 5m
      labels:
        severity: critical
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/config-reloaders.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-config-reloaders
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: config-reloaders
    rules:
    - alert: ConfigReloaderSidecarErrors
      annotations:
        description: 'Errors encountered while the {{$labels.pod}} config-reloader sidecar attempts to sync config in {{$labels.namespace}} namespace.

          As a result, configuration for service running in {{$labels.pod}} may be stale and cannot be updated anymore.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/configreloadersidecarerrors
        summary: config-reloader sidecar has not had a successful reload for 10m
      expr: max_over_time(reloader_last_reload_successful{namespace=~".+"}[5m]) == 0
      for: 10m
      labels:
        severity: warning
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/general.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-general.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: general.rules
    rules:
    - alert: TargetDown
      annotations:
        description: '{{ printf "%.4g" $value }}% of the {{ $labels.job }}/{{ $labels.service }} targets in {{ $labels.namespace }} namespace are down.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/general/targetdown
        summary: One or more targets are unreachable.
      expr: 100 * (count(up == 0) BY (cluster, job, namespace, service) / count(up) BY (cluster, job, namespace, service)) > 10
      for: 10m
      labels:
        severity: warning
    - alert: Watchdog
      annotations:
        description: 'This is an alert meant to ensure that the entire alerting pipeline is functional.

          This alert is always firing, therefore it should always be firing in Alertmanager

          and always fire against a receiver. There are integrations with various notification

          mechanisms that send a notification when this alert is not firing. For example the

          "DeadMansSnitch" integration in PagerDuty.

          '
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/general/watchdog
        summary: An alert that should always be firing to certify that Alertmanager is working properly.
      expr: vector(1)
      labels:
        severity: none
    - alert: InfoInhibitor
      annotations:
        description: 'This is an alert that is used to inhibit info alerts.

          By themselves, the info-level alerts are sometimes very noisy, but they are relevant when combined with

          other alerts.

          This alert fires whenever there''s a severity="info" alert, and stops firing when another alert with a

          severity of ''warning'' or ''critical'' starts firing on the same namespace.

          This alert should be routed to a null receiver and configured to inhibit alerts with severity="info".

          '
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/general/infoinhibitor
        summary: Info-level alert inhibition.
      expr: ALERTS{severity = "info"} == 1 unless on (namespace) ALERTS{alertname != "InfoInhibitor", severity =~ "warning|critical", alertstate="firing"} == 1
      labels:
        severity: none
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/k8s.rules.container_cpu_usage_seconds_total.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-k8s.rules.container-cpu-usage-seconds-tot
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: k8s.rules.container_cpu_usage_seconds_total
    rules:
    - expr: |-
        sum by (cluster, namespace, pod, container) (
          irate(container_cpu_usage_seconds_total{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}[5m])
        ) * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (
          1, max by (cluster, namespace, pod, node) (kube_pod_info{node!=""})
        )
      record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/k8s.rules.container_memory_cache.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-k8s.rules.container-memory-cache
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: k8s.rules.container_memory_cache
    rules:
    - expr: |-
        container_memory_cache{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
        * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (1,
          max by (cluster, namespace, pod, node) (kube_pod_info{node!=""})
        )
      record: node_namespace_pod_container:container_memory_cache
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/k8s.rules.container_memory_rss.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-k8s.rules.container-memory-rss
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: k8s.rules.container_memory_rss
    rules:
    - expr: |-
        container_memory_rss{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
        * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (1,
          max by (cluster, namespace, pod, node) (kube_pod_info{node!=""})
        )
      record: node_namespace_pod_container:container_memory_rss
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/k8s.rules.container_memory_swap.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-k8s.rules.container-memory-swap
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: k8s.rules.container_memory_swap
    rules:
    - expr: |-
        container_memory_swap{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
        * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (1,
          max by (cluster, namespace, pod, node) (kube_pod_info{node!=""})
        )
      record: node_namespace_pod_container:container_memory_swap
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/k8s.rules.container_memory_working_set_bytes.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-k8s.rules.container-memory-working-set-by
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: k8s.rules.container_memory_working_set_bytes
    rules:
    - expr: |-
        container_memory_working_set_bytes{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
        * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (1,
          max by (cluster, namespace, pod, node) (kube_pod_info{node!=""})
        )
      record: node_namespace_pod_container:container_memory_working_set_bytes
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/k8s.rules.container_resource.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-k8s.rules.container-resource
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: k8s.rules.container_resource
    rules:
    - expr: |-
        kube_pod_container_resource_requests{resource="memory",job="kube-state-metrics"}  * on (namespace, pod, cluster)
        group_left() max by (namespace, pod, cluster) (
          (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
        )
      record: cluster:namespace:pod_memory:active:kube_pod_container_resource_requests
    - expr: |-
        sum by (namespace, cluster) (
            sum by (namespace, pod, cluster) (
                max by (namespace, pod, container, cluster) (
                  kube_pod_container_resource_requests{resource="memory",job="kube-state-metrics"}
                ) * on (namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                  kube_pod_status_phase{phase=~"Pending|Running"} == 1
                )
            )
        )
      record: namespace_memory:kube_pod_container_resource_requests:sum
    - expr: |-
        kube_pod_container_resource_requests{resource="cpu",job="kube-state-metrics"}  * on (namespace, pod, cluster)
        group_left() max by (namespace, pod, cluster) (
          (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
        )
      record: cluster:namespace:pod_cpu:active:kube_pod_container_resource_requests
    - expr: |-
        sum by (namespace, cluster) (
            sum by (namespace, pod, cluster) (
                max by (namespace, pod, container, cluster) (
                  kube_pod_container_resource_requests{resource="cpu",job="kube-state-metrics"}
                ) * on (namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                  kube_pod_status_phase{phase=~"Pending|Running"} == 1
                )
            )
        )
      record: namespace_cpu:kube_pod_container_resource_requests:sum
    - expr: |-
        kube_pod_container_resource_limits{resource="memory",job="kube-state-metrics"}  * on (namespace, pod, cluster)
        group_left() max by (namespace, pod, cluster) (
          (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
        )
      record: cluster:namespace:pod_memory:active:kube_pod_container_resource_limits
    - expr: |-
        sum by (namespace, cluster) (
            sum by (namespace, pod, cluster) (
                max by (namespace, pod, container, cluster) (
                  kube_pod_container_resource_limits{resource="memory",job="kube-state-metrics"}
                ) * on (namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                  kube_pod_status_phase{phase=~"Pending|Running"} == 1
                )
            )
        )
      record: namespace_memory:kube_pod_container_resource_limits:sum
    - expr: |-
        kube_pod_container_resource_limits{resource="cpu",job="kube-state-metrics"}  * on (namespace, pod, cluster)
        group_left() max by (namespace, pod, cluster) (
         (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
         )
      record: cluster:namespace:pod_cpu:active:kube_pod_container_resource_limits
    - expr: |-
        sum by (namespace, cluster) (
            sum by (namespace, pod, cluster) (
                max by (namespace, pod, container, cluster) (
                  kube_pod_container_resource_limits{resource="cpu",job="kube-state-metrics"}
                ) * on (namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                  kube_pod_status_phase{phase=~"Pending|Running"} == 1
                )
            )
        )
      record: namespace_cpu:kube_pod_container_resource_limits:sum
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/k8s.rules.pod_owner.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-k8s.rules.pod-owner
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: k8s.rules.pod_owner
    rules:
    - expr: |-
        max by (cluster, namespace, workload, pod) (
          label_replace(
            label_replace(
              kube_pod_owner{job="kube-state-metrics", owner_kind="ReplicaSet"},
              "replicaset", "$1", "owner_name", "(.*)"
            ) * on (replicaset, namespace) group_left(owner_name) topk by (replicaset, namespace) (
              1, max by (replicaset, namespace, owner_name) (
                kube_replicaset_owner{job="kube-state-metrics"}
              )
            ),
            "workload", "$1", "owner_name", "(.*)"
          )
        )
      labels:
        workload_type: deployment
      record: namespace_workload_pod:kube_pod_owner:relabel
    - expr: |-
        max by (cluster, namespace, workload, pod) (
          label_replace(
            kube_pod_owner{job="kube-state-metrics", owner_kind="DaemonSet"},
            "workload", "$1", "owner_name", "(.*)"
          )
        )
      labels:
        workload_type: daemonset
      record: namespace_workload_pod:kube_pod_owner:relabel
    - expr: |-
        max by (cluster, namespace, workload, pod) (
          label_replace(
            kube_pod_owner{job="kube-state-metrics", owner_kind="StatefulSet"},
            "workload", "$1", "owner_name", "(.*)"
          )
        )
      labels:
        workload_type: statefulset
      record: namespace_workload_pod:kube_pod_owner:relabel
    - expr: |-
        max by (cluster, namespace, workload, pod) (
          label_replace(
            kube_pod_owner{job="kube-state-metrics", owner_kind="Job"},
            "workload", "$1", "owner_name", "(.*)"
          )
        )
      labels:
        workload_type: job
      record: namespace_workload_pod:kube_pod_owner:relabel
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kube-apiserver-availability.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kube-apiserver-availability.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - interval: 3m
    name: kube-apiserver-availability.rules
    rules:
    - expr: avg_over_time(code_verb:apiserver_request_total:increase1h[30d]) * 24 * 30
      record: code_verb:apiserver_request_total:increase30d
    - expr: sum by (cluster, code) (code_verb:apiserver_request_total:increase30d{verb=~"LIST|GET"})
      labels:
        verb: read
      record: code:apiserver_request_total:increase30d
    - expr: sum by (cluster, code) (code_verb:apiserver_request_total:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
      labels:
        verb: write
      record: code:apiserver_request_total:increase30d
    - expr: sum by (cluster, verb, scope) (increase(apiserver_request_sli_duration_seconds_count{job="apiserver"}[1h]))
      record: cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase1h
    - expr: sum by (cluster, verb, scope) (avg_over_time(cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase1h[30d]) * 24 * 30)
      record: cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase30d
    - expr: sum by (cluster, verb, scope, le) (increase(apiserver_request_sli_duration_seconds_bucket[1h]))
      record: cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase1h
    - expr: sum by (cluster, verb, scope, le) (avg_over_time(cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase1h[30d]) * 24 * 30)
      record: cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d
    - expr: |-
        1 - (
          (
            # write too slow
            sum by (cluster) (cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
            -
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"POST|PUT|PATCH|DELETE",le="1"})
          ) +
          (
            # read too slow
            sum by (cluster) (cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase30d{verb=~"LIST|GET"})
            -
            (
              (
                sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope=~"resource|",le="1"})
                or
                vector(0)
              )
              +
              sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="namespace",le="5"})
              +
              sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="cluster",le="30"})
            )
          ) +
          # errors
          sum by (cluster) (code:apiserver_request_total:increase30d{code=~"5.."} or vector(0))
        )
        /
        sum by (cluster) (code:apiserver_request_total:increase30d)
      labels:
        verb: all
      record: apiserver_request:availability30d
    - expr: |-
        1 - (
          sum by (cluster) (cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase30d{verb=~"LIST|GET"})
          -
          (
            # too slow
            (
              sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope=~"resource|",le="1"})
              or
              vector(0)
            )
            +
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="namespace",le="5"})
            +
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="cluster",le="30"})
          )
          +
          # errors
          sum by (cluster) (code:apiserver_request_total:increase30d{verb="read",code=~"5.."} or vector(0))
        )
        /
        sum by (cluster) (code:apiserver_request_total:increase30d{verb="read"})
      labels:
        verb: read
      record: apiserver_request:availability30d
    - expr: |-
        1 - (
          (
            # too slow
            sum by (cluster) (cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
            -
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~"POST|PUT|PATCH|DELETE",le="1"})
          )
          +
          # errors
          sum by (cluster) (code:apiserver_request_total:increase30d{verb="write",code=~"5.."} or vector(0))
        )
        /
        sum by (cluster) (code:apiserver_request_total:increase30d{verb="write"})
      labels:
        verb: write
      record: apiserver_request:availability30d
    - expr: sum by (cluster,code,resource) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[5m]))
      labels:
        verb: read
      record: code_resource:apiserver_request_total:rate5m
    - expr: sum by (cluster,code,resource) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
      labels:
        verb: write
      record: code_resource:apiserver_request_total:rate5m
    - expr: sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"2.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
    - expr: sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"3.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
    - expr: sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"4.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
    - expr: sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"5.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kube-apiserver-burnrate.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kube-apiserver-burnrate.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kube-apiserver-burnrate.rules
    rules:
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[1d]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[1d]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[1d]))
              +
              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[1d]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[1d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[1d]))
      labels:
        verb: read
      record: apiserver_request:burnrate1d
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[1h]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[1h]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[1h]))
              +
              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[1h]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[1h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[1h]))
      labels:
        verb: read
      record: apiserver_request:burnrate1h
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[2h]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[2h]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[2h]))
              +
              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[2h]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[2h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[2h]))
      labels:
        verb: read
      record: apiserver_request:burnrate2h
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[30m]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[30m]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[30m]))
              +
              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[30m]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[30m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[30m]))
      labels:
        verb: read
      record: apiserver_request:burnrate30m
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[3d]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[3d]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[3d]))
              +
              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[3d]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[3d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[3d]))
      labels:
        verb: read
      record: apiserver_request:burnrate3d
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[5m]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[5m]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[5m]))
              +
              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[5m]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[5m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[5m]))
      labels:
        verb: read
      record: apiserver_request:burnrate5m
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[6h]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[6h]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[6h]))
              +
              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[6h]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[6h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[6h]))
      labels:
        verb: read
      record: apiserver_request:burnrate6h
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[1d]))
            -
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[1d]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[1d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1d]))
      labels:
        verb: write
      record: apiserver_request:burnrate1d
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[1h]))
            -
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[1h]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[1h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1h]))
      labels:
        verb: write
      record: apiserver_request:burnrate1h
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[2h]))
            -
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[2h]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[2h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[2h]))
      labels:
        verb: write
      record: apiserver_request:burnrate2h
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[30m]))
            -
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[30m]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[30m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[30m]))
      labels:
        verb: write
      record: apiserver_request:burnrate30m
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[3d]))
            -
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[3d]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[3d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[3d]))
      labels:
        verb: write
      record: apiserver_request:burnrate3d
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[5m]))
            -
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[5m]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[5m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
      labels:
        verb: write
      record: apiserver_request:burnrate5m
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[6h]))
            -
            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[6h]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[6h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[6h]))
      labels:
        verb: write
      record: apiserver_request:burnrate6h
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kube-apiserver-histogram.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kube-apiserver-histogram.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kube-apiserver-histogram.rules
    rules:
    - expr: histogram_quantile(0.99, sum by (cluster, le, resource) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[5m]))) > 0
      labels:
        quantile: '0.99'
        verb: read
      record: cluster_quantile:apiserver_request_sli_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.99, sum by (cluster, le, resource) (rate(apiserver_request_sli_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[5m]))) > 0
      labels:
        quantile: '0.99'
        verb: write
      record: cluster_quantile:apiserver_request_sli_duration_seconds:histogram_quantile
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kube-apiserver-slos.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kube-apiserver-slos
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kube-apiserver-slos
    rules:
    - alert: KubeAPIErrorBudgetBurn
      annotations:
        description: The API server is burning too much error budget.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeapierrorbudgetburn
        summary: The API server is burning too much error budget.
      expr: |-
        sum(apiserver_request:burnrate1h) > (14.40 * 0.01000)
        and
        sum(apiserver_request:burnrate5m) > (14.40 * 0.01000)
      for: 2m
      labels:
        long: 1h
        severity: critical
        short: 5m
    - alert: KubeAPIErrorBudgetBurn
      annotations:
        description: The API server is burning too much error budget.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeapierrorbudgetburn
        summary: The API server is burning too much error budget.
      expr: |-
        sum(apiserver_request:burnrate6h) > (6.00 * 0.01000)
        and
        sum(apiserver_request:burnrate30m) > (6.00 * 0.01000)
      for: 15m
      labels:
        long: 6h
        severity: critical
        short: 30m
    - alert: KubeAPIErrorBudgetBurn
      annotations:
        description: The API server is burning too much error budget.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeapierrorbudgetburn
        summary: The API server is burning too much error budget.
      expr: |-
        sum(apiserver_request:burnrate1d) > (3.00 * 0.01000)
        and
        sum(apiserver_request:burnrate2h) > (3.00 * 0.01000)
      for: 1h
      labels:
        long: 1d
        severity: warning
        short: 2h
    - alert: KubeAPIErrorBudgetBurn
      annotations:
        description: The API server is burning too much error budget.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeapierrorbudgetburn
        summary: The API server is burning too much error budget.
      expr: |-
        sum(apiserver_request:burnrate3d) > (1.00 * 0.01000)
        and
        sum(apiserver_request:burnrate6h) > (1.00 * 0.01000)
      for: 3h
      labels:
        long: 3d
        severity: warning
        short: 6h
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kube-prometheus-general.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kube-prometheus-general.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kube-prometheus-general.rules
    rules:
    - expr: count without(instance, pod, node) (up == 1)
      record: count:up1
    - expr: count without(instance, pod, node) (up == 0)
      record: count:up0
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kube-prometheus-node-recording.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kube-prometheus-node-recording.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kube-prometheus-node-recording.rules
    rules:
    - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait",mode!="steal"}[3m])) BY (instance)
      record: instance:node_cpu:rate:sum
    - expr: sum(rate(node_network_receive_bytes_total[3m])) BY (instance)
      record: instance:node_network_receive_bytes:rate:sum
    - expr: sum(rate(node_network_transmit_bytes_total[3m])) BY (instance)
      record: instance:node_network_transmit_bytes:rate:sum
    - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait",mode!="steal"}[5m])) WITHOUT (cpu, mode) / ON(instance) GROUP_LEFT() count(sum(node_cpu_seconds_total) BY (instance, cpu)) BY (instance)
      record: instance:node_cpu:ratio
    - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait",mode!="steal"}[5m]))
      record: cluster:node_cpu:sum_rate5m
    - expr: cluster:node_cpu:sum_rate5m / count(sum(node_cpu_seconds_total) BY (instance, cpu))
      record: cluster:node_cpu:ratio
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kube-scheduler.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kube-scheduler.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kube-scheduler.rules
    rules:
    - expr: histogram_quantile(0.99, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.99'
      record: cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.99, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.99'
      record: cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.99, sum(rate(scheduler_binding_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.99'
      record: cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.9, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.9'
      record: cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.9, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.9'
      record: cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.9, sum(rate(scheduler_binding_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.9'
      record: cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.5, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.5'
      record: cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.5, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.5'
      record: cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.5, sum(rate(scheduler_binding_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.5'
      record: cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kube-state-metrics.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kube-state-metrics
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kube-state-metrics
    rules:
    - alert: KubeStateMetricsListErrors
      annotations:
        description: kube-state-metrics is experiencing errors at an elevated rate in list operations. This is likely causing it to not be able to expose metrics about Kubernetes objects correctly or at all.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kube-state-metrics/kubestatemetricslisterrors
        summary: kube-state-metrics is experiencing errors in list operations.
      expr: |-
        (sum(rate(kube_state_metrics_list_total{job="kube-state-metrics",result="error"}[5m])) by (cluster)
          /
        sum(rate(kube_state_metrics_list_total{job="kube-state-metrics"}[5m])) by (cluster))
        > 0.01
      for: 15m
      labels:
        severity: critical
    - alert: KubeStateMetricsWatchErrors
      annotations:
        description: kube-state-metrics is experiencing errors at an elevated rate in watch operations. This is likely causing it to not be able to expose metrics about Kubernetes objects correctly or at all.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kube-state-metrics/kubestatemetricswatcherrors
        summary: kube-state-metrics is experiencing errors in watch operations.
      expr: |-
        (sum(rate(kube_state_metrics_watch_total{job="kube-state-metrics",result="error"}[5m])) by (cluster)
          /
        sum(rate(kube_state_metrics_watch_total{job="kube-state-metrics"}[5m])) by (cluster))
        > 0.01
      for: 15m
      labels:
        severity: critical
    - alert: KubeStateMetricsShardingMismatch
      annotations:
        description: kube-state-metrics pods are running with different --total-shards configuration, some Kubernetes objects may be exposed multiple times or not exposed at all.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kube-state-metrics/kubestatemetricsshardingmismatch
        summary: kube-state-metrics sharding is misconfigured.
      expr: stdvar (kube_state_metrics_total_shards{job="kube-state-metrics"}) by (cluster) != 0
      for: 15m
      labels:
        severity: critical
    - alert: KubeStateMetricsShardsMissing
      annotations:
        description: kube-state-metrics shards are missing, some Kubernetes objects are not being exposed.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kube-state-metrics/kubestatemetricsshardsmissing
        summary: kube-state-metrics shards are missing.
      expr: |-
        2^max(kube_state_metrics_total_shards{job="kube-state-metrics"}) by (cluster) - 1
          -
        sum( 2 ^ max by (cluster, shard_ordinal) (kube_state_metrics_shard_ordinal{job="kube-state-metrics"}) ) by (cluster)
        != 0
      for: 15m
      labels:
        severity: critical
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kubelet.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kubelet.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kubelet.rules
    rules:
    - expr: histogram_quantile(0.99, sum(rate(kubelet_pleg_relist_duration_seconds_bucket{job="kubelet", metrics_path="/metrics"}[5m])) by (cluster, instance, le) * on (cluster, instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"})
      labels:
        quantile: '0.99'
      record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.9, sum(rate(kubelet_pleg_relist_duration_seconds_bucket{job="kubelet", metrics_path="/metrics"}[5m])) by (cluster, instance, le) * on (cluster, instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"})
      labels:
        quantile: '0.9'
      record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.5, sum(rate(kubelet_pleg_relist_duration_seconds_bucket{job="kubelet", metrics_path="/metrics"}[5m])) by (cluster, instance, le) * on (cluster, instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"})
      labels:
        quantile: '0.5'
      record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-apps.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kubernetes-apps
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-apps
    rules:
    - alert: KubePodCrashLooping
      annotations:
        description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is in waiting state (reason: "CrashLoopBackOff").'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepodcrashlooping
        summary: Pod is crash looping.
      expr: max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job="kube-state-metrics", namespace=~".*"}[5m]) >= 1
      for: 15m
      labels:
        severity: warning
    - alert: KubePodNotReady
      annotations:
        description: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepodnotready
        summary: Pod has been in a non-ready state for more than 15 minutes.
      expr: |-
        sum by (namespace, pod, cluster) (
          max by (namespace, pod, cluster) (
            kube_pod_status_phase{job="kube-state-metrics", namespace=~".*", phase=~"Pending|Unknown|Failed"}
          ) * on (namespace, pod, cluster) group_left(owner_kind) topk by (namespace, pod, cluster) (
            1, max by (namespace, pod, owner_kind, cluster) (kube_pod_owner{owner_kind!="Job"})
          )
        ) > 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeDeploymentGenerationMismatch
      annotations:
        description: Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment }} does not match, this indicates that the Deployment has failed but has not been rolled back.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedeploymentgenerationmismatch
        summary: Deployment generation mismatch due to possible roll-back
      expr: |-
        kube_deployment_status_observed_generation{job="kube-state-metrics", namespace=~".*"}
          !=
        kube_deployment_metadata_generation{job="kube-state-metrics", namespace=~".*"}
      for: 15m
      labels:
        severity: warning
    - alert: KubeDeploymentReplicasMismatch
      annotations:
        description: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas for longer than 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedeploymentreplicasmismatch
        summary: Deployment has not matched the expected number of replicas.
      expr: |-
        (
          kube_deployment_spec_replicas{job="kube-state-metrics", namespace=~".*"}
            >
          kube_deployment_status_replicas_available{job="kube-state-metrics", namespace=~".*"}
        ) and (
          changes(kube_deployment_status_replicas_updated{job="kube-state-metrics", namespace=~".*"}[10m])
            ==
          0
        )
      for: 15m
      labels:
        severity: warning
    - alert: KubeDeploymentRolloutStuck
      annotations:
        description: Rollout of deployment {{ $labels.namespace }}/{{ $labels.deployment }} is not progressing for longer than 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedeploymentrolloutstuck
        summary: Deployment rollout is not progressing.
      expr: |-
        kube_deployment_status_condition{condition="Progressing", status="false",job="kube-state-metrics", namespace=~".*"}
        != 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeStatefulSetReplicasMismatch
      annotations:
        description: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has not matched the expected number of replicas for longer than 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubestatefulsetreplicasmismatch
        summary: StatefulSet has not matched the expected number of replicas.
      expr: |-
        (
          kube_statefulset_status_replicas_ready{job="kube-state-metrics", namespace=~".*"}
            !=
          kube_statefulset_status_replicas{job="kube-state-metrics", namespace=~".*"}
        ) and (
          changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics", namespace=~".*"}[10m])
            ==
          0
        )
      for: 15m
      labels:
        severity: warning
    - alert: KubeStatefulSetGenerationMismatch
      annotations:
        description: StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset }} does not match, this indicates that the StatefulSet has failed but has not been rolled back.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubestatefulsetgenerationmismatch
        summary: StatefulSet generation mismatch due to possible roll-back
      expr: |-
        kube_statefulset_status_observed_generation{job="kube-state-metrics", namespace=~".*"}
          !=
        kube_statefulset_metadata_generation{job="kube-state-metrics", namespace=~".*"}
      for: 15m
      labels:
        severity: warning
    - alert: KubeStatefulSetUpdateNotRolledOut
      annotations:
        description: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update has not been rolled out.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubestatefulsetupdatenotrolledout
        summary: StatefulSet update has not been rolled out.
      expr: |-
        (
          max without (revision) (
            kube_statefulset_status_current_revision{job="kube-state-metrics", namespace=~".*"}
              unless
            kube_statefulset_status_update_revision{job="kube-state-metrics", namespace=~".*"}
          )
            *
          (
            kube_statefulset_replicas{job="kube-state-metrics", namespace=~".*"}
              !=
            kube_statefulset_status_replicas_updated{job="kube-state-metrics", namespace=~".*"}
          )
        )  and (
          changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics", namespace=~".*"}[5m])
            ==
          0
        )
      for: 15m
      labels:
        severity: warning
    - alert: KubeDaemonSetRolloutStuck
      annotations:
        description: DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} has not finished or progressed for at least 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedaemonsetrolloutstuck
        summary: DaemonSet rollout is stuck.
      expr: |-
        (
          (
            kube_daemonset_status_current_number_scheduled{job="kube-state-metrics", namespace=~".*"}
             !=
            kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics", namespace=~".*"}
          ) or (
            kube_daemonset_status_number_misscheduled{job="kube-state-metrics", namespace=~".*"}
             !=
            0
          ) or (
            kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics", namespace=~".*"}
             !=
            kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics", namespace=~".*"}
          ) or (
            kube_daemonset_status_number_available{job="kube-state-metrics", namespace=~".*"}
             !=
            kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics", namespace=~".*"}
          )
        ) and (
          changes(kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics", namespace=~".*"}[5m])
            ==
          0
        )
      for: 15m
      labels:
        severity: warning
    - alert: KubeContainerWaiting
      annotations:
        description: pod/{{ $labels.pod }} in namespace {{ $labels.namespace }} on container {{ $labels.container}} has been in waiting state for longer than 1 hour.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubecontainerwaiting
        summary: Pod container waiting longer than 1 hour
      expr: sum by (namespace, pod, container, cluster) (kube_pod_container_status_waiting_reason{job="kube-state-metrics", namespace=~".*"}) > 0
      for: 1h
      labels:
        severity: warning
    - alert: KubeDaemonSetNotScheduled
      annotations:
        description: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedaemonsetnotscheduled
        summary: DaemonSet pods are not scheduled.
      expr: |-
        kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics", namespace=~".*"}
          -
        kube_daemonset_status_current_number_scheduled{job="kube-state-metrics", namespace=~".*"} > 0
      for: 10m
      labels:
        severity: warning
    - alert: KubeDaemonSetMisScheduled
      annotations:
        description: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are running where they are not supposed to run.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedaemonsetmisscheduled
        summary: DaemonSet pods are misscheduled.
      expr: kube_daemonset_status_number_misscheduled{job="kube-state-metrics", namespace=~".*"} > 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeJobNotCompleted
      annotations:
        description: Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more than {{ "43200" | humanizeDuration }} to complete.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubejobnotcompleted
        summary: Job did not complete in time
      expr: |-
        time() - max by (namespace, job_name, cluster) (kube_job_status_start_time{job="kube-state-metrics", namespace=~".*"}
          and
        kube_job_status_active{job="kube-state-metrics", namespace=~".*"} > 0) > 43200
      labels:
        severity: warning
    - alert: KubeJobFailed
      annotations:
        description: Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete. Removing failed job after investigation should clear this alert.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubejobfailed
        summary: Job failed to complete.
      expr: kube_job_failed{job="kube-state-metrics", namespace=~".*"}  > 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeHpaReplicasMismatch
      annotations:
        description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has not matched the desired number of replicas for longer than 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubehpareplicasmismatch
        summary: HPA has not matched desired number of replicas.
      expr: |-
        (kube_horizontalpodautoscaler_status_desired_replicas{job="kube-state-metrics", namespace=~".*"}
          !=
        kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics", namespace=~".*"})
          and
        (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics", namespace=~".*"}
          >
        kube_horizontalpodautoscaler_spec_min_replicas{job="kube-state-metrics", namespace=~".*"})
          and
        (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics", namespace=~".*"}
          <
        kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics", namespace=~".*"})
          and
        changes(kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics", namespace=~".*"}[15m]) == 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeHpaMaxedOut
      annotations:
        description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has been running at max replicas for longer than 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubehpamaxedout
        summary: HPA is running at max replicas
      expr: |-
        kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics", namespace=~".*"}
          ==
        kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics", namespace=~".*"}
      for: 15m
      labels:
        severity: warning
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-resources.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kubernetes-resources
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-resources
    rules:
    - alert: KubeCPUOvercommit
      annotations:
        description: Cluster {{ $labels.cluster }} has overcommitted CPU resource requests for Pods by {{ $value }} CPU shares and cannot tolerate node failure.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubecpuovercommit
        summary: Cluster has overcommitted CPU resource requests.
      expr: |-
        sum(namespace_cpu:kube_pod_container_resource_requests:sum{job="kube-state-metrics",}) by (cluster) - (sum(kube_node_status_allocatable{job="kube-state-metrics",resource="cpu"}) by (cluster) - max(kube_node_status_allocatable{job="kube-state-metrics",resource="cpu"}) by (cluster)) > 0
        and
        (sum(kube_node_status_allocatable{job="kube-state-metrics",resource="cpu"}) by (cluster) - max(kube_node_status_allocatable{job="kube-state-metrics",resource="cpu"}) by (cluster)) > 0
      for: 10m
      labels:
        severity: warning
    - alert: KubeMemoryOvercommit
      annotations:
        description: Cluster {{ $labels.cluster }} has overcommitted memory resource requests for Pods by {{ $value | humanize }} bytes and cannot tolerate node failure.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubememoryovercommit
        summary: Cluster has overcommitted memory resource requests.
      expr: |-
        sum(namespace_memory:kube_pod_container_resource_requests:sum{}) by (cluster) - (sum(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"}) by (cluster) - max(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"}) by (cluster)) > 0
        and
        (sum(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"}) by (cluster) - max(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"}) by (cluster)) > 0
      for: 10m
      labels:
        severity: warning
    - alert: KubeCPUQuotaOvercommit
      annotations:
        description: Cluster {{ $labels.cluster }}  has overcommitted CPU resource requests for Namespaces.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubecpuquotaovercommit
        summary: Cluster has overcommitted CPU resource requests.
      expr: |-
        sum(min without(resource) (kube_resourcequota{job="kube-state-metrics", type="hard", resource=~"(cpu|requests.cpu)"})) by (cluster)
          /
        sum(kube_node_status_allocatable{resource="cpu", job="kube-state-metrics"}) by (cluster)
          > 1.5
      for: 5m
      labels:
        severity: warning
    - alert: KubeMemoryQuotaOvercommit
      annotations:
        description: Cluster {{ $labels.cluster }}  has overcommitted memory resource requests for Namespaces.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubememoryquotaovercommit
        summary: Cluster has overcommitted memory resource requests.
      expr: |-
        sum(min without(resource) (kube_resourcequota{job="kube-state-metrics", type="hard", resource=~"(memory|requests.memory)"})) by (cluster)
          /
        sum(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"}) by (cluster)
          > 1.5
      for: 5m
      labels:
        severity: warning
    - alert: KubeQuotaAlmostFull
      annotations:
        description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubequotaalmostfull
        summary: Namespace quota is going to be full.
      expr: |-
        kube_resourcequota{job="kube-state-metrics", type="used"}
          / ignoring(instance, job, type)
        (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)
          > 0.9 < 1
      for: 15m
      labels:
        severity: info
    - alert: KubeQuotaFullyUsed
      annotations:
        description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubequotafullyused
        summary: Namespace quota is fully used.
      expr: |-
        kube_resourcequota{job="kube-state-metrics", type="used"}
          / ignoring(instance, job, type)
        (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)
          == 1
      for: 15m
      labels:
        severity: info
    - alert: KubeQuotaExceeded
      annotations:
        description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubequotaexceeded
        summary: Namespace quota has exceeded the limits.
      expr: |-
        kube_resourcequota{job="kube-state-metrics", type="used"}
          / ignoring(instance, job, type)
        (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)
          > 1
      for: 15m
      labels:
        severity: warning
    - alert: CPUThrottlingHigh
      annotations:
        description: '{{ $value | humanizePercentage }} throttling of CPU in namespace {{ $labels.namespace }} for container {{ $labels.container }} in pod {{ $labels.pod }}.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/cputhrottlinghigh
        summary: Processes experience elevated CPU throttling.
      expr: |-
        sum(increase(container_cpu_cfs_throttled_periods_total{container!="", }[5m])) by (cluster, container, pod, namespace)
          /
        sum(increase(container_cpu_cfs_periods_total{}[5m])) by (cluster, container, pod, namespace)
          > ( 25 / 100 )
      for: 15m
      labels:
        severity: info
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-storage.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kubernetes-storage
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-storage
    rules:
    - alert: KubePersistentVolumeFillingUp
      annotations:
        description: The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} is only {{ $value | humanizePercentage }} free.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumefillingup
        summary: PersistentVolume is filling up.
      expr: |-
        (
          kubelet_volume_stats_available_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"}
            /
          kubelet_volume_stats_capacity_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"}
        ) < 0.03
        and
        kubelet_volume_stats_used_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"} > 0
        unless on (cluster, namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
        unless on (cluster, namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
      for: 1m
      labels:
        severity: critical
    - alert: KubePersistentVolumeFillingUp
      annotations:
        description: Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} is expected to fill up within four days. Currently {{ $value | humanizePercentage }} is available.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumefillingup
        summary: PersistentVolume is filling up.
      expr: |-
        (
          kubelet_volume_stats_available_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"}
            /
          kubelet_volume_stats_capacity_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"}
        ) < 0.15
        and
        kubelet_volume_stats_used_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"} > 0
        and
        predict_linear(kubelet_volume_stats_available_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"}[6h], 4 * 24 * 3600) < 0
        unless on (cluster, namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
        unless on (cluster, namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
      for: 1h
      labels:
        severity: warning
    - alert: KubePersistentVolumeInodesFillingUp
      annotations:
        description: The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} only has {{ $value | humanizePercentage }} free inodes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumeinodesfillingup
        summary: PersistentVolumeInodes are filling up.
      expr: |-
        (
          kubelet_volume_stats_inodes_free{job="kubelet", namespace=~".*", metrics_path="/metrics"}
            /
          kubelet_volume_stats_inodes{job="kubelet", namespace=~".*", metrics_path="/metrics"}
        ) < 0.03
        and
        kubelet_volume_stats_inodes_used{job="kubelet", namespace=~".*", metrics_path="/metrics"} > 0
        unless on (cluster, namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
        unless on (cluster, namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
      for: 1m
      labels:
        severity: critical
    - alert: KubePersistentVolumeInodesFillingUp
      annotations:
        description: Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} is expected to run out of inodes within four days. Currently {{ $value | humanizePercentage }} of its inodes are free.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumeinodesfillingup
        summary: PersistentVolumeInodes are filling up.
      expr: |-
        (
          kubelet_volume_stats_inodes_free{job="kubelet", namespace=~".*", metrics_path="/metrics"}
            /
          kubelet_volume_stats_inodes{job="kubelet", namespace=~".*", metrics_path="/metrics"}
        ) < 0.15
        and
        kubelet_volume_stats_inodes_used{job="kubelet", namespace=~".*", metrics_path="/metrics"} > 0
        and
        predict_linear(kubelet_volume_stats_inodes_free{job="kubelet", namespace=~".*", metrics_path="/metrics"}[6h], 4 * 24 * 3600) < 0
        unless on (cluster, namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
        unless on (cluster, namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
      for: 1h
      labels:
        severity: warning
    - alert: KubePersistentVolumeErrors
      annotations:
        description: The persistent volume {{ $labels.persistentvolume }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} has status {{ $labels.phase }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumeerrors
        summary: PersistentVolume is having issues with provisioning.
      expr: kube_persistentvolume_status_phase{phase=~"Failed|Pending",job="kube-state-metrics"} > 0
      for: 5m
      labels:
        severity: critical
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-system-apiserver.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kubernetes-system-apiserver
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-system-apiserver
    rules:
    - alert: KubeClientCertificateExpiration
      annotations:
        description: A client certificate used to authenticate to kubernetes apiserver is expiring in less than 7.0 days.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeclientcertificateexpiration
        summary: Client certificate is about to expire.
      expr: apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and on (job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 604800
      for: 5m
      labels:
        severity: warning
    - alert: KubeClientCertificateExpiration
      annotations:
        description: A client certificate used to authenticate to kubernetes apiserver is expiring in less than 24.0 hours.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeclientcertificateexpiration
        summary: Client certificate is about to expire.
      expr: apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and on (job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 86400
      for: 5m
      labels:
        severity: critical
    - alert: KubeAggregatedAPIErrors
      annotations:
        description: Kubernetes aggregated API {{ $labels.name }}/{{ $labels.namespace }} has reported errors. It has appeared unavailable {{ $value | humanize }} times averaged over the past 10m.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeaggregatedapierrors
        summary: Kubernetes aggregated API has reported errors.
      expr: sum by (name, namespace, cluster)(increase(aggregator_unavailable_apiservice_total{job="apiserver"}[10m])) > 4
      labels:
        severity: warning
    - alert: KubeAggregatedAPIDown
      annotations:
        description: Kubernetes aggregated API {{ $labels.name }}/{{ $labels.namespace }} has been only {{ $value | humanize }}% available over the last 10m.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeaggregatedapidown
        summary: Kubernetes aggregated API is down.
      expr: (1 - max by (name, namespace, cluster)(avg_over_time(aggregator_unavailable_apiservice{job="apiserver"}[10m]))) * 100 < 85
      for: 5m
      labels:
        severity: warning
    - alert: KubeAPIDown
      annotations:
        description: KubeAPI has disappeared from Prometheus target discovery.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeapidown
        summary: Target disappeared from Prometheus target discovery.
      expr: absent(up{job="apiserver"} == 1)
      for: 15m
      labels:
        severity: critical
    - alert: KubeAPITerminatedRequests
      annotations:
        description: The kubernetes apiserver has terminated {{ $value | humanizePercentage }} of its incoming requests.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeapiterminatedrequests
        summary: The kubernetes apiserver has terminated {{ $value | humanizePercentage }} of its incoming requests.
      expr: sum(rate(apiserver_request_terminations_total{job="apiserver"}[10m]))  / (  sum(rate(apiserver_request_total{job="apiserver"}[10m])) + sum(rate(apiserver_request_terminations_total{job="apiserver"}[10m])) ) > 0.20
      for: 5m
      labels:
        severity: warning
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-system-controller-manager.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kubernetes-system-controller-manager
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-system-controller-manager
    rules:
    - alert: KubeControllerManagerDown
      annotations:
        description: KubeControllerManager has disappeared from Prometheus target discovery.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubecontrollermanagerdown
        summary: Target disappeared from Prometheus target discovery.
      expr: absent(up{job="kube-controller-manager"} == 1)
      for: 15m
      labels:
        severity: critical
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-system-kube-proxy.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kubernetes-system-kube-proxy
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-system-kube-proxy
    rules:
    - alert: KubeProxyDown
      annotations:
        description: KubeProxy has disappeared from Prometheus target discovery.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeproxydown
        summary: Target disappeared from Prometheus target discovery.
      expr: absent(up{job="kube-proxy"} == 1)
      for: 15m
      labels:
        severity: critical
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-system-kubelet.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kubernetes-system-kubelet
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-system-kubelet
    rules:
    - alert: KubeNodeNotReady
      annotations:
        description: '{{ $labels.node }} has been unready for more than 15 minutes.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubenodenotready
        summary: Node is not ready.
      expr: kube_node_status_condition{job="kube-state-metrics",condition="Ready",status="true"} == 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeNodeUnreachable
      annotations:
        description: '{{ $labels.node }} is unreachable and some workloads may be rescheduled.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubenodeunreachable
        summary: Node is unreachable.
      expr: (kube_node_spec_taint{job="kube-state-metrics",key="node.kubernetes.io/unreachable",effect="NoSchedule"} unless ignoring(key,value) kube_node_spec_taint{job="kube-state-metrics",key=~"ToBeDeletedByClusterAutoscaler|cloud.google.com/impending-node-termination|aws-node-termination-handler/spot-itn"}) == 1
      for: 15m
      labels:
        severity: warning
    - alert: KubeletTooManyPods
      annotations:
        description: Kubelet '{{ $labels.node }}' is running at {{ $value | humanizePercentage }} of its Pod capacity.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubelettoomanypods
        summary: Kubelet is running at capacity.
      expr: |-
        count by (cluster, node) (
          (kube_pod_status_phase{job="kube-state-metrics",phase="Running"} == 1) * on (instance,pod,namespace,cluster) group_left(node) topk by (instance,pod,namespace,cluster) (1, kube_pod_info{job="kube-state-metrics"})
        )
        /
        max by (cluster, node) (
          kube_node_status_capacity{job="kube-state-metrics",resource="pods"} != 1
        ) > 0.95
      for: 15m
      labels:
        severity: info
    - alert: KubeNodeReadinessFlapping
      annotations:
        description: The readiness status of node {{ $labels.node }} has changed {{ $value }} times in the last 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubenodereadinessflapping
        summary: Node readiness status is flapping.
      expr: sum(changes(kube_node_status_condition{job="kube-state-metrics",status="true",condition="Ready"}[15m])) by (cluster, node) > 2
      for: 15m
      labels:
        severity: warning
    - alert: KubeletPlegDurationHigh
      annotations:
        description: The Kubelet Pod Lifecycle Event Generator has a 99th percentile duration of {{ $value }} seconds on node {{ $labels.node }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletplegdurationhigh
        summary: Kubelet Pod Lifecycle Event Generator is taking too long to relist.
      expr: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile{quantile="0.99"} >= 10
      for: 5m
      labels:
        severity: warning
    - alert: KubeletPodStartUpLatencyHigh
      annotations:
        description: Kubelet Pod startup 99th percentile latency is {{ $value }} seconds on node {{ $labels.node }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletpodstartuplatencyhigh
        summary: Kubelet Pod startup latency is too high.
      expr: histogram_quantile(0.99, sum(rate(kubelet_pod_worker_duration_seconds_bucket{job="kubelet", metrics_path="/metrics"}[5m])) by (cluster, instance, le)) * on (cluster, instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"} > 60
      for: 15m
      labels:
        severity: warning
    - alert: KubeletClientCertificateExpiration
      annotations:
        description: Client certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletclientcertificateexpiration
        summary: Kubelet client certificate is about to expire.
      expr: kubelet_certificate_manager_client_ttl_seconds < 604800
      labels:
        severity: warning
    - alert: KubeletClientCertificateExpiration
      annotations:
        description: Client certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletclientcertificateexpiration
        summary: Kubelet client certificate is about to expire.
      expr: kubelet_certificate_manager_client_ttl_seconds < 86400
      labels:
        severity: critical
    - alert: KubeletServerCertificateExpiration
      annotations:
        description: Server certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletservercertificateexpiration
        summary: Kubelet server certificate is about to expire.
      expr: kubelet_certificate_manager_server_ttl_seconds < 604800
      labels:
        severity: warning
    - alert: KubeletServerCertificateExpiration
      annotations:
        description: Server certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletservercertificateexpiration
        summary: Kubelet server certificate is about to expire.
      expr: kubelet_certificate_manager_server_ttl_seconds < 86400
      labels:
        severity: critical
    - alert: KubeletClientCertificateRenewalErrors
      annotations:
        description: Kubelet on node {{ $labels.node }} has failed to renew its client certificate ({{ $value | humanize }} errors in the last 5 minutes).
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletclientcertificaterenewalerrors
        summary: Kubelet has failed to renew its client certificate.
      expr: increase(kubelet_certificate_manager_client_expiration_renew_errors[5m]) > 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeletServerCertificateRenewalErrors
      annotations:
        description: Kubelet on node {{ $labels.node }} has failed to renew its server certificate ({{ $value | humanize }} errors in the last 5 minutes).
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletservercertificaterenewalerrors
        summary: Kubelet has failed to renew its server certificate.
      expr: increase(kubelet_server_expiration_renew_errors[5m]) > 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeletDown
      annotations:
        description: Kubelet has disappeared from Prometheus target discovery.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletdown
        summary: Target disappeared from Prometheus target discovery.
      expr: absent(up{job="kubelet", metrics_path="/metrics"} == 1)
      for: 15m
      labels:
        severity: critical
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-system-scheduler.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kubernetes-system-scheduler
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-system-scheduler
    rules:
    - alert: KubeSchedulerDown
      annotations:
        description: KubeScheduler has disappeared from Prometheus target discovery.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeschedulerdown
        summary: Target disappeared from Prometheus target discovery.
      expr: absent(up{job="kube-scheduler"} == 1)
      for: 15m
      labels:
        severity: critical
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-system.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-kubernetes-system
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-system
    rules:
    - alert: KubeVersionMismatch
      annotations:
        description: There are {{ $value }} different semantic versions of Kubernetes components running.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeversionmismatch
        summary: Different semantic versions of Kubernetes components running.
      expr: count by (cluster) (count by (git_version, cluster) (label_replace(kubernetes_build_info{job!~"kube-dns|coredns"},"git_version","$1","git_version","(v[0-9]*.[0-9]*).*"))) > 1
      for: 15m
      labels:
        severity: warning
    - alert: KubeClientErrors
      annotations:
        description: Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance }}' is experiencing {{ $value | humanizePercentage }} errors.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeclienterrors
        summary: Kubernetes API server client is experiencing errors.
      expr: |-
        (sum(rate(rest_client_requests_total{job="apiserver",code=~"5.."}[5m])) by (cluster, instance, job, namespace)
          /
        sum(rate(rest_client_requests_total{job="apiserver"}[5m])) by (cluster, instance, job, namespace))
        > 0.01
      for: 15m
      labels:
        severity: warning
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/node-exporter.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-node-exporter.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: node-exporter.rules
    rules:
    - expr: |-
        count without (cpu, mode) (
          node_cpu_seconds_total{job="node-exporter",mode="idle"}
        )
      record: instance:node_num_cpu:sum
    - expr: |-
        1 - avg without (cpu) (
          sum without (mode) (rate(node_cpu_seconds_total{job="node-exporter", mode=~"idle|iowait|steal"}[5m]))
        )
      record: instance:node_cpu_utilisation:rate5m
    - expr: |-
        (
          node_load1{job="node-exporter"}
        /
          instance:node_num_cpu:sum{job="node-exporter"}
        )
      record: instance:node_load1_per_cpu:ratio
    - expr: |-
        1 - (
          (
            node_memory_MemAvailable_bytes{job="node-exporter"}
            or
            (
              node_memory_Buffers_bytes{job="node-exporter"}
              +
              node_memory_Cached_bytes{job="node-exporter"}
              +
              node_memory_MemFree_bytes{job="node-exporter"}
              +
              node_memory_Slab_bytes{job="node-exporter"}
            )
          )
        /
          node_memory_MemTotal_bytes{job="node-exporter"}
        )
      record: instance:node_memory_utilisation:ratio
    - expr: rate(node_vmstat_pgmajfault{job="node-exporter"}[5m])
      record: instance:node_vmstat_pgmajfault:rate5m
    - expr: rate(node_disk_io_time_seconds_total{job="node-exporter", device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|md.+|dasd.+)"}[5m])
      record: instance_device:node_disk_io_time_seconds:rate5m
    - expr: rate(node_disk_io_time_weighted_seconds_total{job="node-exporter", device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|md.+|dasd.+)"}[5m])
      record: instance_device:node_disk_io_time_weighted_seconds:rate5m
    - expr: |-
        sum without (device) (
          rate(node_network_receive_bytes_total{job="node-exporter", device!="lo"}[5m])
        )
      record: instance:node_network_receive_bytes_excluding_lo:rate5m
    - expr: |-
        sum without (device) (
          rate(node_network_transmit_bytes_total{job="node-exporter", device!="lo"}[5m])
        )
      record: instance:node_network_transmit_bytes_excluding_lo:rate5m
    - expr: |-
        sum without (device) (
          rate(node_network_receive_drop_total{job="node-exporter", device!="lo"}[5m])
        )
      record: instance:node_network_receive_drop_excluding_lo:rate5m
    - expr: |-
        sum without (device) (
          rate(node_network_transmit_drop_total{job="node-exporter", device!="lo"}[5m])
        )
      record: instance:node_network_transmit_drop_excluding_lo:rate5m
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/node-exporter.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-node-exporter
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: node-exporter
    rules:
    - alert: NodeFilesystemSpaceFillingUp
      annotations:
        description: Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left and is filling up.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemspacefillingup
        summary: Filesystem is predicted to run out of space within the next 24 hours.
      expr: |-
        (
          node_filesystem_avail_bytes{job="node-exporter",fstype!="",mountpoint!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!="",mountpoint!=""} * 100 < 15
        and
          predict_linear(node_filesystem_avail_bytes{job="node-exporter",fstype!="",mountpoint!=""}[6h], 24*60*60) < 0
        and
          node_filesystem_readonly{job="node-exporter",fstype!="",mountpoint!=""} == 0
        )
      for: 1h
      labels:
        severity: warning
    - alert: NodeFilesystemSpaceFillingUp
      annotations:
        description: Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left and is filling up fast.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemspacefillingup
        summary: Filesystem is predicted to run out of space within the next 4 hours.
      expr: |-
        (
          node_filesystem_avail_bytes{job="node-exporter",fstype!="",mountpoint!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!="",mountpoint!=""} * 100 < 10
        and
          predict_linear(node_filesystem_avail_bytes{job="node-exporter",fstype!="",mountpoint!=""}[6h], 4*60*60) < 0
        and
          node_filesystem_readonly{job="node-exporter",fstype!="",mountpoint!=""} == 0
        )
      for: 1h
      labels:
        severity: critical
    - alert: NodeFilesystemAlmostOutOfSpace
      annotations:
        description: Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemalmostoutofspace
        summary: Filesystem has less than 5% space left.
      expr: |-
        (
          node_filesystem_avail_bytes{job="node-exporter",fstype!="",mountpoint!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!="",mountpoint!=""} * 100 < 5
        and
          node_filesystem_readonly{job="node-exporter",fstype!="",mountpoint!=""} == 0
        )
      for: 30m
      labels:
        severity: warning
    - alert: NodeFilesystemAlmostOutOfSpace
      annotations:
        description: Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemalmostoutofspace
        summary: Filesystem has less than 3% space left.
      expr: |-
        (
          node_filesystem_avail_bytes{job="node-exporter",fstype!="",mountpoint!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!="",mountpoint!=""} * 100 < 3
        and
          node_filesystem_readonly{job="node-exporter",fstype!="",mountpoint!=""} == 0
        )
      for: 30m
      labels:
        severity: critical
    - alert: NodeFilesystemFilesFillingUp
      annotations:
        description: Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left and is filling up.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemfilesfillingup
        summary: Filesystem is predicted to run out of inodes within the next 24 hours.
      expr: |-
        (
          node_filesystem_files_free{job="node-exporter",fstype!="",mountpoint!=""} / node_filesystem_files{job="node-exporter",fstype!="",mountpoint!=""} * 100 < 40
        and
          predict_linear(node_filesystem_files_free{job="node-exporter",fstype!="",mountpoint!=""}[6h], 24*60*60) < 0
        and
          node_filesystem_readonly{job="node-exporter",fstype!="",mountpoint!=""} == 0
        )
      for: 1h
      labels:
        severity: warning
    - alert: NodeFilesystemFilesFillingUp
      annotations:
        description: Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left and is filling up fast.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemfilesfillingup
        summary: Filesystem is predicted to run out of inodes within the next 4 hours.
      expr: |-
        (
          node_filesystem_files_free{job="node-exporter",fstype!="",mountpoint!=""} / node_filesystem_files{job="node-exporter",fstype!="",mountpoint!=""} * 100 < 20
        and
          predict_linear(node_filesystem_files_free{job="node-exporter",fstype!="",mountpoint!=""}[6h], 4*60*60) < 0
        and
          node_filesystem_readonly{job="node-exporter",fstype!="",mountpoint!=""} == 0
        )
      for: 1h
      labels:
        severity: critical
    - alert: NodeFilesystemAlmostOutOfFiles
      annotations:
        description: Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemalmostoutoffiles
        summary: Filesystem has less than 5% inodes left.
      expr: |-
        (
          node_filesystem_files_free{job="node-exporter",fstype!="",mountpoint!=""} / node_filesystem_files{job="node-exporter",fstype!="",mountpoint!=""} * 100 < 5
        and
          node_filesystem_readonly{job="node-exporter",fstype!="",mountpoint!=""} == 0
        )
      for: 1h
      labels:
        severity: warning
    - alert: NodeFilesystemAlmostOutOfFiles
      annotations:
        description: Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemalmostoutoffiles
        summary: Filesystem has less than 3% inodes left.
      expr: |-
        (
          node_filesystem_files_free{job="node-exporter",fstype!="",mountpoint!=""} / node_filesystem_files{job="node-exporter",fstype!="",mountpoint!=""} * 100 < 3
        and
          node_filesystem_readonly{job="node-exporter",fstype!="",mountpoint!=""} == 0
        )
      for: 1h
      labels:
        severity: critical
    - alert: NodeNetworkReceiveErrs
      annotations:
        description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} receive errors in the last two minutes.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodenetworkreceiveerrs
        summary: Network interface is reporting many receive errors.
      expr: rate(node_network_receive_errs_total{job="node-exporter"}[2m]) / rate(node_network_receive_packets_total{job="node-exporter"}[2m]) > 0.01
      for: 1h
      labels:
        severity: warning
    - alert: NodeNetworkTransmitErrs
      annotations:
        description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} transmit errors in the last two minutes.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodenetworktransmiterrs
        summary: Network interface is reporting many transmit errors.
      expr: rate(node_network_transmit_errs_total{job="node-exporter"}[2m]) / rate(node_network_transmit_packets_total{job="node-exporter"}[2m]) > 0.01
      for: 1h
      labels:
        severity: warning
    - alert: NodeHighNumberConntrackEntriesUsed
      annotations:
        description: '{{ $value | humanizePercentage }} of conntrack entries are used.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodehighnumberconntrackentriesused
        summary: Number of conntrack are getting close to the limit.
      expr: (node_nf_conntrack_entries{job="node-exporter"} / node_nf_conntrack_entries_limit) > 0.75
      labels:
        severity: warning
    - alert: NodeTextFileCollectorScrapeError
      annotations:
        description: Node Exporter text file collector on {{ $labels.instance }} failed to scrape.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodetextfilecollectorscrapeerror
        summary: Node Exporter text file collector failed to scrape.
      expr: node_textfile_scrape_error{job="node-exporter"} == 1
      labels:
        severity: warning
    - alert: NodeClockSkewDetected
      annotations:
        description: Clock at {{ $labels.instance }} is out of sync by more than 0.05s. Ensure NTP is configured correctly on this host.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodeclockskewdetected
        summary: Clock skew detected.
      expr: |-
        (
          node_timex_offset_seconds{job="node-exporter"} > 0.05
        and
          deriv(node_timex_offset_seconds{job="node-exporter"}[5m]) >= 0
        )
        or
        (
          node_timex_offset_seconds{job="node-exporter"} < -0.05
        and
          deriv(node_timex_offset_seconds{job="node-exporter"}[5m]) <= 0
        )
      for: 10m
      labels:
        severity: warning
    - alert: NodeClockNotSynchronising
      annotations:
        description: Clock at {{ $labels.instance }} is not synchronising. Ensure NTP is configured on this host.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodeclocknotsynchronising
        summary: Clock not synchronising.
      expr: |-
        min_over_time(node_timex_sync_status{job="node-exporter"}[5m]) == 0
        and
        node_timex_maxerror_seconds{job="node-exporter"} >= 16
      for: 10m
      labels:
        severity: warning
    - alert: NodeRAIDDegraded
      annotations:
        description: RAID array '{{ $labels.device }}' at {{ $labels.instance }} is in degraded state due to one or more disks failures. Number of spare drives is insufficient to fix issue automatically.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/noderaiddegraded
        summary: RAID Array is degraded.
      expr: node_md_disks_required{job="node-exporter",device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|md.+|dasd.+)"} - ignoring (state) (node_md_disks{state="active",job="node-exporter",device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|md.+|dasd.+)"}) > 0
      for: 15m
      labels:
        severity: critical
    - alert: NodeRAIDDiskFailure
      annotations:
        description: At least one device in RAID array at {{ $labels.instance }} failed. Array '{{ $labels.device }}' needs attention and possibly a disk swap.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/noderaiddiskfailure
        summary: Failed device in RAID array.
      expr: node_md_disks{state="failed",job="node-exporter",device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|md.+|dasd.+)"} > 0
      labels:
        severity: warning
    - alert: NodeFileDescriptorLimit
      annotations:
        description: File descriptors limit at {{ $labels.instance }} is currently at {{ printf "%.2f" $value }}%.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefiledescriptorlimit
        summary: Kernel is predicted to exhaust file descriptors limit soon.
      expr: |-
        (
          node_filefd_allocated{job="node-exporter"} * 100 / node_filefd_maximum{job="node-exporter"} > 70
        )
      for: 15m
      labels:
        severity: warning
    - alert: NodeFileDescriptorLimit
      annotations:
        description: File descriptors limit at {{ $labels.instance }} is currently at {{ printf "%.2f" $value }}%.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefiledescriptorlimit
        summary: Kernel is predicted to exhaust file descriptors limit soon.
      expr: |-
        (
          node_filefd_allocated{job="node-exporter"} * 100 / node_filefd_maximum{job="node-exporter"} > 90
        )
      for: 15m
      labels:
        severity: critical
    - alert: NodeCPUHighUsage
      annotations:
        description: 'CPU usage at {{ $labels.instance }} has been above 90% for the last 15 minutes, is currently at {{ printf "%.2f" $value }}%.

          '
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodecpuhighusage
        summary: High CPU usage.
      expr: sum without(mode) (avg without (cpu) (rate(node_cpu_seconds_total{job="node-exporter", mode!="idle"}[2m]))) * 100 > 90
      for: 15m
      labels:
        severity: info
    - alert: NodeSystemSaturation
      annotations:
        description: 'System load per core at {{ $labels.instance }} has been above 2 for the last 15 minutes, is currently at {{ printf "%.2f" $value }}.

          This might indicate this instance resources saturation and can cause it becoming unresponsive.

          '
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodesystemsaturation
        summary: System saturated, load per core is very high.
      expr: |-
        node_load1{job="node-exporter"}
        / count without (cpu, mode) (node_cpu_seconds_total{job="node-exporter", mode="idle"}) > 2
      for: 15m
      labels:
        severity: warning
    - alert: NodeMemoryMajorPagesFaults
      annotations:
        description: 'Memory major pages are occurring at very high rate at {{ $labels.instance }}, 500 major page faults per second for the last 15 minutes, is currently at {{ printf "%.2f" $value }}.

          Please check that there is enough memory available at this instance.

          '
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodememorymajorpagesfaults
        summary: Memory major page faults are occurring at very high rate.
      expr: rate(node_vmstat_pgmajfault{job="node-exporter"}[5m]) > 500
      for: 15m
      labels:
        severity: warning
    - alert: NodeMemoryHighUtilization
      annotations:
        description: 'Memory is filling up at {{ $labels.instance }}, has been above 90% for the last 15 minutes, is currently at {{ printf "%.2f" $value }}%.

          '
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodememoryhighutilization
        summary: Host is running out of memory.
      expr: 100 - (node_memory_MemAvailable_bytes{job="node-exporter"} / node_memory_MemTotal_bytes{job="node-exporter"} * 100) > 90
      for: 15m
      labels:
        severity: warning
    - alert: NodeDiskIOSaturation
      annotations:
        description: 'Disk IO queue (aqu-sq) is high on {{ $labels.device }} at {{ $labels.instance }}, has been above 10 for the last 30 minutes, is currently at {{ printf "%.2f" $value }}.

          This symptom might indicate disk saturation.

          '
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodediskiosaturation
        summary: Disk IO queue is high.
      expr: rate(node_disk_io_time_weighted_seconds_total{job="node-exporter", device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|md.+|dasd.+)"}[5m]) > 10
      for: 30m
      labels:
        severity: warning
    - alert: NodeSystemdServiceFailed
      annotations:
        description: Systemd service {{ $labels.name }} has entered failed state at {{ $labels.instance }}
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodesystemdservicefailed
        summary: Systemd service has entered failed state.
      expr: node_systemd_unit_state{job="node-exporter", state="failed"} == 1
      for: 5m
      labels:
        severity: warning
    - alert: NodeBondingDegraded
      annotations:
        description: Bonding interface {{ $labels.master }} on {{ $labels.instance }} is in degraded state due to one or more slave failures.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodebondingdegraded
        summary: Bonding interface is degraded
      expr: (node_bonding_slaves - node_bonding_active) != 0
      for: 5m
      labels:
        severity: warning
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/node-network.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-node-network
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: node-network
    rules:
    - alert: NodeNetworkInterfaceFlapping
      annotations:
        description: Network interface "{{ $labels.device }}" changing its up status often on node-exporter {{ $labels.namespace }}/{{ $labels.pod }}
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/general/nodenetworkinterfaceflapping
        summary: Network interface is often changing its status
      expr: changes(node_network_up{job="node-exporter",device!~"veth.+"}[2m]) > 2
      for: 2m
      labels:
        severity: warning
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/node.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-node.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: node.rules
    rules:
    - expr: |-
        topk by (cluster, namespace, pod) (1,
          max by (cluster, node, namespace, pod) (
            label_replace(kube_pod_info{job="kube-state-metrics",node!=""}, "pod", "$1", "pod", "(.*)")
        ))
      record: 'node_namespace_pod:kube_pod_info:'
    - expr: |-
        count by (cluster, node) (
          node_cpu_seconds_total{mode="idle",job="node-exporter"}
          * on (cluster, namespace, pod) group_left(node)
          topk by (cluster, namespace, pod) (1, node_namespace_pod:kube_pod_info:)
        )
      record: node:node_num_cpu:sum
    - expr: |-
        sum(
          node_memory_MemAvailable_bytes{job="node-exporter"} or
          (
            node_memory_Buffers_bytes{job="node-exporter"} +
            node_memory_Cached_bytes{job="node-exporter"} +
            node_memory_MemFree_bytes{job="node-exporter"} +
            node_memory_Slab_bytes{job="node-exporter"}
          )
        ) by (cluster)
      record: :node_memory_MemAvailable_bytes:sum
    - expr: |-
        avg by (cluster, node) (
          sum without (mode) (
            rate(node_cpu_seconds_total{mode!="idle",mode!="iowait",mode!="steal",job="node-exporter"}[5m])
          )
        )
      record: node:node_cpu_utilization:ratio_rate5m
    - expr: |-
        avg by (cluster) (
          node:node_cpu_utilization:ratio_rate5m
        )
      record: cluster:node_cpu:ratio_rate5m
---
# Source: kube-prometheus-stack/templates/prometheus/rules-1.14/prometheus-operator.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kube-prometheus-stack-prometheus-operator
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  groups:
  - name: prometheus-operator
    rules:
    - alert: PrometheusOperatorListErrors
      annotations:
        description: Errors while performing List operations in controller {{$labels.controller}} in {{$labels.namespace}} namespace.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorlisterrors
        summary: Errors while performing list operations in controller.
      expr: (sum by (cluster,controller,namespace) (rate(prometheus_operator_list_operations_failed_total{job="kube-prometheus-stack-operator",namespace="monitoring"}[10m])) / sum by (cluster,controller,namespace) (rate(prometheus_operator_list_operations_total{job="kube-prometheus-stack-operator",namespace="monitoring"}[10m]))) > 0.4
      for: 15m
      labels:
        severity: warning
    - alert: PrometheusOperatorWatchErrors
      annotations:
        description: Errors while performing watch operations in controller {{$labels.controller}} in {{$labels.namespace}} namespace.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorwatcherrors
        summary: Errors while performing watch operations in controller.
      expr: (sum by (cluster,controller,namespace) (rate(prometheus_operator_watch_operations_failed_total{job="kube-prometheus-stack-operator",namespace="monitoring"}[5m])) / sum by (cluster,controller,namespace) (rate(prometheus_operator_watch_operations_total{job="kube-prometheus-stack-operator",namespace="monitoring"}[5m]))) > 0.4
      for: 15m
      labels:
        severity: warning
    - alert: PrometheusOperatorSyncFailed
      annotations:
        description: Controller {{ $labels.controller }} in {{ $labels.namespace }} namespace fails to reconcile {{ $value }} objects.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorsyncfailed
        summary: Last controller reconciliation failed
      expr: min_over_time(prometheus_operator_syncs{status="failed",job="kube-prometheus-stack-operator",namespace="monitoring"}[5m]) > 0
      for: 10m
      labels:
        severity: warning
    - alert: PrometheusOperatorReconcileErrors
      annotations:
        description: '{{ $value | humanizePercentage }} of reconciling operations failed for {{ $labels.controller }} controller in {{ $labels.namespace }} namespace.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorreconcileerrors
        summary: Errors while reconciling objects.
      expr: (sum by (cluster,controller,namespace) (rate(prometheus_operator_reconcile_errors_total{job="kube-prometheus-stack-operator",namespace="monitoring"}[5m]))) / (sum by (cluster,controller,namespace) (rate(prometheus_operator_reconcile_operations_total{job="kube-prometheus-stack-operator",namespace="monitoring"}[5m]))) > 0.1
      for: 10m
      labels:
        severity: warning
    - alert: PrometheusOperatorStatusUpdateErrors
      annotations:
        description: '{{ $value | humanizePercentage }} of status update operations failed for {{ $labels.controller }} controller in {{ $labels.namespace }} namespace.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorstatusupdateerrors
        summary: Errors while updating objects status.
      expr: (sum by (cluster,controller,namespace) (rate(prometheus_operator_status_update_errors_total{job="kube-prometheus-stack-operator",namespace="monitoring"}[5m]))) / (sum by (cluster,controller,namespace) (rate(prometheus_operator_status_update_operations_total{job="kube-prometheus-stack-operator",namespace="monitoring"}[5m]))) > 0.1
      for: 10m
      labels:
        severity: warning
    - alert: PrometheusOperatorNodeLookupErrors
      annotations:
        description: Errors while reconciling Prometheus in {{ $labels.namespace }} Namespace.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatornodelookuperrors
        summary: Errors while reconciling Prometheus.
      expr: rate(prometheus_operator_node_address_lookup_errors_total{job="kube-prometheus-stack-operator",namespace="monitoring"}[5m]) > 0.1
      for: 10m
      labels:
        severity: warning
    - alert: PrometheusOperatorNotReady
      annotations:
        description: Prometheus operator in {{ $labels.namespace }} namespace isn't ready to reconcile {{ $labels.controller }} resources.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatornotready
        summary: Prometheus operator not ready
      expr: min by (cluster,controller,namespace) (max_over_time(prometheus_operator_ready{job="kube-prometheus-stack-operator",namespace="monitoring"}[5m]) == 0)
      for: 5m
      labels:
        severity: warning
    - alert: PrometheusOperatorRejectedResources
      annotations:
        description: Prometheus operator in {{ $labels.namespace }} namespace rejected {{ printf "%0.0f" $value }} {{ $labels.controller }}/{{ $labels.resource }} resources.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorrejectedresources
        summary: Resources rejected by Prometheus operator
      expr: min_over_time(prometheus_operator_managed_resources{state="rejected",job="kube-prometheus-stack-operator",namespace="monitoring"}[5m]) > 0
      for: 5m
      labels:
        severity: warning
---
# Source: kube-prometheus-stack/charts/grafana/templates/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kube-prometheus-stack-grafana
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-7.3.10
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "10.4.1"
    app.kubernetes.io/managed-by: Helm
spec:
  endpoints:
  - port: http-web
    scrapeTimeout: 30s
    honorLabels: true
    path: /metrics
    scheme: http
  jobLabel: "kube-prometheus-stack"
  selector:
    matchLabels:
      app.kubernetes.io/name: grafana
      app.kubernetes.io/instance: kube-prometheus-stack
  namespaceSelector:
    matchNames:
      - monitoring
---
# Source: kube-prometheus-stack/charts/kube-state-metrics/templates/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kube-prometheus-stack-kube-state-metrics
  namespace: monitoring
  labels:    
    helm.sh/chart: kube-state-metrics-5.19.0
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "2.12.0"
    release: kube-prometheus-stack
spec:
  jobLabel: app.kubernetes.io/name  
  selector:
    matchLabels:      
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/instance: kube-prometheus-stack
  endpoints:
    - port: http
      honorLabels: true
---
# Source: kube-prometheus-stack/charts/prometheus-node-exporter/templates/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kube-prometheus-stack-prometheus-node-exporter
  namespace: monitoring
  labels:
    helm.sh/chart: prometheus-node-exporter-4.34.0
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: prometheus-node-exporter
    app.kubernetes.io/name: prometheus-node-exporter
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "1.8.0"
    jobLabel: node-exporter
    release: kube-prometheus-stack
spec:
  jobLabel: jobLabel
  
  selector:
    matchLabels:
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/instance: kube-prometheus-stack
  attachMetadata:
    node: false
  endpoints:
    - port: http-metrics
      scheme: http
---
# Source: kube-prometheus-stack/templates/alertmanager/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kube-prometheus-stack-alertmanager
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-alertmanager
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  
  selector:
    matchLabels:
      app: kube-prometheus-stack-alertmanager
      release: "kube-prometheus-stack"
      self-monitor: "true"
  namespaceSelector:
    matchNames:
      - "monitoring"
  endpoints:
  - port: http-web
    enableHttp2: true
    path: "/metrics"
  - port: reloader-web
    path: "/metrics"
---
# Source: kube-prometheus-stack/templates/exporters/core-dns/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kube-prometheus-stack-coredns
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-coredns
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  jobLabel: jobLabel
  
  selector:
    matchLabels:
      app: kube-prometheus-stack-coredns
      release: "kube-prometheus-stack"
  namespaceSelector:
    matchNames:
      - "kube-system"
  endpoints:
  - port: http-metrics
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
---
# Source: kube-prometheus-stack/templates/exporters/kube-api-server/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kube-prometheus-stack-apiserver
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-apiserver
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  
  endpoints:
  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    port: https
    scheme: https
    metricRelabelings:
      - action: drop
        regex: apiserver_request_duration_seconds_bucket;(0.15|0.2|0.3|0.35|0.4|0.45|0.6|0.7|0.8|0.9|1.25|1.5|1.75|2|3|3.5|4|4.5|6|7|8|9|15|25|40|50)
        sourceLabels:
        - __name__
        - le
    tlsConfig:
      caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      serverName: kubernetes
      insecureSkipVerify: false
  jobLabel: component
  namespaceSelector:
    matchNames:
    - default
  selector:
    matchLabels:
      component: apiserver
      provider: kubernetes
---
# Source: kube-prometheus-stack/templates/exporters/kube-controller-manager/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kube-prometheus-stack-kube-controller-manager
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-kube-controller-manager
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  jobLabel: jobLabel
  
  selector:
    matchLabels:
      app: kube-prometheus-stack-kube-controller-manager
      release: "kube-prometheus-stack"
  namespaceSelector:
    matchNames:
      - "kube-system"
  endpoints:
  - port: http-metrics
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    scheme: https
    tlsConfig:
      caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecureSkipVerify: true
---
# Source: kube-prometheus-stack/templates/exporters/kube-etcd/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kube-prometheus-stack-kube-etcd
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-kube-etcd
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  jobLabel: jobLabel
    
  selector:
    matchLabels:
      app: kube-prometheus-stack-kube-etcd
      release: "kube-prometheus-stack"
  namespaceSelector:
    matchNames:
      - "kube-system"
  endpoints:
  - port: http-metrics
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
---
# Source: kube-prometheus-stack/templates/exporters/kube-proxy/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kube-prometheus-stack-kube-proxy
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-kube-proxy
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  jobLabel: jobLabel
  
  selector:
    matchLabels:
      app: kube-prometheus-stack-kube-proxy
      release: "kube-prometheus-stack"
  namespaceSelector:
    matchNames:
      - "kube-system"
  endpoints:
  - port: http-metrics
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
---
# Source: kube-prometheus-stack/templates/exporters/kube-scheduler/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kube-prometheus-stack-kube-scheduler
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-kube-scheduler
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  jobLabel: jobLabel
  
  selector:
    matchLabels:
      app: kube-prometheus-stack-kube-scheduler
      release: "kube-prometheus-stack"
  namespaceSelector:
    matchNames:
      - "kube-system"
  endpoints:
  - port: http-metrics
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    scheme: https
    tlsConfig:
      caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecureSkipVerify: true
---
# Source: kube-prometheus-stack/templates/exporters/kubelet/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kube-prometheus-stack-kubelet
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-kubelet    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  
  attachMetadata:
    node: false
  endpoints:
  - port: https-metrics
    scheme: https
    tlsConfig:
      caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecureSkipVerify: true
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    honorLabels: true
    honorTimestamps: true
    relabelings:
    - action: replace
      sourceLabels:
      - __metrics_path__
      targetLabel: metrics_path
  - port: https-metrics
    scheme: https
    path: /metrics/cadvisor
    honorLabels: true
    honorTimestamps: true
    tlsConfig:
      caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecureSkipVerify: true
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    metricRelabelings:
    - action: drop
      regex: container_cpu_(cfs_throttled_seconds_total|load_average_10s|system_seconds_total|user_seconds_total)
      sourceLabels:
      - __name__
    - action: drop
      regex: container_fs_(io_current|io_time_seconds_total|io_time_weighted_seconds_total|reads_merged_total|sector_reads_total|sector_writes_total|writes_merged_total)
      sourceLabels:
      - __name__
    - action: drop
      regex: container_memory_(mapped_file|swap)
      sourceLabels:
      - __name__
    - action: drop
      regex: container_(file_descriptors|tasks_state|threads_max)
      sourceLabels:
      - __name__
    - action: drop
      regex: container_spec.*
      sourceLabels:
      - __name__
    - action: drop
      regex: .+;
      sourceLabels:
      - id
      - pod
    relabelings:
    - action: replace
      sourceLabels:
      - __metrics_path__
      targetLabel: metrics_path
  - port: https-metrics
    scheme: https
    path: /metrics/probes
    honorLabels: true
    honorTimestamps: true
    tlsConfig:
      caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecureSkipVerify: true
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    relabelings:
    - action: replace
      sourceLabels:
      - __metrics_path__
      targetLabel: metrics_path
  jobLabel: k8s-app
  namespaceSelector:
    matchNames:
    - kube-system
  selector:
    matchLabels:
      app.kubernetes.io/name: kubelet
      k8s-app: kubelet
---
# Source: kube-prometheus-stack/templates/prometheus-operator/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kube-prometheus-stack-operator
  namespace: monitoring
  labels:
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
    app: kube-prometheus-stack-operator
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator
spec:
  
  endpoints:
  - port: https
    scheme: https
    tlsConfig:
      serverName: kube-prometheus-stack-operator
      ca:
        secret:
          name: kube-prometheus-stack-admission
          key: ca
          optional: false
    honorLabels: true
  selector:
    matchLabels:
      app: kube-prometheus-stack-operator
      release: "kube-prometheus-stack"
  namespaceSelector:
    matchNames:
      - "monitoring"
---
# Source: kube-prometheus-stack/templates/prometheus/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: kube-prometheus-stack-prometheus
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-prometheus
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
spec:
  
  selector:
    matchLabels:
      app: kube-prometheus-stack-prometheus
      release: "kube-prometheus-stack"
      self-monitor: "true"
  namespaceSelector:
    matchNames:
      - "monitoring"
  endpoints:
  - port: http-web
    path: "/metrics"
  - port: reloader-web
    path: "/metrics"
---
# Source: kube-prometheus-stack/templates/prometheus-operator/admission-webhooks/validatingWebhookConfiguration.yaml
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  name:  kube-prometheus-stack-admission
  labels:
    app: kube-prometheus-stack-admission
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator-webhook
webhooks:
  - name: prometheusrulemutate.monitoring.coreos.com
    failurePolicy: Ignore
    rules:
      - apiGroups:
          - monitoring.coreos.com
        apiVersions:
          - "*"
        resources:
          - prometheusrules
        operations:
          - CREATE
          - UPDATE
    clientConfig:
      service:
        namespace: monitoring
        name: kube-prometheus-stack-operator
        path: /admission-prometheusrules/validate
    timeoutSeconds: 10
    admissionReviewVersions: ["v1", "v1beta1"]
    sideEffects: None
---
# Source: kube-prometheus-stack/charts/grafana/templates/tests/test-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    helm.sh/chart: grafana-7.3.10
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "10.4.1"
    app.kubernetes.io/managed-by: Helm
  name: kube-prometheus-stack-grafana-test
  namespace: monitoring
  annotations:
    "helm.sh/hook": test-success
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
---
# Source: kube-prometheus-stack/templates/prometheus-operator/admission-webhooks/job-patch/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name:  kube-prometheus-stack-admission
  namespace: monitoring
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app: kube-prometheus-stack-admission
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator-webhook
---
# Source: kube-prometheus-stack/charts/grafana/templates/tests/test-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kube-prometheus-stack-grafana-test
  namespace: monitoring
  annotations:
    "helm.sh/hook": test-success
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
  labels:
    helm.sh/chart: grafana-7.3.10
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "10.4.1"
    app.kubernetes.io/managed-by: Helm
data:
  run.sh: |-
    @test "Test Health" {
      url="http://kube-prometheus-stack-grafana/api/health"

      code=$(wget --server-response --spider --timeout 90 --tries 10 ${url} 2>&1 | awk '/^  HTTP/{print $2}')
      [ "$code" == "200" ]
    }
---
# Source: kube-prometheus-stack/templates/prometheus-operator/admission-webhooks/job-patch/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name:  kube-prometheus-stack-admission
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app: kube-prometheus-stack-admission
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator-webhook
rules:
  - apiGroups:
      - admissionregistration.k8s.io
    resources:
      - validatingwebhookconfigurations
      - mutatingwebhookconfigurations
    verbs:
      - get
      - update
---
# Source: kube-prometheus-stack/templates/prometheus-operator/admission-webhooks/job-patch/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name:  kube-prometheus-stack-admission
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app: kube-prometheus-stack-admission
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator-webhook
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kube-prometheus-stack-admission
subjects:
  - kind: ServiceAccount
    name: kube-prometheus-stack-admission
    namespace: monitoring
---
# Source: kube-prometheus-stack/templates/prometheus-operator/admission-webhooks/job-patch/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name:  kube-prometheus-stack-admission
  namespace: monitoring
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app: kube-prometheus-stack-admission
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator-webhook
rules:
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - get
      - create
---
# Source: kube-prometheus-stack/templates/prometheus-operator/admission-webhooks/job-patch/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name:  kube-prometheus-stack-admission
  namespace: monitoring
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app: kube-prometheus-stack-admission
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator-webhook
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: kube-prometheus-stack-admission
subjects:
  - kind: ServiceAccount
    name: kube-prometheus-stack-admission
    namespace: monitoring
---
# Source: kube-prometheus-stack/charts/grafana/templates/tests/test.yaml
apiVersion: v1
kind: Pod
metadata:
  name: kube-prometheus-stack-grafana-test
  labels:
    helm.sh/chart: grafana-7.3.10
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "10.4.1"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test-success
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
  namespace: monitoring
spec:
  serviceAccountName: kube-prometheus-stack-grafana-test
  containers:
    - name: kube-prometheus-stack-test
      image: "docker.io/bats/bats:v1.4.1"
      imagePullPolicy: "IfNotPresent"
      command: ["/opt/bats/bin/bats", "-t", "/tests/run.sh"]
      volumeMounts:
        - mountPath: /tests
          name: tests
          readOnly: true
  volumes:
    - name: tests
      configMap:
        name: kube-prometheus-stack-grafana-test
  restartPolicy: Never
---
# Source: kube-prometheus-stack/templates/prometheus-operator/admission-webhooks/job-patch/job-createSecret.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name:  kube-prometheus-stack-admission-create
  namespace: monitoring
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app: kube-prometheus-stack-admission-create
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator-webhook
spec:
  ttlSecondsAfterFinished: 60
  template:
    metadata:
      name:  kube-prometheus-stack-admission-create
      labels:
        app: kube-prometheus-stack-admission-create
        
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: kube-prometheus-stack
        app.kubernetes.io/version: "58.5.0"
        app.kubernetes.io/part-of: kube-prometheus-stack
        chart: kube-prometheus-stack-58.5.0
        release: "kube-prometheus-stack"
        heritage: "Helm"
        app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
        app.kubernetes.io/component: prometheus-operator-webhook
    spec:
      containers:
        - name: create
          image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6
          imagePullPolicy: IfNotPresent
          args:
            - create
            - --host=kube-prometheus-stack-operator,kube-prometheus-stack-operator.monitoring.svc
            - --namespace=monitoring
            - --secret-name=kube-prometheus-stack-admission
          securityContext:
          
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          resources:
            {}
      restartPolicy: OnFailure
      serviceAccountName: kube-prometheus-stack-admission
      securityContext:
        runAsGroup: 2000
        runAsNonRoot: true
        runAsUser: 2000
        seccompProfile:
          type: RuntimeDefault
---
# Source: kube-prometheus-stack/templates/prometheus-operator/admission-webhooks/job-patch/job-patchWebhook.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name:  kube-prometheus-stack-admission-patch
  namespace: monitoring
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    app: kube-prometheus-stack-admission-patch
    
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: kube-prometheus-stack
    app.kubernetes.io/version: "58.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-58.5.0
    release: "kube-prometheus-stack"
    heritage: "Helm"
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator-webhook
spec:
  ttlSecondsAfterFinished: 60
  template:
    metadata:
      name:  kube-prometheus-stack-admission-patch
      labels:
        app: kube-prometheus-stack-admission-patch
        
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: kube-prometheus-stack
        app.kubernetes.io/version: "58.5.0"
        app.kubernetes.io/part-of: kube-prometheus-stack
        chart: kube-prometheus-stack-58.5.0
        release: "kube-prometheus-stack"
        heritage: "Helm"
        app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
        app.kubernetes.io/component: prometheus-operator-webhook
    spec:
      containers:
        - name: patch
          image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6
          imagePullPolicy: IfNotPresent
          args:
            - patch
            - --webhook-name=kube-prometheus-stack-admission
            - --namespace=monitoring
            - --secret-name=kube-prometheus-stack-admission
            - --patch-failure-policy=
          securityContext:
          
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          resources:
            {}
      restartPolicy: OnFailure
      serviceAccountName: kube-prometheus-stack-admission
      securityContext:
        runAsGroup: 2000
        runAsNonRoot: true
        runAsUser: 2000
        seccompProfile:
          type: RuntimeDefault

---
# Source: cost-analyzer/charts/grafana/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: grafana
    chart: grafana-1.17.2
    heritage: Helm
    release: kubecost
  name: kubecost-grafana
  namespace: monitoring
---
# Source: cost-analyzer/charts/prometheus/templates/node-exporter-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    component: "node-exporter"
    app: prometheus
    release: kubecost
    chart: prometheus-11.0.2
    heritage: Helm
  name: kubecost-prometheus-node-exporter
  namespace: monitoring
---
# Source: cost-analyzer/charts/prometheus/templates/server-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    component: "server"
    app: prometheus
    release: kubecost
    chart: prometheus-11.0.2
    heritage: Helm
  name: kubecost-prometheus-server
  namespace: monitoring
---
# Source: cost-analyzer/templates/cost-analyzer-service-account-template.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kubecost-cost-analyzer
  namespace: monitoring
  labels:
    
    app.kubernetes.io/name: cost-analyzer
    helm.sh/chart: cost-analyzer-1.107.0
    app.kubernetes.io/instance: kubecost
    app.kubernetes.io/managed-by: Helm
    app: cost-analyzer
---
# Source: cost-analyzer/charts/grafana/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: kubecost-grafana
  namespace: monitoring
  labels:
    app: grafana
    chart: grafana-1.17.2
    release: kubecost
    heritage: Helm
type: Opaque
data:
  admin-user: "YWRtaW4="
  admin-password: "c3Ryb25ncGFzc3dvcmQ="
  ldap-toml: ""
---
# Source: cost-analyzer/charts/grafana/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kubecost-grafana
  namespace: monitoring
  labels:
    app: grafana
    chart: grafana-1.17.2
    release: kubecost
    heritage: Helm
data:
  grafana.ini: |
    [analytics]
    check_for_updates = true
    [auth.anonymous]
    enabled = true
    org_name = Main Org.
    org_role = Editor
    [grafana_net]
    url = https://grafana.net
    [log]
    mode = console
    [paths]
    data = /var/lib/grafana/data
    logs = /var/log/grafana
    plugins = /var/lib/grafana/plugins
    provisioning = /etc/grafana/provisioning
    [server]
    root_url = %(protocol)s://%(domain)s:%(http_port)s/grafana
    serve_from_sub_path = true
  datasources.yaml: |
    apiVersion: 1
    datasources:
    - access: proxy
      isDefault: true
      name: Prometheus
      type: prometheus
      url: http://kubecost-prometheus-server.monitoring.svc
      jsonData:
        httpMethod: POST
        prometheusType: Prometheus
        prometheusVersion: 2.35.0
        timeInterval: 1m
---
# Source: cost-analyzer/charts/prometheus/templates/server-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    component: "server"
    app: prometheus
    release: kubecost
    chart: prometheus-11.0.2
    heritage: Helm
  name: kubecost-prometheus-server
  namespace: monitoring
data:
  alerting_rules.yml: |
    {}
  alerts: |
    {}
  prometheus.yml: |
    global:
      evaluation_interval: 1m
      external_labels:
        cluster_id: cluster-one
      scrape_interval: 1m
      scrape_timeout: 60s
    rule_files:
    - /etc/config/recording_rules.yml
    - /etc/config/alerting_rules.yml
    - /etc/config/rules
    - /etc/config/alerts
    scrape_configs:
    - job_name: prometheus
      static_configs:
      - targets:
        - localhost:9090
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-nodes-cadvisor
      kubernetes_sd_configs:
      - role: node
      metric_relabel_configs:
      - action: keep
        regex: (container_cpu_usage_seconds_total|container_memory_working_set_bytes|container_network_receive_errors_total|container_network_transmit_errors_total|container_network_receive_packets_dropped_total|container_network_transmit_packets_dropped_total|container_memory_usage_bytes|container_cpu_cfs_throttled_periods_total|container_cpu_cfs_periods_total|container_fs_usage_bytes|container_fs_limit_bytes|container_cpu_cfs_periods_total|container_fs_inodes_free|container_fs_inodes_total|container_fs_usage_bytes|container_fs_limit_bytes|container_cpu_cfs_throttled_periods_total|container_cpu_cfs_periods_total|container_network_receive_bytes_total|container_network_transmit_bytes_total|container_fs_inodes_free|container_fs_inodes_total|container_fs_usage_bytes|container_fs_limit_bytes|container_spec_cpu_shares|container_spec_memory_limit_bytes|container_network_receive_bytes_total|container_network_transmit_bytes_total|container_fs_reads_bytes_total|container_network_receive_bytes_total|container_fs_writes_bytes_total|container_fs_reads_bytes_total|cadvisor_version_info|kubecost_pv_info)
        source_labels:
        - __name__
      - action: replace
        regex: (.+)
        source_labels:
        - container
        target_label: container_name
      - action: replace
        regex: (.+)
        source_labels:
        - pod
        target_label: pod_name
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-nodes
      kubernetes_sd_configs:
      - role: node
      metric_relabel_configs:
      - action: keep
        regex: (kubelet_volume_stats_used_bytes)
        source_labels:
        - __name__
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/$1/proxy/metrics
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - job_name: kubernetes-service-endpoints
      kubernetes_sd_configs:
      - role: endpoints
      metric_relabel_configs:
      - action: keep
        regex: (container_cpu_allocation|container_cpu_usage_seconds_total|container_fs_limit_bytes|container_fs_writes_bytes_total|container_gpu_allocation|container_memory_allocation_bytes|container_memory_usage_bytes|container_memory_working_set_bytes|container_network_receive_bytes_total|container_network_transmit_bytes_total|DCGM_FI_DEV_GPU_UTIL|deployment_match_labels|kube_daemonset_status_desired_number_scheduled|kube_daemonset_status_number_ready|kube_deployment_spec_replicas|kube_deployment_status_replicas|kube_deployment_status_replicas_available|kube_job_status_failed|kube_namespace_annotations|kube_namespace_labels|kube_node_info|kube_node_labels|kube_node_status_allocatable|kube_node_status_allocatable_cpu_cores|kube_node_status_allocatable_memory_bytes|kube_node_status_capacity|kube_node_status_capacity_cpu_cores|kube_node_status_capacity_memory_bytes|kube_node_status_condition|kube_persistentvolume_capacity_bytes|kube_persistentvolume_status_phase|kube_persistentvolumeclaim_info|kube_persistentvolumeclaim_resource_requests_storage_bytes|kube_pod_container_info|kube_pod_container_resource_limits|kube_pod_container_resource_limits_cpu_cores|kube_pod_container_resource_limits_memory_bytes|kube_pod_container_resource_requests|kube_pod_container_resource_requests_cpu_cores|kube_pod_container_resource_requests_memory_bytes|kube_pod_container_status_restarts_total|kube_pod_container_status_running|kube_pod_container_status_terminated_reason|kube_pod_labels|kube_pod_owner|kube_pod_status_phase|kube_replicaset_owner|kube_statefulset_replicas|kube_statefulset_status_replicas|kubecost_cluster_info|kubecost_cluster_management_cost|kubecost_cluster_memory_working_set_bytes|kubecost_load_balancer_cost|kubecost_network_internet_egress_cost|kubecost_network_region_egress_cost|kubecost_network_zone_egress_cost|kubecost_node_is_spot|kubecost_pod_network_egress_bytes_total|node_cpu_hourly_cost|node_cpu_seconds_total|node_disk_reads_completed|node_disk_reads_completed_total|node_disk_writes_completed|node_disk_writes_completed_total|node_filesystem_device_error|node_gpu_count|node_gpu_hourly_cost|node_memory_Buffers_bytes|node_memory_Cached_bytes|node_memory_MemAvailable_bytes|node_memory_MemFree_bytes|node_memory_MemTotal_bytes|node_network_transmit_bytes_total|node_ram_hourly_cost|node_total_hourly_cost|pod_pvc_allocation|pv_hourly_cost|service_selector_labels|statefulSet_match_labels|kubecost_pv_info|up)
        source_labels:
        - __name__
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scrape
      - action: keep
        regex: (.*kube-state-metrics|.*node-exporter|kubecost-network-costs)
        source_labels:
        - __meta_kubernetes_endpoints_name
      - action: replace
        regex: (https?)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scheme
        target_label: __scheme__
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_service_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_service_name
        target_label: kubernetes_name
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_node_name
        target_label: kubernetes_node
    - job_name: kubecost
      honor_labels: true
      scrape_interval: 1m
      scrape_timeout: 60s
      metrics_path: /metrics
      scheme: http
      dns_sd_configs:
      - names:
        - kubecost-cost-analyzer
        type: 'A'
        port: 9003
    - job_name: kubecost-networking
      kubernetes_sd_configs:
        - role: pod
      relabel_configs:
      # Scrape only the the targets matching the following metadata
        - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_instance]
          action: keep
          regex:  kubecost
        - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
          action: keep
          regex:  network-costs
    
  recording_rules.yml: |
    {}
  rules: |
    groups:
    - name: CPU
      rules:
      - expr: sum(rate(container_cpu_usage_seconds_total{container!=""}[5m]))
        record: cluster:cpu_usage:rate5m
      - expr: rate(container_cpu_usage_seconds_total{container!=""}[5m])
        record: cluster:cpu_usage_nosum:rate5m
      - expr: avg(irate(container_cpu_usage_seconds_total{container!="POD", container!=""}[5m]))
          by (container,pod,namespace)
        record: kubecost_container_cpu_usage_irate
      - expr: sum(container_memory_working_set_bytes{container!="POD",container!=""})
          by (container,pod,namespace)
        record: kubecost_container_memory_working_set_bytes
      - expr: sum(container_memory_working_set_bytes{container!="POD",container!=""})
        record: kubecost_cluster_memory_working_set_bytes
    - name: Savings
      rules:
      - expr: sum(avg(kube_pod_owner{owner_kind!="DaemonSet"}) by (pod) * sum(container_cpu_allocation)
          by (pod))
        labels:
          daemonset: "false"
        record: kubecost_savings_cpu_allocation
      - expr: sum(avg(kube_pod_owner{owner_kind="DaemonSet"}) by (pod) * sum(container_cpu_allocation)
          by (pod)) / sum(kube_node_info)
        labels:
          daemonset: "true"
        record: kubecost_savings_cpu_allocation
      - expr: sum(avg(kube_pod_owner{owner_kind!="DaemonSet"}) by (pod) * sum(container_memory_allocation_bytes)
          by (pod))
        labels:
          daemonset: "false"
        record: kubecost_savings_memory_allocation_bytes
      - expr: sum(avg(kube_pod_owner{owner_kind="DaemonSet"}) by (pod) * sum(container_memory_allocation_bytes)
          by (pod)) / sum(kube_node_info)
        labels:
          daemonset: "true"
        record: kubecost_savings_memory_allocation_bytes
---
# Source: cost-analyzer/templates/cost-analyzer-config-map-template.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kubecost-cost-analyzer
  namespace: monitoring
  labels:
    
    app.kubernetes.io/name: cost-analyzer
    helm.sh/chart: cost-analyzer-1.107.0
    app.kubernetes.io/instance: kubecost
    app.kubernetes.io/managed-by: Helm
    app: cost-analyzer
data:
    prometheus-alertmanager-endpoint: http://kubecost-prometheus-alertmanager.monitoring
    prometheus-server-endpoint: http://kubecost-prometheus-server.monitoring
    kubecost-token: not-applied
---
# Source: cost-analyzer/templates/cost-analyzer-frontend-config-map-template.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-conf
  namespace: monitoring
  labels:
    
    app.kubernetes.io/name: cost-analyzer
    helm.sh/chart: cost-analyzer-1.107.0
    app.kubernetes.io/instance: kubecost
    app.kubernetes.io/managed-by: Helm
    app: cost-analyzer
data:
  nginx.conf: |
    gzip_static  on;

    # Enable gzip encoding for content of the provided types of 50kb and higher.
    gzip on;
    gzip_min_length 50000;
    gzip_proxied expired no-cache no-store private auth;
    gzip_types
        application/atom+xml
        application/geo+json
        application/javascript
        application/x-javascript
        application/json
        application/ld+json
        application/manifest+json
        application/rdf+xml
        application/rss+xml
        application/vnd.ms-fontobject
        application/wasm
        application/x-web-app-manifest+json
        application/xhtml+xml
        application/xml
        font/eot
        font/otf
        font/ttf
        image/bmp
        image/svg+xml
        text/cache-manifest
        text/calendar
        text/css
        text/javascript
        text/markdown
        text/plain
        text/xml
        text/x-component
        text/x-cross-domain-policy;

    upstream api {
        server kubecost-cost-analyzer.monitoring:9001;
    }

    upstream model {
        server kubecost-cost-analyzer.monitoring:9003;
    }
    upstream grafana {
        server kubecost-grafana.monitoring;
    }
    server {
        server_name _;
        root /var/www;
        index index.html;

        add_header Cache-Control "must-revalidate";
        large_client_header_buffers 4 32k;

        error_page 504 /custom_504.html;
        location = /custom_504.html {
            internal;
        }
        add_header Cache-Control "max-age=300";
        location / {
            try_files $uri $uri/ /index.html;
        }
        add_header ETag "1.107.0";
        listen 9090;
        listen [::]:9090;
        location /api/ {
            proxy_pass http://api/;
            proxy_redirect off;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header  X-Real-IP  $remote_addr;
            proxy_set_header  X-Forwarded-For $proxy_add_x_forwarded_for;
        }
        location /model/ {
            proxy_connect_timeout       600;
            proxy_send_timeout          600;
            proxy_read_timeout          600;
            proxy_pass http://model/;
            proxy_redirect off;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header  X-Real-IP  $remote_addr;
            proxy_set_header  X-Forwarded-For $proxy_add_x_forwarded_for;
        }

        location ~ ^/(turndown|cluster)/ {

            add_header 'Access-Control-Allow-Origin' '*' always;
            add_header 'Access-Control-Allow-Methods' 'GET, PUT, POST, DELETE, OPTIONS' always;
            return 404;
        }
        location /oidc/ {
            proxy_connect_timeout       180;
            proxy_send_timeout          180;
            proxy_read_timeout          180;
            proxy_pass http://model/oidc/;
            proxy_redirect off;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header  X-Real-IP  $remote_addr;
            proxy_set_header  X-Forwarded-For $proxy_add_x_forwarded_for;
        }
        location /saml/ {
            proxy_connect_timeout       180;
            proxy_send_timeout          180;
            proxy_read_timeout          180;
            proxy_pass http://model/saml/;
            proxy_redirect off;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header  X-Real-IP  $remote_addr;
            proxy_set_header  X-Forwarded-For $proxy_add_x_forwarded_for;
        }
        location /login {
            proxy_connect_timeout       180;
            proxy_send_timeout          180;
            proxy_read_timeout          180;
            proxy_pass http://model/login;
            proxy_redirect off;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header  X-Real-IP  $remote_addr;
            proxy_set_header  X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header  X-Original-URI $request_uri;
        }

        location /logout {
            proxy_connect_timeout       180;
            proxy_send_timeout          180;
            proxy_read_timeout          180;
            proxy_pass http://model/logout;
            proxy_redirect off;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header  X-Real-IP  $remote_addr;
            proxy_set_header  X-Forwarded-For $proxy_add_x_forwarded_for;
        }
        location /grafana/ {
            proxy_pass http://grafana/;
            proxy_redirect off;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header  X-Real-IP  $remote_addr;
            proxy_set_header  X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header Host $http_host;
        }
    

    # Query Service Replicas (QSR) proxy
        location = /model/hideDiagnostics {
            default_type text/html;
            return 200 'false';
        }
    }
---
# Source: cost-analyzer/charts/prometheus/templates/server-pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  labels:
    component: "server"
    app: prometheus
    release: kubecost
    chart: prometheus-11.0.2
    heritage: Helm
  name: kubecost-prometheus-server
  namespace: monitoring
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: "32Gi"
---
# Source: cost-analyzer/templates/cost-analyzer-pvc-template.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: kubecost-cost-analyzer
  namespace: monitoring
  labels:
    
    app.kubernetes.io/name: cost-analyzer
    helm.sh/chart: cost-analyzer-1.107.0
    app.kubernetes.io/instance: kubecost
    app.kubernetes.io/managed-by: Helm
    app: cost-analyzer
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 32Gi
---
# Source: cost-analyzer/charts/grafana/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    app: grafana
    chart: grafana-1.17.2
    release: kubecost
    heritage: Helm
  name: kubecost-grafana-clusterrole
rules: []
---
# Source: cost-analyzer/charts/prometheus/templates/server-clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    component: "server"
    app: prometheus
    release: kubecost
    chart: prometheus-11.0.2
    heritage: Helm
  name: kubecost-prometheus-server
rules:
  - apiGroups:
      - ""
    resources:
      - nodes
      - nodes/proxy
      - nodes/metrics
      - services
      - endpoints
      - pods
      - ingresses
      - configmaps
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - "extensions"
    resources:
      - ingresses/status
      - ingresses
    verbs:
      - get
      - list
      - watch
  - nonResourceURLs:
      - "/metrics"
    verbs:
      - get
---
# Source: cost-analyzer/templates/cost-analyzer-cluster-role-template.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kubecost-cost-analyzer
  labels:
    
    app.kubernetes.io/name: cost-analyzer
    helm.sh/chart: cost-analyzer-1.107.0
    app.kubernetes.io/instance: kubecost
    app.kubernetes.io/managed-by: Helm
    app: cost-analyzer
rules:
  - apiGroups:
      - ''
    resources:
      - configmaps
      - nodes
      - pods
      - events
      - services
      - resourcequotas
      - replicationcontrollers
      - limitranges
      - persistentvolumeclaims
      - persistentvolumes
      - namespaces
      - endpoints
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - apps
    resources:
      - statefulsets
      - deployments
      - daemonsets
      - replicasets
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - batch
    resources:
      - cronjobs
      - jobs
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - autoscaling
    resources:
      - horizontalpodautoscalers
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - policy
    resources:
      - poddisruptionbudgets
    verbs:
      - get
      - list
      - watch
  - apiGroups: 
      - storage.k8s.io
    resources: 
      - storageclasses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - events.k8s.io
    resources:
      - events
    verbs:
      - get
      - list
      - watch
---
# Source: cost-analyzer/charts/grafana/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: kubecost-grafana-clusterrolebinding
  labels:
    app: grafana
    chart: grafana-1.17.2
    release: kubecost
    heritage: Helm
subjects:
  - kind: ServiceAccount
    name: kubecost-grafana
    namespace: monitoring
roleRef:
  kind: ClusterRole
  name: kubecost-grafana-clusterrole
  apiGroup: rbac.authorization.k8s.io
---
# Source: cost-analyzer/charts/prometheus/templates/server-clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    component: "server"
    app: prometheus
    release: kubecost
    chart: prometheus-11.0.2
    heritage: Helm
  name: kubecost-prometheus-server
subjects:
  - kind: ServiceAccount
    name: kubecost-prometheus-server
    namespace: monitoring
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kubecost-prometheus-server
---
# Source: cost-analyzer/templates/cost-analyzer-cluster-role-binding-template.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kubecost-cost-analyzer
  labels:
    
    app.kubernetes.io/name: cost-analyzer
    helm.sh/chart: cost-analyzer-1.107.0
    app.kubernetes.io/instance: kubecost
    app.kubernetes.io/managed-by: Helm
    app: cost-analyzer
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kubecost-cost-analyzer
subjects:
  - kind: ServiceAccount
    name: kubecost-cost-analyzer
    namespace: monitoring
---
# Source: cost-analyzer/charts/grafana/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: kubecost-grafana
  namespace: monitoring
  labels:
    app: grafana
    chart: grafana-1.17.2
    heritage: Helm
    release: kubecost
---
# Source: cost-analyzer/templates/cost-analyzer-cluster-role-template.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: monitoring
  name: kubecost-cost-analyzer
  labels:
    
    app.kubernetes.io/name: cost-analyzer
    helm.sh/chart: cost-analyzer-1.107.0
    app.kubernetes.io/instance: kubecost
    app.kubernetes.io/managed-by: Helm
    app: cost-analyzer
rules:
- apiGroups: 
    - ''
  resources:
    - "pods/log"
  verbs:
    - get
    - list
    - watch
---
# Source: cost-analyzer/charts/grafana/templates/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: kubecost-grafana
  namespace: monitoring
  labels:
    app: grafana
    chart: grafana-1.17.2
    heritage: Helm
    release: kubecost
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: kubecost-grafana
subjects:
- kind: ServiceAccount
  name: kubecost-grafana
---
# Source: cost-analyzer/templates/cost-analyzer-cluster-role-binding-template.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: kubecost-cost-analyzer
  namespace: monitoring
  labels:
    
    app.kubernetes.io/name: cost-analyzer
    helm.sh/chart: cost-analyzer-1.107.0
    app.kubernetes.io/instance: kubecost
    app.kubernetes.io/managed-by: Helm
    app: cost-analyzer
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: kubecost-cost-analyzer
subjects:
  - kind: ServiceAccount
    name: kubecost-cost-analyzer
    namespace: monitoring
---
# Source: cost-analyzer/charts/grafana/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kubecost-grafana
  namespace: monitoring
  labels:
    app: grafana
    chart: grafana-1.17.2
    release: kubecost
    heritage: Helm
spec:
  type: ClusterIP
  ports:
    - name: tcp-service
      port: 80
      protocol: TCP
      targetPort: 3000

  selector:
    app: grafana
    release: kubecost
---
# Source: cost-analyzer/charts/prometheus/templates/node-exporter-service.yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/scrape: "true"
  labels:
    component: "node-exporter"
    app: prometheus
    release: kubecost
    chart: prometheus-11.0.2
    heritage: Helm
  name: kubecost-prometheus-node-exporter
  namespace: monitoring
spec:
  clusterIP: None
  ports:
    - name: metrics
      port: 9100
      protocol: TCP
      targetPort: 9100
  selector:
    component: "node-exporter"
    app: prometheus
    release: kubecost
  type: "ClusterIP"
---
# Source: cost-analyzer/charts/prometheus/templates/server-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    component: "server"
    app: prometheus
    release: kubecost
    chart: prometheus-11.0.2
    heritage: Helm
  name: kubecost-prometheus-server
  namespace: monitoring
spec:
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 9090
  selector:
    component: "server"
    app: prometheus
    release: kubecost
  sessionAffinity: None
  type: "ClusterIP"
---
# Source: cost-analyzer/templates/cost-analyzer-service-template.yaml
kind: Service
apiVersion: v1
metadata:
  name: kubecost-cost-analyzer
  namespace: monitoring
  labels:
    
    app.kubernetes.io/name: cost-analyzer
    helm.sh/chart: cost-analyzer-1.107.0
    app.kubernetes.io/instance: kubecost
    app.kubernetes.io/managed-by: Helm
    app: cost-analyzer
spec:
  selector:
    
    app.kubernetes.io/name: cost-analyzer
    app.kubernetes.io/instance: kubecost
    app: cost-analyzer
  type: "ClusterIP"
  ports:
    - name: tcp-model
      port: 9003
      targetPort: 9003
    - name: tcp-frontend
      port: 9090
      targetPort: 9090
---
# Source: cost-analyzer/charts/prometheus/templates/node-exporter-daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    component: "node-exporter"
    app: prometheus
    release: kubecost
    chart: prometheus-11.0.2
    heritage: Helm
  name: kubecost-prometheus-node-exporter
  namespace: monitoring
spec:
  selector:
    matchLabels:
      component: "node-exporter"
      app: prometheus
      release: kubecost
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        component: "node-exporter"
        app: prometheus
        release: kubecost
        chart: prometheus-11.0.2
        heritage: Helm
    spec:
      serviceAccountName: kubecost-prometheus-node-exporter
      dnsPolicy: "ClusterFirstWithHostNet"
      containers:
        - name: prometheus-node-exporter
          image: "prom/node-exporter:v1.5.0"
          imagePullPolicy: "IfNotPresent"
          args:
            - --path.procfs=/host/proc
            - --path.sysfs=/host/sys
            - --web.listen-address=:9100
          ports:
            - name: metrics
              containerPort: 9100
              hostPort: 9100
          resources:
            {}
          volumeMounts:
            - name: proc
              mountPath: /host/proc
              readOnly:  true
            - name: sys
              mountPath: /host/sys
              readOnly: true
      hostNetwork: true
      hostPID: true
      volumes:
        - name: proc
          hostPath:
            path: /proc
        - name: sys
          hostPath:
            path: /sys
---
# Source: cost-analyzer/charts/grafana/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubecost-grafana
  namespace: monitoring
  labels:
    app: grafana
    chart: grafana-1.17.2
    release: kubecost
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
      release: kubecost
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: grafana
        release: kubecost
    spec:
      serviceAccountName: kubecost-grafana
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: OnRootMismatch
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seccompProfile:
          type: RuntimeDefault
      containers:
        - name: grafana
          image: "grafana/grafana:9.4.7"
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
          volumeMounts:
            - name: config
              mountPath: "/etc/grafana/grafana.ini"
              subPath: grafana.ini
            - name: ldap
              mountPath: "/etc/grafana/ldap.toml"
              subPath: ldap.toml
            - name: config
              mountPath: "/etc/grafana/provisioning/datasources/datasources.yaml"
              subPath: datasources.yaml
            - name: storage
              mountPath: "/var/lib/grafana"
              subPath: 
          ports:
            - name: service
              containerPort: 80
              protocol: TCP
            - name: grafana
              containerPort: 3000
              protocol: TCP
          env:
            - name: GF_SECURITY_ADMIN_USER
              valueFrom:
                secretKeyRef:
                  name: kubecost-grafana
                  key: admin-user
            - name: GF_SECURITY_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: kubecost-grafana
                  key: admin-password
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
            initialDelaySeconds: 60
            timeoutSeconds: 30
          readinessProbe:
            httpGet:
              path: /api/health
              port: 3000
          resources:
            {}
      volumes:
        - name: config
          configMap:
            name: kubecost-grafana
        - name: ldap
          secret:
            secretName: kubecost-grafana
            items:
              - key: ldap-toml
                path: ldap.toml
        - name: storage
          emptyDir: {}
---
# Source: cost-analyzer/charts/prometheus/templates/server-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    component: "server"
    app: prometheus
    release: kubecost
    chart: prometheus-11.0.2
    heritage: Helm
  name: kubecost-prometheus-server
  namespace: monitoring
spec:
  selector:
    matchLabels:
      component: "server"
      app: prometheus
      release: kubecost
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        component: "server"
        app: prometheus
        release: kubecost
        chart: prometheus-11.0.2
        heritage: Helm
    spec:
      serviceAccountName: kubecost-prometheus-server
      containers:
        - name: prometheus-server-configmap-reload
          image: "quay.io/prometheus-operator/prometheus-config-reloader:v0.68.0"
          imagePullPolicy: "IfNotPresent"
          args:
            - --watched-dir=/etc/config
            - --reload-url=http://127.0.0.1:9090/-/reload
          resources:
            {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
              readOnly: true

        - name: prometheus-server
          image: "quay.io/prometheus/prometheus:v2.35.0"
          imagePullPolicy: "IfNotPresent"
          args:
            - --storage.tsdb.retention.time=15d
            - --config.file=/etc/config/prometheus.yml
            - --storage.tsdb.path=/data
            - --web.console.libraries=/etc/prometheus/console_libraries
            - --web.console.templates=/etc/prometheus/consoles
            - --web.enable-lifecycle
            - --query.max-concurrency=1
            - --query.max-samples=1e+08
          ports:
            - containerPort: 9090
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9090
            initialDelaySeconds: 30
            timeoutSeconds: 30
            failureThreshold: 3
            successThreshold: 1
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9090
            initialDelaySeconds: 30
            timeoutSeconds: 30
            failureThreshold: 3
            successThreshold: 1
          resources:
            {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
            - name: storage-volume
              mountPath: /data
              subPath: ""
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: OnRootMismatch
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seccompProfile:
          type: RuntimeDefault
      terminationGracePeriodSeconds: 300
      volumes:
        - name: config-volume
          configMap:
            name: kubecost-prometheus-server
        - name: storage-volume
          persistentVolumeClaim:
            claimName: kubecost-prometheus-server
---
# Source: cost-analyzer/templates/cost-analyzer-deployment-template.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubecost-cost-analyzer
  namespace: monitoring
  labels:
    app.kubernetes.io/name: cost-analyzer
    helm.sh/chart: cost-analyzer-1.107.0
    app.kubernetes.io/instance: kubecost
    app.kubernetes.io/managed-by: Helm
    app: cost-analyzer
spec:
  replicas: 1
  selector:
    matchLabels:
        app.kubernetes.io/name: cost-analyzer
        app.kubernetes.io/instance: kubecost
        app: cost-analyzer
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: cost-analyzer
        app.kubernetes.io/instance: kubecost
        app: cost-analyzer
    spec:
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: OnRootMismatch
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seccompProfile:
          type: RuntimeDefault
      restartPolicy: Always
      serviceAccountName: kubecost-cost-analyzer
      volumes:
        - name: tmp
          emptyDir: {}
        - name: nginx-conf
          configMap:
            name: nginx-conf
            items:
              - key: nginx.conf
                path: default.conf
        - name: persistent-configs
          persistentVolumeClaim:
            claimName: kubecost-cost-analyzer
      initContainers:
      containers:
        - image: gcr.io/kubecost1/cost-model:prod-1.107.0
        
          name: cost-model
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
          imagePullPolicy: Always
          ports:
          - name: tcp-model
            containerPort: 9003
            protocol: TCP
          - name: tcp-frontend
            containerPort: 9090
            protocol: TCP
          resources:
            requests:
              cpu: 200m
              memory: 55Mi
          readinessProbe:
            httpGet:
              path: /healthz
              port: 9003
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 200
          livenessProbe:
            httpGet:
              path: /healthz
              port: 9003
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 200
          volumeMounts:
            - name: persistent-configs
              mountPath: /var/configs
          env:
            - name: GRAFANA_ENABLED
              value: "true"
            - name: HELM_VALUES
              value: {"affinity":{},"awsstore":{"createServiceAccount":false,"priorityClassName":"","useAwsStore":false},"clusterName":"devops-eks-cluster","extraObjects":[],"extraVolumeMounts":[],"extraVolumes":[],"federatedETL":{"federatedCluster":false,"primaryCluster":false,"redirectS3Backup":false,"useMultiClusterDB":false},"global":{"additionalLabels":{},"containerSecurityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"privileged":false,"readOnlyRootFilesystem":true},"grafana":{"domainName":"cost-analyzer-grafana.default.svc","enabled":true,"proxy":true,"scheme":"http"},"notifications":{},"podAnnotations":{},"prometheus":{"enabled":true,"fqdn":"http://kube-prometheus-stack-prometheus.monitoring.svc.cluster.local"},"securityContext":{"fsGroup":1001,"fsGroupChangePolicy":"OnRootMismatch","runAsGroup":1001,"runAsNonRoot":true,"runAsUser":1001,"seccompProfile":{"type":"RuntimeDefault"}}},"initChownData":{"resources":{}},"initChownDataImage":"busybox","kubecostDeployment":{"annotations":{},"labels":{},"queryService":{"configVolumeSize":"1Gi","containerSecurityContext":{"allowPrivilegeEscalation":true,"capabilities":{"drop":["ALL"]},"readOnlyRootFilesystem":false},"databaseVolumeSize":"100Gi","initImage":{},"resources":{"requests":{"cpu":"1000m","memory":"500Mi"}},"securityContext":{"fsGroup":1001,"fsGroupChangePolicy":"OnRootMismatch","runAsGroup":1001,"runAsNonRoot":false,"runAsUser":1001,"seccompProfile":{"type":"RuntimeDefault"}},"storageClass":""},"queryServiceReplicas":0,"replicas":1},"kubecostFrontend":{"enabled":true,"image":"gcr.io/kubecost1/frontend","imagePullPolicy":"Always","ipv6":{"enabled":true},"livenessProbe":{"enabled":true,"failureThreshold":200,"initialDelaySeconds":30,"periodSeconds":10},"resources":{"requests":{"cpu":"10m","memory":"55Mi"}}},"kubecostMetrics":{},"kubecostModel":{"allocation":null,"cloudCost":{"enabled":true,"labelList":{"IsIncludeList":false,"labels":""},"topNItems":1000},"cloudProvider":"custom","etl":true,"etlDailyStoreDurationDays":91,"etlFileStoreEnabled":true,"etlHourlyStoreDurationHours":49,"etlReadOnlyMode":false,"etlWeeklyStoreDurationWeeks":53,"extraArgs":[],"image":"gcr.io/kubecost1/cost-model","imagePullPolicy":"Always","maxQueryConcurrency":5,"outOfClusterPromMetricsEnabled":false,"projectID":"kubecost-project","resources":{"requests":{"cpu":"200m","memory":"55Mi"}},"warmCache":false,"warmSavingsCache":true},"kubecostToken":null,"nodeSelector":{},"persistentVolume":{"annotations":{},"dbSize":"32.0Gi","enabled":true,"labels":{},"size":"32Gi"},"prometheus":{"alertmanagerFiles":{"alertmanager.yml":{"global":{},"receivers":[{"name":"default-receiver"}],"route":{"group_interval":"5m","group_wait":"10s","receiver":"default-receiver","repeat_interval":"3h"}}},"configmapReload":{"alertmanager":{"enabled":true,"extraArgs":{},"extraConfigmapMounts":[],"extraVolumeDirs":[],"image":{"pullPolicy":"IfNotPresent","repository":"quay.io/prometheus-operator/prometheus-config-reloader","tag":"v0.68.0"},"name":"configmap-reload","resources":{}},"prometheus":{"containerSecurityContext":{},"enabled":true,"extraArgs":{},"extraConfigmapMounts":[],"extraVolumeDirs":[],"image":{"pullPolicy":"IfNotPresent","repository":"quay.io/prometheus-operator/prometheus-config-reloader","tag":"v0.68.0"},"name":"configmap-reload","resources":{}}},"extraScrapeConfigs":"- job_name: kubecost\n  honor_labels: true\n  scrape_interval: 1m\n  scrape_timeout: 60s\n  metrics_path: /metrics\n  scheme: http\n  dns_sd_configs:\n  - names:\n    - {{ template \"cost-analyzer.serviceName\" . }}\n    type: 'A'\n    port: 9003\n- job_name: kubecost-networking\n  kubernetes_sd_configs:\n    - role: pod\n  relabel_configs:\n  # Scrape only the the targets matching the following metadata\n    - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_instance]\n      action: keep\n      regex:  kubecost\n    - source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]\n      action: keep\n      regex:  network-costs\n","global":{"additionalLabels":{},"containerSecurityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"privileged":false,"readOnlyRootFilesystem":true},"grafana":{"domainName":"cost-analyzer-grafana.default.svc","enabled":true,"proxy":true,"scheme":"http"},"notifications":{},"podAnnotations":{},"prometheus":{"enabled":true,"fqdn":"http://kube-prometheus-stack-prometheus.monitoring.svc.cluster.local"},"securityContext":{"fsGroup":1001,"fsGroupChangePolicy":"OnRootMismatch","runAsGroup":1001,"runAsNonRoot":true,"runAsUser":1001,"seccompProfile":{"type":"RuntimeDefault"}}},"kube-state-metrics":{"disabled":true,"enabled":true},"nodeExporter":{"dnsPolicy":"ClusterFirstWithHostNet","enabled":true,"extraArgs":{},"extraConfigmapMounts":[],"extraHostPathMounts":[],"hostNetwork":true,"hostPID":true,"image":{"pullPolicy":"IfNotPresent","repository":"prom/node-exporter","tag":"v1.5.0"},"name":"node-exporter","nodeSelector":{},"pod":{"labels":{}},"podAnnotations":{},"podSecurityPolicy":{"annotations":{}},"priorityClassName":"","resources":{},"securityContext":{},"service":{"annotations":{"prometheus.io/scrape":"true"},"clusterIP":"None","externalIPs":[],"hostPort":9100,"labels":{},"loadBalancerIP":"","loadBalancerSourceRanges":[],"servicePort":9100,"type":"ClusterIP"},"tolerations":[],"updateStrategy":{"type":"RollingUpdate"}},"rbac":{"create":true},"server":{"affinity":{},"alertmanagers":[],"baseURL":"","configMapOverrideName":"","configPath":"/etc/config/prometheus.yml","containerSecurityContext":{},"emptyDir":{"sizeLimit":""},"enabled":true,"env":[],"extraArgs":{"query.max-concurrency":1,"query.max-samples":100000000},"extraConfigmapMounts":[],"extraFlags":["web.enable-lifecycle"],"extraHostPathMounts":[],"extraInitContainers":[],"extraSecretMounts":[],"extraVolumeMounts":[],"extraVolumes":[],"global":{"evaluation_interval":"1m","external_labels":{"cluster_id":"cluster-one"},"scrape_interval":"1m","scrape_timeout":"60s"},"image":{"pullPolicy":"IfNotPresent","repository":"quay.io/prometheus/prometheus","tag":"v2.35.0"},"livenessProbeFailureThreshold":3,"livenessProbeInitialDelay":30,"livenessProbeSuccessThreshold":1,"livenessProbeTimeout":30,"name":"server","nodeSelector":{},"persistentVolume":{"accessModes":["ReadWriteOnce"],"annotations":{},"enabled":true,"existingClaim":"","mountPath":"/data","size":"32Gi","subPath":""},"podAnnotations":{},"podLabels":{},"podSecurityPolicy":{"annotations":{}},"prefixURL":"","priorityClassName":"","readinessProbeFailureThreshold":3,"readinessProbeInitialDelay":30,"readinessProbeSuccessThreshold":1,"readinessProbeTimeout":30,"remoteRead":{},"remoteWrite":{},"replicaCount":1,"resources":{},"retention":"15d","securityContext":{"fsGroup":1001,"runAsGroup":1001,"runAsNonRoot":true,"runAsUser":1001},"service":{"annotations":{},"clusterIP":"","externalIPs":[],"labels":{},"loadBalancerIP":"","loadBalancerSourceRanges":[],"servicePort":80,"sessionAffinity":"None","type":"ClusterIP"},"strategy":{"type":"Recreate"},"terminationGracePeriodSeconds":300,"tolerations":[]},"serverFiles":{"alerting_rules.yml":{},"alerts":{},"prometheus.yml":{"rule_files":["/etc/config/recording_rules.yml","/etc/config/alerting_rules.yml","/etc/config/rules","/etc/config/alerts"],"scrape_configs":[{"job_name":"prometheus","static_configs":[{"targets":["localhost:9090"]}]},{"bearer_token_file":"/var/run/secrets/kubernetes.io/serviceaccount/token","job_name":"kubernetes-nodes-cadvisor","kubernetes_sd_configs":[{"role":"node"}],"metric_relabel_configs":[{"action":"keep","regex":"(container_cpu_usage_seconds_total|container_memory_working_set_bytes|container_network_receive_errors_total|container_network_transmit_errors_total|container_network_receive_packets_dropped_total|container_network_transmit_packets_dropped_total|container_memory_usage_bytes|container_cpu_cfs_throttled_periods_total|container_cpu_cfs_periods_total|container_fs_usage_bytes|container_fs_limit_bytes|container_cpu_cfs_periods_total|container_fs_inodes_free|container_fs_inodes_total|container_fs_usage_bytes|container_fs_limit_bytes|container_cpu_cfs_throttled_periods_total|container_cpu_cfs_periods_total|container_network_receive_bytes_total|container_network_transmit_bytes_total|container_fs_inodes_free|container_fs_inodes_total|container_fs_usage_bytes|container_fs_limit_bytes|container_spec_cpu_shares|container_spec_memory_limit_bytes|container_network_receive_bytes_total|container_network_transmit_bytes_total|container_fs_reads_bytes_total|container_network_receive_bytes_total|container_fs_writes_bytes_total|container_fs_reads_bytes_total|cadvisor_version_info|kubecost_pv_info)","source_labels":["__name__"]},{"action":"replace","regex":"(.+)","source_labels":["container"],"target_label":"container_name"},{"action":"replace","regex":"(.+)","source_labels":["pod"],"target_label":"pod_name"}],"relabel_configs":[{"action":"labelmap","regex":"__meta_kubernetes_node_label_(.+)"},{"replacement":"kubernetes.default.svc:443","target_label":"__address__"},{"regex":"(.+)","replacement":"/api/v1/nodes/$1/proxy/metrics/cadvisor","source_labels":["__meta_kubernetes_node_name"],"target_label":"__metrics_path__"}],"scheme":"https","tls_config":{"ca_file":"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt","insecure_skip_verify":true}},{"bearer_token_file":"/var/run/secrets/kubernetes.io/serviceaccount/token","job_name":"kubernetes-nodes","kubernetes_sd_configs":[{"role":"node"}],"metric_relabel_configs":[{"action":"keep","regex":"(kubelet_volume_stats_used_bytes)","source_labels":["__name__"]}],"relabel_configs":[{"action":"labelmap","regex":"__meta_kubernetes_node_label_(.+)"},{"replacement":"kubernetes.default.svc:443","target_label":"__address__"},{"regex":"(.+)","replacement":"/api/v1/nodes/$1/proxy/metrics","source_labels":["__meta_kubernetes_node_name"],"target_label":"__metrics_path__"}],"scheme":"https","tls_config":{"ca_file":"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt","insecure_skip_verify":true}},{"job_name":"kubernetes-service-endpoints","kubernetes_sd_configs":[{"role":"endpoints"}],"metric_relabel_configs":[{"action":"keep","regex":"(container_cpu_allocation|container_cpu_usage_seconds_total|container_fs_limit_bytes|container_fs_writes_bytes_total|container_gpu_allocation|container_memory_allocation_bytes|container_memory_usage_bytes|container_memory_working_set_bytes|container_network_receive_bytes_total|container_network_transmit_bytes_total|DCGM_FI_DEV_GPU_UTIL|deployment_match_labels|kube_daemonset_status_desired_number_scheduled|kube_daemonset_status_number_ready|kube_deployment_spec_replicas|kube_deployment_status_replicas|kube_deployment_status_replicas_available|kube_job_status_failed|kube_namespace_annotations|kube_namespace_labels|kube_node_info|kube_node_labels|kube_node_status_allocatable|kube_node_status_allocatable_cpu_cores|kube_node_status_allocatable_memory_bytes|kube_node_status_capacity|kube_node_status_capacity_cpu_cores|kube_node_status_capacity_memory_bytes|kube_node_status_condition|kube_persistentvolume_capacity_bytes|kube_persistentvolume_status_phase|kube_persistentvolumeclaim_info|kube_persistentvolumeclaim_resource_requests_storage_bytes|kube_pod_container_info|kube_pod_container_resource_limits|kube_pod_container_resource_limits_cpu_cores|kube_pod_container_resource_limits_memory_bytes|kube_pod_container_resource_requests|kube_pod_container_resource_requests_cpu_cores|kube_pod_container_resource_requests_memory_bytes|kube_pod_container_status_restarts_total|kube_pod_container_status_running|kube_pod_container_status_terminated_reason|kube_pod_labels|kube_pod_owner|kube_pod_status_phase|kube_replicaset_owner|kube_statefulset_replicas|kube_statefulset_status_replicas|kubecost_cluster_info|kubecost_cluster_management_cost|kubecost_cluster_memory_working_set_bytes|kubecost_load_balancer_cost|kubecost_network_internet_egress_cost|kubecost_network_region_egress_cost|kubecost_network_zone_egress_cost|kubecost_node_is_spot|kubecost_pod_network_egress_bytes_total|node_cpu_hourly_cost|node_cpu_seconds_total|node_disk_reads_completed|node_disk_reads_completed_total|node_disk_writes_completed|node_disk_writes_completed_total|node_filesystem_device_error|node_gpu_count|node_gpu_hourly_cost|node_memory_Buffers_bytes|node_memory_Cached_bytes|node_memory_MemAvailable_bytes|node_memory_MemFree_bytes|node_memory_MemTotal_bytes|node_network_transmit_bytes_total|node_ram_hourly_cost|node_total_hourly_cost|pod_pvc_allocation|pv_hourly_cost|service_selector_labels|statefulSet_match_labels|kubecost_pv_info|up)","source_labels":["__name__"]}],"relabel_configs":[{"action":"keep","regex":true,"source_labels":["__meta_kubernetes_service_annotation_prometheus_io_scrape"]},{"action":"keep","regex":"(.*kube-state-metrics|.*node-exporter|kubecost-network-costs)","source_labels":["__meta_kubernetes_endpoints_name"]},{"action":"replace","regex":"(https?)","source_labels":["__meta_kubernetes_service_annotation_prometheus_io_scheme"],"target_label":"__scheme__"},{"action":"replace","regex":"(.+)","source_labels":["__meta_kubernetes_service_annotation_prometheus_io_path"],"target_label":"__metrics_path__"},{"action":"replace","regex":"([^:]+)(?::\\d+)?;(\\d+)","replacement":"$1:$2","source_labels":["__address__","__meta_kubernetes_service_annotation_prometheus_io_port"],"target_label":"__address__"},{"action":"labelmap","regex":"__meta_kubernetes_service_label_(.+)"},{"action":"replace","source_labels":["__meta_kubernetes_namespace"],"target_label":"kubernetes_namespace"},{"action":"replace","source_labels":["__meta_kubernetes_service_name"],"target_label":"kubernetes_name"},{"action":"replace","source_labels":["__meta_kubernetes_pod_node_name"],"target_label":"kubernetes_node"}]}]},"recording_rules.yml":{},"rules":{"groups":[{"name":"CPU","rules":[{"expr":"sum(rate(container_cpu_usage_seconds_total{container!=\"\"}[5m]))","record":"cluster:cpu_usage:rate5m"},{"expr":"rate(container_cpu_usage_seconds_total{container!=\"\"}[5m])","record":"cluster:cpu_usage_nosum:rate5m"},{"expr":"avg(irate(container_cpu_usage_seconds_total{container!=\"POD\", container!=\"\"}[5m])) by (container,pod,namespace)","record":"kubecost_container_cpu_usage_irate"},{"expr":"sum(container_memory_working_set_bytes{container!=\"POD\",container!=\"\"}) by (container,pod,namespace)","record":"kubecost_container_memory_working_set_bytes"},{"expr":"sum(container_memory_working_set_bytes{container!=\"POD\",container!=\"\"})","record":"kubecost_cluster_memory_working_set_bytes"}]},{"name":"Savings","rules":[{"expr":"sum(avg(kube_pod_owner{owner_kind!=\"DaemonSet\"}) by (pod) * sum(container_cpu_allocation) by (pod))","labels":{"daemonset":"false"},"record":"kubecost_savings_cpu_allocation"},{"expr":"sum(avg(kube_pod_owner{owner_kind=\"DaemonSet\"}) by (pod) * sum(container_cpu_allocation) by (pod)) / sum(kube_node_info)","labels":{"daemonset":"true"},"record":"kubecost_savings_cpu_allocation"},{"expr":"sum(avg(kube_pod_owner{owner_kind!=\"DaemonSet\"}) by (pod) * sum(container_memory_allocation_bytes) by (pod))","labels":{"daemonset":"false"},"record":"kubecost_savings_memory_allocation_bytes"},{"expr":"sum(avg(kube_pod_owner{owner_kind=\"DaemonSet\"}) by (pod) * sum(container_memory_allocation_bytes) by (pod)) / sum(kube_node_info)","labels":{"daemonset":"true"},"record":"kubecost_savings_memory_allocation_bytes"}]}]}},"serviceAccounts":{"alertmanager":{"create":true},"nodeExporter":{"create":true},"pushgateway":{"create":true},"server":{"annotations":{},"create":true}}},"remoteWrite":{},"reporting":{"errorReporting":true,"logCollection":true,"productAnalytics":true,"valuesReporting":true},"service":{"annotations":{},"labels":{},"port":9090,"targetPort":9090,"type":"ClusterIP"},"serviceAccount":{"annotations":{},"create":true},"sigV4Proxy":{"extraEnv":null,"host":"aps-workspaces.us-west-2.amazonaws.com","image":"public.ecr.aws/aws-observability/aws-sigv4-proxy:latest","imagePullPolicy":"Always","name":"aps","port":8005,"region":"us-west-2"},"supportNFS":false,"tolerations":[]}
            - name: READ_ONLY
              value: "false"
            - name: PROMETHEUS_SERVER_ENDPOINT
              valueFrom:
                configMapKeyRef:
                  name: kubecost-cost-analyzer
                  key: prometheus-server-endpoint
            - name: CLOUD_PROVIDER_API_KEY
              value: "AIzaSyDXQPG_MHUEy9neR7stolq6l0ujXmjJlvk" # The GCP Pricing API key.This GCP api key is expected to be here and is limited to accessing google's billing API.
            - name: CONFIG_PATH
              value: /var/configs/
            - name: DB_PATH
              value: /var/db/
            - name: CLUSTER_PROFILE
              value: production
            - name: EMIT_POD_ANNOTATIONS_METRIC
              value: "false"
            - name: EMIT_NAMESPACE_ANNOTATIONS_METRIC
              value: "false"
            - name: EMIT_KSM_V1_METRICS
              value: "true"
            - name: EMIT_KSM_V1_METRICS_ONLY # ONLY emit KSM v1 metrics that do not exist in KSM 2 by default
              value: "false"
            - name: LOG_COLLECTION_ENABLED
              value: "true"
            - name: PRODUCT_ANALYTICS_ENABLED
              value: "true"
            - name: ERROR_REPORTING_ENABLED
              value: "true"
            - name: VALUES_REPORTING_ENABLED
              value: "true"
            - name: SENTRY_DSN
              value: "https://71964476292e4087af8d5072afe43abd@o394722.ingest.sentry.io/5245431"
            - name: LEGACY_EXTERNAL_API_DISABLED
              value: "false"
            - name: OUT_OF_CLUSTER_PROM_METRICS_ENABLED
              value: "false"
            - name: CACHE_WARMING_ENABLED
              value: "false"
            - name: SAVINGS_ENABLED
              value: "true"
            - name: ETL_ENABLED
              value: "true"
            - name: ETL_STORE_READ_ONLY
              value: "false"
            - name : ETL_CLOUD_USAGE_ENABLED
              value: "false"
            - name: CLOUD_ASSETS_EXCLUDE_PROVIDER_ID
              value: "false"
            - name: ETL_CLOUD_REFRESH_RATE_HOURS
              value: "6"
            - name: ETL_CLOUD_QUERY_WINDOW_DAYS
              value: "7"
            - name: ETL_CLOUD_RUN_WINDOW_DAYS
              value: "3"
            - name: ETL_RESOLUTION_SECONDS
              value: "300"
            - name: ETL_MAX_PROMETHEUS_QUERY_DURATION_MINUTES
              value: "1440"
            - name: ETL_DAILY_STORE_DURATION_DAYS
              value: "91"
            - name: ETL_HOURLY_STORE_DURATION_HOURS
              value: "49"
            - name: ETL_WEEKLY_STORE_DURATION_WEEKS
              value: "53"
            - name: ETL_FILE_STORE_ENABLED
              value: "true"
            - name: ETL_ASSET_RECONCILIATION_ENABLED
              value: "true"
            - name: ETL_USE_UNBLENDED_COST
              value: "false"
            - name: CLOUD_COST_ENABLED
              value: "true"
            - name: CLOUD_COST_IS_INCLUDE_LIST
              value: "false"
            - name: CLOUD_COST_LABEL_LIST
              value: ""
            - name: CLOUD_COST_TOP_N
              value: "1000"
            - name: CONTAINER_STATS_ENABLED
              value: "false"
            - name: RECONCILE_NETWORK
              value: "true"
            - name: KUBECOST_METRICS_POD_ENABLED
              value: "false"
            - name: PV_ENABLED
              value: "true"
            - name: MAX_QUERY_CONCURRENCY
              value: "5"
            - name: UTC_OFFSET
              value: 
            - name: CLUSTER_ID
              value: cluster-one
            - name: SQL_ADDRESS
              value: pgprometheus
            - name: COST_EVENTS_AUDIT_ENABLED
              value: "false"
            - name: RELEASE_NAME
              value: kubecost
            - name: KUBECOST_NAMESPACE
              value: monitoring
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: KUBECOST_TOKEN
              valueFrom:
                configMapKeyRef:
                  name: kubecost-cost-analyzer
                  key: kubecost-token
        - image: gcr.io/kubecost1/frontend:prod-1.107.0
        
          env:
            - name: GET_HOSTS_FROM
              value: dns
          name: cost-analyzer-frontend
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
          volumeMounts:
            - name: tmp
              mountPath: /tmp
            - name: nginx-conf
              mountPath: /etc/nginx/conf.d/
          resources:
            requests:
              cpu: 10m
              memory: 55Mi
          imagePullPolicy: Always
          readinessProbe:
            httpGet:
              path: /healthz
              port: 9003
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 200
          livenessProbe:
            httpGet:
              path: /healthz
              port: 9003
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 200
---
# Source: cost-analyzer/templates/tests/basic-health.yaml
apiVersion: v1
kind: Pod
metadata:
  name: basic-health
  namespace: monitoring
  annotations:
    helm.sh/hook: test
spec:
  serviceAccountName: kubecost-cost-analyzer
  restartPolicy: Never
  containers:
  - name: test-kubecost
    image: alpine/k8s:1.26.9
    command:
      - /bin/sh
    args:
      - -c
      - >-
        svc=$(kubectl -n monitoring get svc -l app.kubernetes.io/name=cost-analyzer -o json | jq -r .items[0].metadata.name);
        echo Getting current Kubecost state.;
        response=$(curl -sL http://${svc}:9090/model/getConfigs);
        code=$(echo ${response} | jq .code);
        if [ "$code" -eq 200 ]; then
          echo "Got Kubecost working configuration. Successful."
          exit 0
        else 
          echo "Failed to fetch Kubecost configuration. Response was $response"
          exit 1
        fi

---
# Source: robusta/templates/forwarder-service-account.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: robusta-forwarder-service-account
  namespace: robusta
---
# Source: robusta/templates/runner-service-account.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: robusta-runner-service-account
  namespace: robusta
---
# Source: robusta/templates/playbooks-config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: robusta-playbooks-config-secret
  namespace: robusta
type: Opaque
data:
  active_playbooks.yaml: |-
    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
---
# Source: robusta/templates/runner.yaml
---

apiVersion: v1
kind: Secret
metadata:
  name: robusta-runner-secret
  namespace: robusta
type: Opaque
stringData:
  SENTRY_DSN: https://53b627690db14de7b02095407596fa16@o1120648.ingest.sentry.io/6156573
---
# Source: robusta/templates/kubewatch-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: robusta-kubewatch-config
  namespace: robusta
data:
  .kubewatch.yaml: |-
    handler:
      cloudevent:
        url: "http://robusta-runner:80/api/handle"
    namespace: ""
    resource:
      deployment: true
      replicationcontroller: true
      replicaset: true
      daemonset: true
      statefulset: true
      services: true
      pod: true
      job: true
      node: true
      hpa: true
      clusterrole: true
      clusterrolebinding: true
      serviceaccount: true
      persistentvolume: true
      namespace: true
      configmap: true # 0.9.17
      secret: false       # disabled for security reasons
---
# Source: robusta/templates/forwarder-service-account.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: robusta-forwarder-cluster-role
  namespace : robusta
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
      - daemonsets
      - deployments
      - events
      - namespaces
      - nodes
      - persistentvolumes
      - pods
      - replicasets
      - replicationcontrollers
      #- secrets
      - services
      - serviceaccounts
    verbs:
      - get
      - list
      - watch

  - apiGroups:
      - "autoscaling"
    resources:
      - horizontalpodautoscalers
    verbs:
      - get
      - list
      - watch

  - apiGroups:
      - "rbac.authorization.k8s.io"
    resources:
      - clusterroles
      - clusterrolebindings
    verbs:
      - get
      - list
      - watch

  - apiGroups:
      - apps
    resources:
      - daemonsets
      - deployments
      - deployments/scale
      - replicasets
      - replicasets/scale
      - statefulsets
    verbs:
      - get
      - list
      - watch

  - apiGroups:
      - extensions
    resources:
      - daemonsets
      - deployments
      - deployments/scale
      - ingresses
      - replicasets
      - replicasets/scale
      - replicationcontrollers/scale
    verbs:
      - get
      - list
      - watch
    
  - apiGroups:
      - batch
    resources:
      - cronjobs
      - jobs
    verbs:
      - get
      - list
      - watch
---
# Source: robusta/templates/runner-service-account.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: robusta-runner-cluster-role
  namespace : robusta
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
      - daemonsets
      - deployments
      - events
      - namespaces
      - nodes
      - persistentvolumes
      - persistentvolumeclaims
      - pods
      - pods/status
      - pods/exec
      - pods/log
      - replicasets
      - replicationcontrollers
      - services
      - serviceaccounts
    verbs:
      - get
      - list
      - watch

  - apiGroups:
      - ""
    resources:
      - configmaps
      - persistentvolumes
      - persistentvolumeclaims
      - pods
      - pods/status
      - pods/exec
      - pods/log
    verbs:
      - delete
      - create
      - patch
      - update

  - apiGroups:
      - "rbac.authorization.k8s.io"
    resources:
      - clusterroles
      - clusterrolebindings
    verbs:
      - get
      - list
      - watch

  - apiGroups:
      - "autoscaling"
    resources:
      - horizontalpodautoscalers
    verbs:
      - get
      - list
      - watch
      - patch
      - update

  - apiGroups:
      - apps
    resources:
      - daemonsets
      - deployments
      - deployments/scale
      - replicasets
      - replicasets/scale
      - statefulsets
    verbs:
      - get
      - list
      - watch

  - apiGroups:
      - apps
    resources:
      - deployments
    verbs:
      - create
      - patch
      - delete

  - apiGroups:
      - extensions
    resources:
      - daemonsets
      - deployments
      - deployments/scale
      - ingresses
      - replicasets
      - replicasets/scale
      - replicationcontrollers/scale
    verbs:
      - get
      - list
      - watch

  - apiGroups:
      - batch
    resources:
      - cronjobs
      - jobs
    verbs:
      - get
      - list
      - watch
      - patch
      - delete
      - create
---
# Source: robusta/templates/forwarder-service-account.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: robusta-forwarder-cluster-role-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: robusta-forwarder-cluster-role
subjects:
  - kind: ServiceAccount
    name: robusta-forwarder-service-account
    namespace: robusta
---
# Source: robusta/templates/runner-service-account.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: robusta-runner-cluster-role-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: robusta-runner-cluster-role
subjects:
  - kind: ServiceAccount
    name: robusta-runner-service-account
    namespace: robusta
---
# Source: robusta/templates/runner.yaml
apiVersion: v1
kind: Service
metadata:
  name: robusta-runner
  namespace: robusta
  labels:
    app: robusta-runner
spec:
  selector:
    app: robusta-runner
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 5000
---
# Source: robusta/templates/forwarder.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: robusta-forwarder
  namespace: robusta
spec:
  selector:
    matchLabels:
      app: robusta-forwarder
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/config: 93ea5dab5db4ebfb8b279cdc6fee92cd1ce72dbf3307ea0ef510f052e557bc60
      labels:
        app: robusta-forwarder
    spec:
      serviceAccountName: robusta-forwarder-service-account
      containers:
      - name: kubewatch
        # this is a custom version of kubewatch built from https://github.com/aantn/kubewatch
        image: us-central1-docker.pkg.dev/genuine-flight-317411/devel/kubewatch:v2.0
        imagePullPolicy: IfNotPresent
        env:
          - name: KW_CONFIG
            value: /config
          - name: ENABLE_PPROF
            value: "true"
        volumeMounts:
          - name: robusta-kubewatch-config
            mountPath: /config
        resources:
          requests:
            cpu: 10m
            memory: "512Mi"
          limits:
            memory: "512Mi"
            
      volumes:
        - name:  robusta-kubewatch-config
          configMap:
            name: robusta-kubewatch-config
---
# Source: robusta/templates/runner.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: robusta-runner
  namespace: robusta
  labels:
    app: robusta-runner
spec:
  replicas: 1
  selector:
    matchLabels:
      app: robusta-runner
  template:
    metadata:
      labels:
        app: robusta-runner
        robustaComponent: "runner"
    spec:
      serviceAccountName: robusta-runner-service-account
      containers:
      - name: runner
        image: us-central1-docker.pkg.dev/genuine-flight-317411/devel/robusta-runner:0.10.6
        imagePullPolicy: IfNotPresent
        securityContext:
          privileged: false
        env:
          - name: PLAYBOOKS_CONFIG_FILE_PATH
            value: /etc/robusta/config/active_playbooks.yaml
          - name: ENABLE_MANHOLE
            value: "true"
          - name: RELEASE_NAME
            value: "robusta"
          - name: ENABLE_COLORED_LOGS
            value: "true"
          - name: PROMETHEUS_ENABLED
            value: "false"
          - name: SEND_ADDITIONAL_TELEMETRY
            value: "false"
          - name: LOG_LEVEL
            value: INFO
          - name: INSTALLATION_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: RUNNER_VERSION
            value: 0.10.6
        envFrom: 
        - secretRef:
            name: robusta-runner-secret
            optional: true
        volumeMounts:
          - name: auth-config-secret
            mountPath: /etc/robusta/auth
          - name: playbooks-config-secret
            mountPath: /etc/robusta/config
        lifecycle:
          preStop:
            exec:
              command: ["bash", "-c", "kill -SIGINT 1"]
        resources:
          requests:
            cpu: 250m
            memory: "1024Mi"
          limits:
            memory: "1024Mi"
            
      volumes:
        - name: playbooks-config-secret
          secret:
            secretName: robusta-playbooks-config-secret
            optional: true
        - name: auth-config-secret
          secret:
            secretName: robusta-auth-config-secret
            optional: true

